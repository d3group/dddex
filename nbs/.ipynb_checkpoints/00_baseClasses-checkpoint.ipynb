{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Class\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp baseClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "from fastcore.script import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "import copy\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Level-Set Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseLSx:\n",
    "    \"\"\"\n",
    "    Base class for the Level-Set based approaches. This class is not supposed to be used directly.\n",
    "    Use derived classes instead.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 estimator, # Model with a `fit` and `predict` method (implementing the scikit-learn estimator interface).\n",
    "                 binSize: int=None, # Number of training samples considered for creating weights.\n",
    "                 # Determines behaviour of method `getWeights`. If False, all weights receive the same  \n",
    "                 # value. If True, the distance of the point forecasts is taking into account.\n",
    "                 weightsByDistance: bool=False,  \n",
    "                 ):\n",
    "        \n",
    "        if not (hasattr(estimator, 'predict') and callable(estimator.predict)):\n",
    "            raise ValueError(\"'estimator' has to have a 'predict'-method!\")\n",
    "            \n",
    "        if not (isinstance(binSize, (int, np.integer)) or binSize is None):\n",
    "            raise ValueError(\"'binSize' has to be an integer!\")\n",
    "            \n",
    "        self.estimator = copy.deepcopy(estimator)\n",
    "        self.binSize = binSize\n",
    "        self.weightsByDistance = weightsByDistance      \n",
    "        \n",
    "    #---\n",
    "    \n",
    "    def pointPredict(self: BaseLSx, \n",
    "                     # Feature matrix for which point predictions are computed based\n",
    "                     # on the point forecasting model specified via `estimator`.\n",
    "                     X: np.ndarray \n",
    "                     ):\n",
    "        \n",
    "        return self.estimator.predict(X)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def refitPointEstimator(self: BaseLSx, \n",
    "                            X: np.ndarray, # Input feature matrix\n",
    "                            y: np.ndarray, # Target values\n",
    "                            **kwargs):\n",
    "        \n",
    "        try:\n",
    "            self.estimator.set_params(**kwargs)\n",
    "        except:\n",
    "            raise NotImplementedError(\"The 'estimator' object has no 'set_params' method, so the\"\n",
    "                                      \"provided parameters via **kwargs can't be set!\")\n",
    "        else:\n",
    "            setattr(self, 'estimator', self.estimator.fit(X = X, y = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx.pointPredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BaseLSx.refitPointEstimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-Based Predictor - Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseWeightsBasedEstimator(BaseEstimator):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution. This class is not supposed\n",
    "    to be used directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None,\n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \"\"\"\n",
    "        Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
    "        of the returned list depends on the specified value of `outputType`:\n",
    "        \n",
    "        - **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
    "          of each training sample.\n",
    "        - **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
    "          Note: This is the most memory and computationally efficient output type.\n",
    "        - **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
    "          corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        - **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the corresponding value of `yTrain`.\n",
    "        - **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
    "          the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        \"\"\"\n",
    "        pass\n",
    "     \n",
    "    #---\n",
    "    \n",
    "    def predict(self : BaseWeightsBasedEstimator, \n",
    "                X: np.ndarray, # Feature matrix for which conditional quantiles are computed.\n",
    "                probs: list, # Probabilities for which quantiles are computed.\n",
    "                outputAsDf: bool=True, # Determines output. Either a dataframe with probs as columns or a dict with probs as keys.\n",
    "                # Optional. List with length X.shape[0]. Values are multiplied to the predictions\n",
    "                # of each sample to rescale values.\n",
    "                scalingList: list=None, \n",
    "                ): \n",
    "        \"\"\" Predict p-quantiles based on a reweighting of the empirical distribution function.\"\"\"\n",
    "        \n",
    "        # Checks\n",
    "        if isinstance(probs, int) or isinstance(probs, float):\n",
    "            if probs >= 0 and probs <= 1:\n",
    "                probs = [probs]\n",
    "            else:\n",
    "                raise ValueError(\"The values specified via 'probs' must lie between 0 and 1!\")           \n",
    "                 \n",
    "        if any([prob > 1 or prob < 0 for prob in probs]):\n",
    "            raise ValueError(\"The values specified via 'probs' must lie between 0 and 1!\")\n",
    "            \n",
    "        try:\n",
    "            probs = np.array(probs)\n",
    "        except:\n",
    "            raise ValueError(\"Can't convert `probs` to 1-dimensional array.\")\n",
    "        \n",
    "        #---\n",
    "                             \n",
    "        distributionDataList = self.getWeights(X = X,\n",
    "                                               outputType = 'cumulativeDistribution',\n",
    "                                               scalingList = scalingList)        \n",
    "        \n",
    "        quantilesList = list()\n",
    "        \n",
    "        for probsDistribution, valuesDistribution in distributionDataList:\n",
    "            \n",
    "            # A tolerance term of 10^-8 is substracted from prob to account for rounding errors due to numerical precision.\n",
    "            quantileIndices = np.searchsorted(a = probsDistribution, v = probs - 10**-8, side = 'left')\n",
    "            quantilesList.append(valuesDistribution[quantileIndices])\n",
    "    \n",
    "        quantilesDf = pd.DataFrame(quantilesList)\n",
    "        quantilesDf.columns = probs\n",
    "\n",
    "        if outputAsDf:\n",
    "            return quantilesDf\n",
    "\n",
    "        else:\n",
    "            return quantilesDf.to_dict(orient = 'series')\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def sampleScenarios(self,\n",
    "                        X: np.ndarray, # Feature matrix for which samples are computed.\n",
    "                        n: int,\n",
    "                        # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                        # density of each sample for scaling purposes.\n",
    "                        scalingList: list=None,\n",
    "                        ) -> np.ndarray: # array-like of shape (n_samples_in, n_scenarios)\n",
    "        \n",
    "        distributionData = self.getWeights(X = X,\n",
    "                                           outputType = 'cumulativeDistribution',\n",
    "                                           scalingList = scalingList)\n",
    "        \n",
    "        sampleList = list()\n",
    "        for probs, values in distributionData:\n",
    "            randomProbs = uniform(size = n)\n",
    "            randomProbs = randomProbs.reshape(n, 1)\n",
    "            sample = values[np.argmax(probs >= randomProbs, axis = 1)]\n",
    "\n",
    "            sampleList.append(sample)\n",
    "        \n",
    "        sampleMatrix = np.concatenate([sampleList], axis = 0)\n",
    "        \n",
    "        return sampleMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/baseClasses.py#L79){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseWeightsBasedEstimator.getWeights\n",
       "\n",
       ">      BaseWeightsBasedEstimator.getWeights (X:numpy.ndarray,\n",
       ">                                            outputType:str='onlyPositiveWeights\n",
       ">                                            ', scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/baseClasses.py#L79){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseWeightsBasedEstimator.getWeights\n",
       "\n",
       ">      BaseWeightsBasedEstimator.getWeights (X:numpy.ndarray,\n",
       ">                                            outputType:str='onlyPositiveWeights\n",
       ">                                            ', scalingList:list=None)\n",
       "\n",
       "Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.getWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/baseClasses.py#L108){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseWeightsBasedEstimator.predict\n",
       "\n",
       ">      BaseWeightsBasedEstimator.predict (X:numpy.ndarray, probs:list,\n",
       ">                                         outputAsDf:bool=True,\n",
       ">                                         scalingList:list=None)\n",
       "\n",
       "Predict p-quantiles based on a reweighting of the empirical distribution function.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional quantiles are computed. |\n",
       "| probs | list |  | Probabilities for which quantiles are computed. |\n",
       "| outputAsDf | bool | True | Determines output. Either a dataframe with probs as columns or a dict with probs as keys. |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the predictions<br>of each sample to rescale values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/baseClasses.py#L108){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseWeightsBasedEstimator.predict\n",
       "\n",
       ">      BaseWeightsBasedEstimator.predict (X:numpy.ndarray, probs:list,\n",
       ">                                         outputAsDf:bool=True,\n",
       ">                                         scalingList:list=None)\n",
       "\n",
       "Predict p-quantiles based on a reweighting of the empirical distribution function.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional quantiles are computed. |\n",
       "| probs | list |  | Probabilities for which quantiles are computed. |\n",
       "| outputAsDf | bool | True | Determines output. Either a dataframe with probs as columns or a dict with probs as keys. |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the predictions<br>of each sample to rescale values. |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseWeightsBasedEstimator.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights-Based Predictor - Multivariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class BaseWeightsBasedEstimator_multivariate(BaseEstimator):\n",
    "    \"\"\" \n",
    "    Base class that implements the 'prediction'-method for approaches based \n",
    "    on a reweighting of the empirical distribution. This class is not supposed\n",
    "    to be used directly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None,\n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \"\"\"\n",
    "        Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
    "        of the returned list depends on the specified value of `outputType`:\n",
    "        \n",
    "        - **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
    "          of each training sample.\n",
    "        - **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
    "          one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
    "          Note: This is the most memory and computationally efficient output type.\n",
    "        - **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
    "          corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
    "        \"\"\"\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 129)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3397\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  Input \u001b[1;32mIn [13]\u001b[0m in \u001b[1;35m<cell line: 2>\u001b[0m\n    import nbdev; nbdev.nbdev_export()\n",
      "  File \u001b[1;32m~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/fastcore/script.py:110\u001b[0m in \u001b[1;35m_f\u001b[0m\n    if not mod: return func(*args, **kwargs)\n",
      "  File \u001b[1;32m~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/nbdev/doclinks.py:139\u001b[0m in \u001b[1;35mnbdev_export\u001b[0m\n    _build_modidx()\n",
      "  File \u001b[1;32m~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/nbdev/doclinks.py:101\u001b[0m in \u001b[1;35m_build_modidx\u001b[0m\n    res['syms'].update(_get_modidx((dest.parent/file).resolve(), code_root, nbs_path=nbs_path))\n",
      "  File \u001b[1;32m~/.conda/envs/HC-Scheduling/lib/python3.8/site-packages/nbdev/doclinks.py:78\u001b[0m in \u001b[1;35m_get_modidx\u001b[0m\n    for tree in ast.parse(cell.code).body:\n",
      "\u001b[0;36m  File \u001b[0;32m~/.conda/envs/HC-Scheduling/lib/python3.8/ast.py:47\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>:129\u001b[0;36m\u001b[0m\n\u001b[0;31m    quantileIndices = np.searchsorted(a = probsDistribution v = probs - 10**-8, side = 'right')\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
