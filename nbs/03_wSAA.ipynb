{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9df2e7-fdc8-44e7-b16c-d8b15ed01db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfbaad6-3667-46e6-b25e-efa0822452ae",
   "metadata": {},
   "source": [
    "# wSAA\n",
    "\n",
    "> Module description for wSAA classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c687b2c-941e-4e2a-9855-aa227ccb8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp wSAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1faac0-5c0d-4c70-80e9-7d959811b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from nbdev.qmd import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e786a-e401-43d8-91e9-97c175eba23a",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86f92e6-67ad-492b-9779-7b9acfc3d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from fastcore.docments import *\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.base import MetaEstimatorMixin\n",
    "from dddex.baseClasses import BaseWeightsBasedEstimator\n",
    "from dddex.utils import restructureWeightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331bd1d-ceaa-4b36-a42e-aaa2e4062c22",
   "metadata": {},
   "source": [
    "## wSAA - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b775c4-ca57-4539-a0b8-e282bdf963cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "class RandomForestWSAA(RandomForestRegressor, BaseWeightsBasedEstimator):\n",
    "    \n",
    "    def fit(self, \n",
    "            X: np.ndarray, # Feature matrix\n",
    "            y: np.ndarray, # Target values\n",
    "            **kwargs):\n",
    "\n",
    "        super().fit(X = X, \n",
    "                    y = y, \n",
    "                    **kwargs)\n",
    "        \n",
    "        self.y = y\n",
    "        self.leafIndicesTrain = self.apply(X)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "               X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "               # Specifies structure of the returned density estimates. One of: \n",
    "               # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "               outputType: str='onlyPositiveWeights', \n",
    "               # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "               # density of each sample for scaling purposes.\n",
    "               scalingList: list=None, \n",
    "               ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "        #---\n",
    "\n",
    "        leafIndicesDf = self.apply(X)\n",
    "\n",
    "        weightsDataList = list()\n",
    "\n",
    "        for leafIndices in leafIndicesDf:\n",
    "            leafComparisonMatrix = (self.leafIndicesTrain == leafIndices) * 1\n",
    "            nObsInSameLeaf = np.sum(leafComparisonMatrix, axis = 0)\n",
    "\n",
    "            # It can happen that RF decides that the best strategy is to fit no tree at\n",
    "            # all and simply average all results (happens when min_child_sample is too high, for example).\n",
    "            # In this case 'leafComparisonMatrix' mustn't be averaged because there has been only a single tree.\n",
    "            if len(leafComparisonMatrix.shape) == 1:\n",
    "                weights = leafComparisonMatrix / nObsInSameLeaf\n",
    "            else:\n",
    "                weights = np.mean(leafComparisonMatrix / nObsInSameLeaf, axis = 1)\n",
    "\n",
    "            weightsPosIndex = np.where(weights > 0)[0]\n",
    "\n",
    "            weightsDataList.append((weights[weightsPosIndex], weightsPosIndex))\n",
    "\n",
    "        #---\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     y = self.y, \n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = False)\n",
    "\n",
    "        return weightsDataList\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def predict(self : BaseWeightsBasedEstimator, \n",
    "                X: np.ndarray, # Feature matrix for which conditional quantiles are computed.\n",
    "                probs: list, # Probabilities for which quantiles are computed.\n",
    "                outputAsDf: bool=True, # Determines output. Either a dataframe with probs as columns or a dict with probs as keys.\n",
    "                # Optional. List with length X.shape[0]. Values are multiplied to the predictions\n",
    "                # of each sample to rescale values.\n",
    "                scalingList: list=None, \n",
    "                ): \n",
    "        \n",
    "        __doc__ = BaseWeightsBasedEstimator.predict.__doc__\n",
    "        \n",
    "        return super(MetaEstimatorMixin, self).predict(X = X,\n",
    "                                                       probs = probs, \n",
    "                                                       outputAsDf = outputAsDf,\n",
    "                                                       scalingList = scalingList)\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def pointPredict(self,\n",
    "                     X: np.ndarray, # Feature Matrix\n",
    "                     **kwargs):\n",
    "        \"\"\"Original `predict` method to generate point forecasts\"\"\"\n",
    "        \n",
    "        return super().predict(X = X,\n",
    "                               **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db18d0f-bdb7-4f08-a8cf-ac07a49e7d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(RandomForestWSAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a240e3b-5acc-4f82-8f4d-29391f5692b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(RandomForestWSAA.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ebe067-f51e-4038-ae00-06bafa7ca014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(RandomForestWSAA.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f471bba6-50ec-49a9-980d-1c10f4361938",
   "metadata": {},
   "source": [
    "## SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b21e7-4c15-4c6d-8ebd-236740ec71e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SampleAverageApproximation(BaseWeightsBasedEstimator):\n",
    "    \"\"\"SAA is a featureless approach that assumes the density of the target variable is given\n",
    "    by assigning equal probability to each historical observation of said target variable.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.yTrain = None\n",
    "        \n",
    "    #---\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"SAA()\"\n",
    "    __repr__ = __str__ \n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def fit(self: SAA, \n",
    "            y: np.ndarray, # Target values which form the estimated density function based on the SAA algorithm.\n",
    "            ):\n",
    "        self.yTrain = y\n",
    "    \n",
    "    #---\n",
    "    \n",
    "    def getWeights(self, \n",
    "                   X: np.ndarray=None, # Feature matrix for which conditional density estimates are computed.\n",
    "                   # Specifies structure of the returned density estimates. One of: \n",
    "                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "                   outputType: str='onlyPositiveWeights', \n",
    "                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "                   # density of each sample for scaling purposes.\n",
    "                   scalingList: list=None, \n",
    "                   ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "        #---\n",
    "\n",
    "        if X is None:\n",
    "            neighborsList = [np.arange(len(self.yTrain))]\n",
    "        else:\n",
    "            neighborsList = [np.arange(len(self.yTrain))] * X.shape[0]\n",
    "\n",
    "        # weightsDataList is a list whose elements correspond to one test prediction each. \n",
    "        weightsDataList = [(np.repeat(1 / len(neighbors), len(neighbors)), np.array(neighbors)) for neighbors in neighborsList]\n",
    "\n",
    "        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "                                                     outputType = outputType, \n",
    "                                                     y = self.yTrain,\n",
    "                                                     scalingList = scalingList,\n",
    "                                                     equalWeights = True)\n",
    "\n",
    "        return weightsDataList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc67de5-0fcb-47b3-82dd-908cbedaae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(SampleAverageApproximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9520933-6480-4e96-bace-8b9f164cd922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(SampleAverageApproximation.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e77e0d-5cb8-4c29-b356-0f0e61bccde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(SampleAverageApproximation.getWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79762a-1427-49d7-b8b2-42ecde48e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f57a0f-e4d4-4655-858c-d6319f087936",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f055de-89ce-4943-8242-8f434ee8a3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from dddex.loadData import *\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14, \n",
    "#                                                  returnXY = True,\n",
    "#                                                  daysToCut = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd2880-1b9e-4d07-ab84-4ba8a2bef226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# RF = RandomForestWSAA(max_depth = 2,\n",
    "#                       n_estimators = 10,\n",
    "#                       n_jobs = 1)\n",
    "\n",
    "# RF.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1533bbef-fe12-4600-85a7-07cd9dc05fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# RF.predict(XTest, probs = [0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HC-Scheduling",
   "language": "python",
   "name": "hc-scheduling"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
