[
  {
    "objectID": "baseclasses.html#base-level-set-class",
    "href": "baseclasses.html#base-level-set-class",
    "title": "Base Class",
    "section": "Base Level-Set Class",
    "text": "Base Level-Set Class\n\nsource\n\nBaseLSx\n\n BaseLSx (estimator)\n\nBase class for the Level-Set based approaches. This class is not supposed to be used directly. Use derived classes instead.\n\n\n\n\n\n\n\n\nDetails\n\n\n\n\nestimator\nModel with a fit and predict method (implementing the scikit-learn estimator interface).\n\n\n\n\n# show_doc(BaseLSx)\n\n\n# show_doc(BaseLSx.pointPredict)\n\n\n# show_doc(BaseLSx.refitPointEstimator)"
  },
  {
    "objectID": "baseclasses.html#weights-based-predictor---univariate",
    "href": "baseclasses.html#weights-based-predictor---univariate",
    "title": "Base Class",
    "section": "Weights-Based Predictor - Univariate",
    "text": "Weights-Based Predictor - Univariate\n\nsource\n\nBaseWeightsBasedEstimator\n\n BaseWeightsBasedEstimator ()\n\nBase class that implements the ‘prediction’-method for approaches based on a reweighting of the empirical distribution. This class is not supposed to be used directly.\n\nsource\n\n\nBaseWeightsBasedEstimator.getWeights\n\n BaseWeightsBasedEstimator.getWeights (X:numpy.ndarray,\n                                       outputType:str='onlyPositiveWeights\n                                       ', scalingList:list=None)\n\nComputes estimated conditional density for each sample specified by X. The concrete structure of each element of the returned list depends on the specified value of outputType:\n\nall: An array with the same length as the number of training samples. Each entry represents the probability of each training sample.\nonlyPositiveWeights: A tuple. The first element of the tuple represents the probabilities and the second one the indices of the corresponding training sample. Only probalities greater than zero are returned. Note: This is the most memory and computationally efficient output type.\nsummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\ncumDistribution: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain.\ncumDistributionSummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nnp.ndarray\n\nFeature matrix for which conditional density estimates are computed.\n\n\noutputType\nstr\nonlyPositiveWeights\nSpecifies structure of the returned density estimates. One of: ‘all’, ‘onlyPositiveWeights’, ‘summarized’, ‘cumDistribution’, ‘cumDistributionSummarized’\n\n\nscalingList\nlist\nNone\nOptional. List with length X.shape[0]. Values are multiplied to the estimated density of each sample for scaling purposes.\n\n\nReturns\nlist\n\nList whose elements are the conditional density estimates for the samples specified by X.\n\n\n\n\nsource\n\n\nBaseWeightsBasedEstimator.predict\n\n BaseWeightsBasedEstimator.predict (X:numpy.ndarray, probs:list,\n                                    scalingList:list=None)\n\nPredict p-quantiles based on a reweighting of the empirical distribution function. If the number of observations of either X or yTrain is above a certain threshold, the results aren’t calculated in one go, but rather by sequentially computing the predictions for 100 different subsets of the observations of X. We do this to avoid because intermediary objects like distributionDataList are stored in ‘(X.shape[0], XTrain.shape[0])’ space in the worst case. Hence, this can cause the program to crash in extreme cases.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nnp.ndarray\n\nFeature matrix for which conditional quantiles are computed.\n\n\nprobs\nlist\n\nProbabilities for which quantiles are computed.\n\n\nscalingList\nlist\nNone\nOptional. List with length X.shape[0]. Values are multiplied to the predictionsof each sample to rescale values.\n\n\nReturns\nnp.ndarray"
  },
  {
    "objectID": "baseclasses.html#weights-based-predictor---multivariate",
    "href": "baseclasses.html#weights-based-predictor---multivariate",
    "title": "Base Class",
    "section": "Weights-Based Predictor - Multivariate",
    "text": "Weights-Based Predictor - Multivariate\n\nsource\n\nBaseWeightsBasedEstimator_multivariate\n\n BaseWeightsBasedEstimator_multivariate ()\n\nBase class that implements the ‘prediction’-method for approaches based on a reweighting of the empirical distribution. This class is not supposed to be used directly."
  },
  {
    "objectID": "wsaa.html#wsaa---random-forest",
    "href": "wsaa.html#wsaa---random-forest",
    "title": "wSAA",
    "section": "wSAA - Random Forest",
    "text": "wSAA - Random Forest\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Attributes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section See Also\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Notes\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section References\n  else: warn(msg)\n/opt/hostedtoolcache/Python/3.9.18/x64/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\nsource\n\nRandomForestWSAA\n\n RandomForestWSAA (n_estimators=100, criterion='squared_error',\n                   max_depth=None, min_samples_split=2,\n                   min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n                   max_features=1.0, max_leaf_nodes=None,\n                   min_impurity_decrease=0.0, bootstrap=True,\n                   oob_score=False, n_jobs=None, random_state=None,\n                   verbose=0, warm_start=False, ccp_alpha=0.0,\n                   max_samples=None)\n\nA random forest regressor.\nA random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\nFor a comparison between tree-based ensemble models see the example :ref:sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py.\nRead more in the :ref:User Guide &lt;forest&gt;.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nn_estimators\nint\n100\nThe number of trees in the forest... versionchanged:: 0.22 The default value of n_estimators changed from 10 to 100 in 0.22.\n\n\ncriterion\nstr\nsquared_error\nThe function to measure the quality of a split. Supported criteriaare “squared_error” for the mean squared error, which is equal tovariance reduction as feature selection criterion and minimizes the L2loss using the mean of each terminal node, “friedman_mse”, which usesmean squared error with Friedman’s improvement score for potentialsplits, “absolute_error” for the mean absolute error, which minimizesthe L1 loss using the median of each terminal node, and “poisson” whichuses reduction in Poisson deviance to find splits.Training using “absolute_error” is significantly slowerthan when using “squared_error”... versionadded:: 0.18 Mean Absolute Error (MAE) criterion... versionadded:: 1.0 Poisson criterion.\n\n\nmax_depth\nNoneType\nNone\nThe maximum depth of the tree. If None, then nodes are expanded untilall leaves are pure or until all leaves contain less thanmin_samples_split samples.\n\n\nmin_samples_split\nint\n2\nThe minimum number of samples required to split an internal node:- If int, then consider min_samples_split as the minimum number.- If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number of samples for each split... versionchanged:: 0.18 Added float values for fractions.\n\n\nmin_samples_leaf\nint\n1\nThe minimum number of samples required to be at a leaf node.A split point at any depth will only be considered if it leaves atleast min_samples_leaf training samples in each of the left andright branches. This may have the effect of smoothing the model,especially in regression.- If int, then consider min_samples_leaf as the minimum number.- If float, then min_samples_leaf is a fraction and ceil(min_samples_leaf * n_samples) are the minimum number of samples for each node... versionchanged:: 0.18 Added float values for fractions.\n\n\nmin_weight_fraction_leaf\nfloat\n0.0\nThe minimum weighted fraction of the sum total of weights (of allthe input samples) required to be at a leaf node. Samples haveequal weight when sample_weight is not provided.\n\n\nmax_features\nfloat\n1.0\nThe number of features to consider when looking for the best split:- If int, then consider max_features features at each split.- If float, then max_features is a fraction and max(1, int(max_features * n_features_in_)) features are considered at each split.- If “sqrt”, then max_features=sqrt(n_features).- If “log2”, then max_features=log2(n_features).- If None or 1.0, then max_features=n_features... note:: The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3... versionchanged:: 1.1 The default of max_features changed from \"auto\" to 1.0.Note: the search for a split does not stop until at least onevalid partition of the node samples is found, even if it requires toeffectively inspect more than max_features features.\n\n\nmax_leaf_nodes\nNoneType\nNone\nGrow trees with max_leaf_nodes in best-first fashion.Best nodes are defined as relative reduction in impurity.If None then unlimited number of leaf nodes.\n\n\nmin_impurity_decrease\nfloat\n0.0\nA node will be split if this split induces a decrease of the impuritygreater than or equal to this value.The weighted impurity decrease equation is the following:: N_t / N * (impurity - N_t_R / N_t * right_impurity - N_t_L / N_t * left_impurity)where N is the total number of samples, N_t is the number ofsamples at the current node, N_t_L is the number of samples in theleft child, and N_t_R is the number of samples in the right child.N, N_t, N_t_R and N_t_L all refer to the weighted sum,if sample_weight is passed... versionadded:: 0.19\n\n\nbootstrap\nbool\nTrue\nWhether bootstrap samples are used when building trees. If False, thewhole dataset is used to build each tree.\n\n\noob_score\nbool\nFalse\nWhether to use out-of-bag samples to estimate the generalization score.By default, :func:~sklearn.metrics.r2_score is used.Provide a callable with signature metric(y_true, y_pred) to use acustom metric. Only available if bootstrap=True.\n\n\nn_jobs\nNoneType\nNone\nThe number of jobs to run in parallel. :meth:fit, :meth:predict,:meth:decision_path and :meth:apply are all parallelized over thetrees. None means 1 unless in a :obj:joblib.parallel_backendcontext. -1 means using all processors. See :term:Glossary&lt;br&gt;&lt;n_jobs&gt; for more details.\n\n\nrandom_state\nNoneType\nNone\nControls both the randomness of the bootstrapping of the samples usedwhen building trees (if bootstrap=True) and the sampling of thefeatures to consider when looking for the best split at each node(if max_features &lt; n_features).See :term:Glossary &lt;random_state&gt; for details.\n\n\nverbose\nint\n0\nControls the verbosity when fitting and predicting.\n\n\nwarm_start\nbool\nFalse\nWhen set to True, reuse the solution of the previous call to fitand add more estimators to the ensemble, otherwise, just fit a wholenew forest. See :term:Glossary &lt;warm_start&gt; and:ref:gradient_boosting_warm_start for details.\n\n\nccp_alpha\nfloat\n0.0\nComplexity parameter used for Minimal Cost-Complexity Pruning. Thesubtree with the largest cost complexity that is smaller thanccp_alpha will be chosen. By default, no pruning is performed. See:ref:minimal_cost_complexity_pruning for details... versionadded:: 0.22\n\n\nmax_samples\nNoneType\nNone\nIf bootstrap is True, the number of samples to draw from Xto train each base estimator.- If None (default), then draw X.shape[0] samples.- If int, then draw max_samples samples.- If float, then draw max(round(n_samples * max_samples), 1) samples. Thus, max_samples should be in the interval (0.0, 1.0]... versionadded:: 0.22\n\n\n\n\n# show_doc(RandomForestWSAA)\n\n\n# show_doc(RandomForestWSAA.fit)\n\n\n# show_doc(RandomForestWSAA.getWeights)"
  },
  {
    "objectID": "wsaa.html#wsaa---random-forest-lightgbm",
    "href": "wsaa.html#wsaa---random-forest-lightgbm",
    "title": "wSAA",
    "section": "wSAA - Random Forest LightGBM",
    "text": "wSAA - Random Forest LightGBM\n\nsource\n\nRandomForestWSAA_LGBM\n\n RandomForestWSAA_LGBM (boosting_type:str='gbdt', num_leaves:int=31,\n                        max_depth:int=-1, learning_rate:float=0.1,\n                        n_estimators:int=100,\n                        subsample_for_bin:int=200000, objective:Union[str,\n                        Callable[[Optional[numpy.ndarray],numpy.ndarray],T\n                        uple[numpy.ndarray,numpy.ndarray]],Callable[[Optio\n                        nal[numpy.ndarray],numpy.ndarray,Optional[numpy.nd\n                        array]],Tuple[numpy.ndarray,numpy.ndarray]],Callab\n                        le[[Optional[numpy.ndarray],numpy.ndarray,Optional\n                        [numpy.ndarray],Optional[numpy.ndarray]],Tuple[num\n                        py.ndarray,numpy.ndarray]],NoneType]=None,\n                        class_weight:Union[Dict,str,NoneType]=None,\n                        min_split_gain:float=0.0,\n                        min_child_weight:float=0.001,\n                        min_child_samples:int=20, subsample:float=1.0,\n                        subsample_freq:int=0, colsample_bytree:float=1.0,\n                        reg_alpha:float=0.0, reg_lambda:float=0.0, random_\n                        state:Union[int,numpy.random.mtrand.RandomState,No\n                        neType]=None, n_jobs:Optional[int]=None,\n                        importance_type:str='split', **kwargs)\n\nLightGBM regressor."
  },
  {
    "objectID": "wsaa.html#saa",
    "href": "wsaa.html#saa",
    "title": "wSAA",
    "section": "SAA",
    "text": "SAA\n\nsource\n\nSampleAverageApproximation\n\n SampleAverageApproximation ()\n\nSAA is a featureless approach that assumes the density of the target variable is given by assigning equal probability to each historical observation of said target variable.\n\n# show_doc(SampleAverageApproximation)\n\n\n# show_doc(SampleAverageApproximation.fit)\n\n\n# show_doc(SampleAverageApproximation.getWeights)"
  },
  {
    "objectID": "levelsetkdex_univariate.html",
    "href": "levelsetkdex_univariate.html",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "",
    "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nIn the following we define the classes LevelSetKDEx and LevelSetKDEx_kNN where KDE is short for ‘Kernel Density Estimator’ and the ‘x’ is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name ‘LevelSet’ stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument estimator and must have a .predict()-method and should have been trained before hand.\nBoth classes LevelSetKDEx and LevelSetKDEx_kNN fulfill the same task: By first running .fit(XTrain, yTrain) and then calling .generateWeights(XTest), they both output an estimation of the conditional density of every sample specified by ‘XTest’. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via estimator.predict(XTrain) and estimator.predict(XTest), respectively. Based on this comparison, we select ‘binSize’-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between LevelSetKDEx and LevelSetKDEx_kNN. Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\nFurther details on how both approaches work approaches can be found below."
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-bin-building",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-bin-building",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on Bin Building",
    "text": "Level-Set Approach based on Bin Building\n\nsource\n\nLevelSetKDEx\n\n LevelSetKDEx (estimator, binSize:int=100, weightsByDistance:bool=False)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nbinSize\nint\n100\nSize of the bins created while running fit.\n\n\nweightsByDistance\nbool\nFalse\nDetermines behaviour of method getWeights. If False, all weights receive the same value. If True, the distance of the point forecasts is taking into account.\n\n\n\n\nsource\n\n\nLevelSetKDEx.fit\n\n LevelSetKDEx.fit (X:numpy.ndarray, y:numpy.ndarray)\n\nFit LevelSetKDEx model by grouping the point predictions of the samples specified via X according to their value. Samples are recursively sorted into bins until each bin contains binSize many samples. For details, checkout the function generateBins which does the heavy lifting.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix used by estimator to predict y.\n\n\ny\nnp.ndarray\n1-dimensional target variable corresponding to the feature matrix X.\n\n\n\n\nsource\n\n\nLevelSetKDEx.getWeights\n\n LevelSetKDEx.getWeights (X:numpy.ndarray,\n                          outputType:str='onlyPositiveWeights',\n                          scalingList:list=None)\n\nComputes estimated conditional density for each sample specified by X. The concrete structure of each element of the returned list depends on the specified value of outputType:\n\nall: An array with the same length as the number of training samples. Each entry represents the probability of each training sample.\nonlyPositiveWeights: A tuple. The first element of the tuple represents the probabilities and the second one the indices of the corresponding training sample. Only probalities greater than zero are returned. Note: This is the most memory and computationally efficient output type.\nsummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\ncumDistribution: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain.\ncumDistributionSummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nnp.ndarray\n\nFeature matrix for which conditional density estimates are computed.\n\n\noutputType\nstr\nonlyPositiveWeights\nSpecifies structure of the returned density estimates. One of: ‘all’, ‘onlyPositiveWeights’, ‘summarized’, ‘cumDistribution’, ‘cumDistributionSummarized’\n\n\nscalingList\nlist\nNone\nOptional. List with length X.shape[0]. Values are multiplied to the estimated density of each sample for scaling purposes.\n\n\nReturns\nlist\n\nList whose elements are the conditional density estimates for the samples specified by X.\n\n\n\n\nGenerate Bins\n\nsource\n\n\n\ngenerateBins\n\n generateBins (binSize:int, yPred:numpy.ndarray)\n\nUsed to generate the bin-structure used by LevelSetKDEx to compute density estimations.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nbinSize\nint\nSize of the bins of values of yPred being grouped together.\n\n\nyPred\nnp.ndarray\n1-dimensional array of predicted values."
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-drf",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-drf",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on DRF",
    "text": "Level-Set Approach based on DRF\n\n# #| export\n\n# from drf import drf \n\n# class LevelSetKDEx_DRF(BaseWeightsBasedEstimator, BaseLSx):\n#     \"\"\"\n#     `LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n#     The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n#     as a similarity measure between samples. The point forecasts of the training samples are sorted and \n#     recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n#     a new bin is created and so on. For a new test sample we check into which bin its point prediction\n#     would have fallen and interpret the training samples of that bin as the empirical distribution function\n#     of this test sample.    \n#     \"\"\"\n    \n#     def __init__(self, \n#                  estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n#                  binSize: int=100, # Size of the bins created while running fit.\n#                  ):\n        \n#         super(BaseEstimator, self).__init__(estimator = estimator)\n\n#         # Check if binSize is integer\n#         if not isinstance(binSize, (int, np.int32, np.int64)):\n#             raise ValueError(\"'binSize' must be an integer!\")\n\n#         self.binSize = binSize\n        \n#         self.yTrain = None\n#         self.yPredTrain = None\n#         self.drf = None\n#         self.fitted = False\n    \n#     #---\n    \n#     def fit(self: LevelSetKDEx_DRF, \n#             X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n#             y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n#             ):\n#         \"\"\"\n#         Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n#         according to their value. Samples are recursively sorted into bins until each bin contains\n#         `binSize` many samples. For details, checkout the function `generateBins` which does the\n#         heavy lifting.\n#         \"\"\"\n        \n#         # Checks\n#         if not isinstance(self.binSize, (int, np.int32, np.int64)):\n#             raise ValueError(\"'binSize' must be an integer!\")\n            \n#         if self.binSize &gt; y.shape[0]:\n#             raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n        \n#         if X.shape[0] != y.shape[0]:\n#             raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n        \n#         #---\n        \n#         try:\n#             yPred = self.estimator.predict(X)\n            \n#         except NotFittedError:\n#             try:\n#                 self.estimator.fit(X = X, y = y)                \n#             except:\n#                 raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n#             else:\n#                 yPred = self.estimator.predict(X)\n        \n#         #---\n        \n#         yPred = pd.DataFrame(yPred)\n#         y = pd.Series(y)\n\n#         DRF = drf(min_node_size = self.binSize, num_trees = 100, num_features = 1, honesty = False, sample_fraction = 0.5, response_scaling = False, mtry = 1, num_threads = 16)\n#         DRF.fit(X = yPred, Y = y)\n        \n#         #---\n        \n#         # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n#         # problems later on.\n#         self.yTrain = y.ravel()\n        \n#         self.yPredTrain = yPred\n#         self.drf = DRF\n#         self.fitted = True\n        \n#     #---\n    \n#     def getWeights(self: LevelSetKDEx_DRF, \n#                    X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n#                    # Specifies structure of the returned density estimates. One of: \n#                    # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n#                    outputType: str='onlyPositiveWeights', \n#                    # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n#                    # density of each sample for scaling purposes.\n#                    scalingList: list=None, \n#                    ) -&gt; list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n        \n#         # __annotations__ = BaseWeightsBasedEstimator.getWeights.__annotations__\n#         __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n        \n#         if not self.fitted:\n#             raise NotFittedError(\"This LevelSetKDEx instance is not fitted yet. Call 'fit' with \"\n#                                  \"appropriate arguments before trying to compute weights.\")\n        \n#         #---\n        \n#         yPred = self.estimator.predict(X)\n#         yPred = pd.DataFrame(yPred)\n        \n#         weightsArray = self.drf.predict(yPred).weights\n#         weightsList = list(weightsArray)\n#         weightsDataList = [(weights[weights &gt; 0], np.where(weights &gt; 0)[0]) for weights in weightsList]\n\n#         weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n#                                                      outputType = outputType, \n#                                                      y = self.yTrain,\n#                                                      scalingList = scalingList,\n#                                                      equalWeights = True)\n        \n#         return weightsDataList"
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-gaussian-kernel",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-gaussian-kernel",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on Gaussian Kernel",
    "text": "Level-Set Approach based on Gaussian Kernel\n\nsource\n\nLevelSetKDEx_RBF\n\n LevelSetKDEx_RBF (estimator, lengthScale:float=1)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nlengthScale\nfloat\n1\nSize of the bins created while running fit."
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-knn",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-knn",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on kNN",
    "text": "Level-Set Approach based on kNN\n\nsource\n\nLevelSetKDEx_kNN\n\n LevelSetKDEx_kNN (estimator, binSize:int=100,\n                   weightsByDistance:bool=False)\n\nLevelSetKDEx_kNN turns any point predictor that has a .predict-method into an estimator of the condititional density of the underlying distribution. The basic idea of each level-set based approach is to interprete the point forecast generated by the underlying point predictor as a similarity measure of samples. In the case of the LevelSetKDEx_kNN defined here, for every new samples ‘binSize’-many training samples are computed whose point forecast is closest to the point forecast of the new sample. The resulting empirical distribution of these ‘nearest’ training samples are viewed as our estimation of the conditional distribution of each the new sample at hand.\nNOTE: In contrast to the standard LevelSetKDEx, it is possible to apply LevelSetKDEx_kNN to arbitrary dimensional point predictors.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nbinSize\nint\n100\nSize of the bins created while running fit.\n\n\nweightsByDistance\nbool\nFalse\nDetermines behaviour of method getWeights. If False, all weights receive the same value. If True, the distance of the point forecasts is taking into account.\n\n\n\n\nsource\n\n\nLevelSetKDEx_kNN.fit\n\n LevelSetKDEx_kNN.fit (X:numpy.ndarray, y:numpy.ndarray)\n\nFit LevelSetKDEx_kNN model by applying the nearest neighbors algorithm to the point predictions of the samples specified by X based on estimator.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix used by estimator to predict y.\n\n\ny\nnp.ndarray\n1-dimensional target variable corresponding to the feature matrix X.\n\n\n\n\nsource\n\n\nLevelSetKDEx_kNN.getWeights\n\n LevelSetKDEx_kNN.getWeights (X:numpy.ndarray,\n                              outputType:str='onlyPositiveWeights',\n                              scalingList:list=None)\n\nComputes estimated conditional density for each sample specified by X. The concrete structure of each element of the returned list depends on the specified value of outputType:\n\nall: An array with the same length as the number of training samples. Each entry represents the probability of each training sample.\nonlyPositiveWeights: A tuple. The first element of the tuple represents the probabilities and the second one the indices of the corresponding training sample. Only probalities greater than zero are returned. Note: This is the most memory and computationally efficient output type.\nsummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\ncumDistribution: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain.\ncumDistributionSummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nnp.ndarray\n\nFeature matrix for which conditional density estimates are computed.\n\n\noutputType\nstr\nonlyPositiveWeights\nSpecifies structure of the returned density estimates. One of: ‘all’, ‘onlyPositiveWeights’, ‘summarized’, ‘cumDistribution’, ‘cumDistributionSummarized’\n\n\nscalingList\nlist\nNone\nOptional. List with length X.shape[0]. Values are multiplied to the estimated density of each sample for scaling purposes.\n\n\nReturns\nlist\n\nList whose elements are the conditional density estimates for the samples specified by X."
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-nn",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-nn",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on NN",
    "text": "Level-Set Approach based on NN\n\nsource\n\nLevelSetKDEx_NN\n\n LevelSetKDEx_NN (estimator, binSize:int=100, efficientRAM:bool=False)\n\nLevelSetKDEx_kNN turns any point predictor that has a .predict-method into an estimator of the condititional density of the underlying distribution. The basic idea of each level-set based approach is to interprete the point forecast generated by the underlying point predictor as a similarity measure of samples. In the case of the LevelSetKDEx_kNN defined here, for every new samples ‘binSize’-many training samples are computed whose point forecast is closest to the point forecast of the new sample. The resulting empirical distribution of these ‘nearest’ training samples are viewed as our estimation of the conditional distribution of each the new sample at hand.\nNOTE: In contrast to the standard LevelSetKDEx, it is possible to apply LevelSetKDEx_kNN to arbitrary dimensional point predictors.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nbinSize\nint\n100\nSize of the bins created while running fit.\n\n\nefficientRAM\nbool\nFalse\nSetting ‘efficientRAM = TRUE’ is only necessary when there are roughly umore than 200k training observations to avoidan overusage of RAM. This setting causes the run-time of the algorithm of the weights computation to linearly depend on ‘binSize’. Because of that the algorithm becomes quite slow for ‘binSize’ &gt; 10k’.\n\n\n\n\n\nGet Neighbors\n\nsource\n\n\ngetNeighbors\n\n getNeighbors (binSize:int, yPred:numpy.ndarray)\n\nUsed to generate the neighboorhoods used by LevelSetKDEx to compute density estimations.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nbinSize\nint\nSize of the bins of values of yPred being grouped together.\n\n\nyPred\nnp.ndarray\n1-dimensional array of predicted values.\n\n\n\n\n\nGet Neighbor Test\n\nsource\n\n\ngetNeighborsTest\n\n getNeighborsTest (binSize:int, yPred:numpy.ndarray,\n                   yPredTrain:numpy.ndarray, neighborsDictTrain:dict)\n\nUsed to generate the neighboorhoods used by LevelSetKDEx to compute density estimations.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nbinSize\nint\nSize of the bins of values of yPred being grouped together.\n\n\nyPred\nnp.ndarray\n1-dimensional array of predicted values.\n\n\nyPredTrain\nnp.ndarray\n1-dimensional array of predicted train values.\n\n\nneighborsDictTrain\ndict\nDict containing the neighbors of all train samples. Keys are the train predictions.\n\n\n\n\n\nGet Kernel Values\n\nsource\n\n\ngetKernelValues\n\n getKernelValues (yPred, yPredTrain, neighborsDictTest,\n                  neighborsDictTrain, neighborsRemoved, neighborsAdded,\n                  binSize, efficientRAM=False)"
  },
  {
    "objectID": "levelsetkdex_univariate.html#level-set-approach-based-on-clustering",
    "href": "levelsetkdex_univariate.html#level-set-approach-based-on-clustering",
    "title": "Level-Set Based Kernel Density Estimation",
    "section": "Level-Set Approach based on Clustering",
    "text": "Level-Set Approach based on Clustering\n\nsource\n\nLevelSetKDEx_clustering\n\n LevelSetKDEx_clustering (estimator, nClusters:int=10)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nnClusters\nint\n10\nNumber of clusters to form as well as number of centroids to generate.\n\n\n\n\nsource\n\n\nLevelSetKDEx_clustering2\n\n LevelSetKDEx_clustering2 (estimator, nClusters:int=10)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nnClusters\nint\n10\nNumber of clusters to form as well as number of centroids to generate."
  },
  {
    "objectID": "levelsetkdex_multivariate.html",
    "href": "levelsetkdex_multivariate.html",
    "title": "Level-Set Based Kernel Density Estimation for multivariate Predictors",
    "section": "",
    "text": "source\n\n\n\n LevelSetKDEx_multivariate (estimator, binSize:int=None,\n                            equalBins:bool=False)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nbinSize\nint\nNone\nSize of the bins created while running fit.\n\n\nequalBins\nbool\nFalse\nDetermines behaviour of method getWeights. If False, all weights receive the same value. If True, the distance of the point forecasts is taking into account."
  },
  {
    "objectID": "levelsetkdex_multivariate.html#level-set-approach-based-on-clusters",
    "href": "levelsetkdex_multivariate.html#level-set-approach-based-on-clusters",
    "title": "Level-Set Based Kernel Density Estimation for multivariate Predictors",
    "section": "",
    "text": "source\n\n\n\n LevelSetKDEx_multivariate (estimator, binSize:int=None,\n                            equalBins:bool=False)\n\nLevelSetKDEx turns any point forecasting model into an estimator of the underlying conditional density. The name ‘LevelSet’ stems from the fact that this approach interprets the values of the point forecasts as a similarity measure between samples. The point forecasts of the training samples are sorted and recursively assigned to a bin until the size of the current bin reaches binSize many samples. Then a new bin is created and so on. For a new test sample we check into which bin its point prediction would have fallen and interpret the training samples of that bin as the empirical distribution function of this test sample.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nModel with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n\n\nbinSize\nint\nNone\nSize of the bins created while running fit.\n\n\nequalBins\nbool\nFalse\nDetermines behaviour of method getWeights. If False, all weights receive the same value. If True, the distance of the point forecasts is taking into account."
  },
  {
    "objectID": "99_unitTests.html",
    "href": "99_unitTests.html",
    "title": "Generate Neighborhoods",
    "section": "",
    "text": "yPred = np.array([1, 3, 6, 10, 15, 21, 28, 36, 45, 55, 66, 78])\nbinSize = 3\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([24]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\ntest_eq(neighborsDictTest[24], [4, 5, 6])\n\nweightsData = getKernelValues(yPred = np.array([24]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\nweights = np.array([2/6, 4/6, 6/6, 4/6, 2/6])\nweights = weights / weights.sum()\nindices = [3, 4, 5, 6, 7]\ntest_eq(weightsData[0][0], weights)\ntest_eq(weightsData[0][1], indices)\n\n#---\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([25.5]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\ntest_eq(neighborsDictTest[25.5], [4, 5, 6, 7])\n\nweightsData = getKernelValues(yPred = np.array([25.5]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\nweights = np.array([2/7, 4/7, 6/7, 6/7, 4/7, 2/7])\nweights = weights / weights.sum()\nindices = [3, 4, 5, 6, 7, 8]\ntest_eq(weightsData[0][0], weights)\ntest_eq(weightsData[0][1], indices)\n\n#---\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([25.54]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\ntest_eq(neighborsDictTest[25.54], [5, 6, 7])\n\nweightsData = getKernelValues(yPred = np.array([25.54]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\nweights = np.array([2/6, 4/6, 6/6, 4/6, 2/6])\nweights = weights / weights.sum()\nindices = [4, 5, 6, 7, 8]\ntest_eq(weightsData[0][0], weights)\ntest_eq(weightsData[0][1], indices)\n\nAfter Loop: Memory used by Jupyter notebook: 192.29 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 192.29 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 192.29 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 192.29 MB\n\n\n\nyPred = np.concatenate([np.arange(3)] * 5, axis = 0)\n\n#-----------------------------------------------------------\n\nbinSize = 5\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12])\ntest_eq(neighborsDictTrain[1], [1, 4, 7, 10, 13])\ntest_eq(neighborsDictTrain[2], [2, 5, 8, 11, 14])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12]\nneighbors1 = [1, 4, 7, 10, 13]\nneighbors2 = [2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n\nweights0 = np.repeat(1/5, 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.array([0, 3, 6, 9, 12])\nweights1 = np.repeat(1/5, 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([1, 4, 7, 10, 13])\nweights2 = np.repeat(1/5, 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.array([2, 5, 8, 11, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n        \n        \nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n        \nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([10 / 15, 10 / 15] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([1, 2, 4, 5, 7, 8, 10, 11, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\n#-----------------------------------------------------------\n\nbinSize = 1\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12])\ntest_eq(neighborsDictTrain[1], [1, 4, 7, 10, 13])\ntest_eq(neighborsDictTrain[2], [2, 5, 8, 11, 14])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12]\nneighbors1 = [1, 4, 7, 10, 13]\nneighbors2 = [2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n        \nweights0 = np.repeat(1/5, 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.array([0, 3, 6, 9, 12])\nweights1 = np.repeat(1/5, 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([1, 4, 7, 10, 13])\nweights2 = np.repeat(1/5, 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.array([2, 5, 8, 11, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n\nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([10 / 15, 10 / 15] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([1, 2, 4, 5, 7, 8, 10, 11, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\n#-----------------------------------------------------------\n\nbinSize = 2\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12])\ntest_eq(neighborsDictTrain[1], [1, 4, 7, 10, 13])\ntest_eq(neighborsDictTrain[2], [2, 5, 8, 11, 14])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12]\nneighbors1 = [1, 4, 7, 10, 13]\nneighbors2 = [2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n\nweights0 = np.repeat(1/5, 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.array([0, 3, 6, 9, 12])\nweights1 = np.repeat(1/5, 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([1, 4, 7, 10, 13])\nweights2 = np.repeat(1/5, 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.array([2, 5, 8, 11, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n\nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([10 / 15, 10 / 15] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([1, 2, 4, 5, 7, 8, 10, 11, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\n#-----------------------------------------------------------\n\nbinSize = 10\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                    yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13])\ntest_eq(neighborsDictTrain[1], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTrain[2], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                     yPred = yPred,\n                                     yPredTrain = yPred,\n                                     neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13]\nneighbors1 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\nneighbors2 = [1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n\nweights0 = np.array([20 / 20, 20 / 25, 10 / 20] * 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.arange(15)\nweights1 = np.array([20 / 25, 30 / 30, 20 / 25] * 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(15)\nweights2 = np.array([10 / 20, 20 / 25, 20 / 20] * 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(15)\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n\nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([10 / 20, 20 / 25, 20 / 20] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\n#-----------------------------------------------------------\n\nbinSize = 8\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13])\ntest_eq(neighborsDictTrain[1], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTrain[2], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\n\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13]\nneighbors1 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\nneighbors2 = [1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n\nweights0 = np.array([20 / 20, 20 / 25, 10 / 20] * 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.arange(15)\nweights1 = np.array([20 / 25, 30 / 30, 20 / 25] * 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(15)\nweights2 = np.array([10 / 20, 20 / 25, 20 / 20] * 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(15)\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n\nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([10 / 20, 20 / 25, 20 / 20] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\n#-----------------------------------------------------------\n\nbinSize = 12\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 1, 2])\n\ntest_eq(neighborsDictTrain[0], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTrain[1], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTrain[2], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 1, 2])\n\nneighbors0 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\nneighbors1 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\nneighbors2 = [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14]\ntest_eq(neighborsDictTest[0], neighbors0)\ntest_eq(neighborsDictTest[1], neighbors1)\ntest_eq(neighborsDictTest[2], neighbors2)\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\nfor i in range(3):\n    for j in range(1, 5, 1):\n        test_eq(weightsData[i][0], weightsData[i + 3*j][0])\n        test_eq(weightsData[i][1], weightsData[i + 3*j][1])\n\nweights0 = np.array([1, 1, 1] * 5)\nweights0 = weights0 / weights0.sum()\nindices0 = np.arange(15)\nweights1 = np.array([1, 1, 1] * 5)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(15)\nweights2 = np.array([1, 1, 1] * 5)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(15)\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights1)\ntest_eq(weightsData[1][1], indices1)\ntest_eq(weightsData[2][0], weights2)\ntest_eq(weightsData[2][1], indices2)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 0.4, 1.5, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 0.4, 1.5, 4])\n\ntest_eq(neighborsDictTest[-1], np.array(neighbors0))\ntest_eq(neighborsDictTest[0.4], np.array(neighbors0))\ntest_eq(neighborsDictTest[1.5], [0, 3, 6, 9, 12, 1, 4, 7, 10, 13, 2, 5, 8, 11, 14])\ntest_eq(neighborsDictTest[4], np.array(neighbors2))\n\nweightsData = getKernelValues(yPred = np.array([-1, 0.4, 1.5, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 4)\n\nweightsTest = np.array([1, 1, 1] * 5)\nweightsTest = weightsTest / weightsTest.sum()\nindicesTest = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14])\n\ntest_eq(weightsData[0][0], weights0)\ntest_eq(weightsData[0][1], indices0)\ntest_eq(weightsData[1][0], weights0)\ntest_eq(weightsData[1][1], indices0)\ntest_eq(weightsData[2][0], weightsTest)\ntest_eq(weightsData[2][1], indicesTest)\ntest_eq(weightsData[3][0], weights2)\ntest_eq(weightsData[3][1], indices2)\n\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Loop: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.67 MB\n\n\n\nyPred = np.array([0, 2, 2, 3, 3, 3])\n\nbinSize = 1\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0])\ntest_eq(neighborsDictTrain[2], [1, 2])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0])\ntest_eq(neighborsDictTest[2], [1, 2])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([1])\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([0])\nweights2 = np.array([1] * 2)\nweights2 = weights2 / weights2.sum()\nindices2 = np.array([1, 2])\nweights3 = np.array([1] * 3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.array([3, 4, 5])\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0])\ntest_eq(neighborsDictTest[4], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\n#-----------------------------------------------------------\n\nbinSize = 2\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0, 1, 2])\ntest_eq(neighborsDictTrain[2], [1, 2])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0, 1, 2])\ntest_eq(neighborsDictTest[2], [1, 2])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([6 / 6] + [4 / 5]*2)\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([0, 1, 2])\nweights2 = np.array([4 / 5] + [4 / 4]*2)\nweights2 = weights2 / weights2.sum()\nindices2 = np.array([0, 1, 2])\nweights3 = np.array([1] * 3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.array([3, 4, 5])\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0, 1, 2])\ntest_eq(neighborsDictTest[4], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\n#-----------------------------------------------------------\n\nbinSize = 3\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0, 1, 2])\ntest_eq(neighborsDictTrain[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0, 1, 2])\ntest_eq(neighborsDictTest[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([6 / 6] + [4 / 8]*2)\nweights1 = weights1 / weights1.sum()\nindices1 = np.array([0, 1, 2])\nweights2 = np.array([4 / 8] + [10 / 10]*2 + [6 / 8]*3)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(6)\nweights3 = np.array([6 / 8]*2 + [6 / 6]*3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.array([1, 2, 3, 4, 5])\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0, 1, 2])\ntest_eq(neighborsDictTest[4], [3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\n#-----------------------------------------------------------\n\nbinSize = 4\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([12/12] + [10/11]*2 + [10/11]*3)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(6)\nweights2 = np.array([10 / 11] + [10 / 10]*2 + [10 / 10]*3)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(6)\nweights3 = np.array([10 / 11] + [10 / 10]*2 + [10 / 10]*3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.arange(6)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[4], [1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\n#-----------------------------------------------------------\n\nbinSize = 5\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([12/12] + [10/11]*2 + [10/11]*3)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(6)\nweights2 = np.array([10 / 11] + [10 / 10]*2 + [10 / 10]*3)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(6)\nweights3 = np.array([10 / 11] + [10 / 10]*2 + [10 / 10]*3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.arange(6)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[4],  [1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\n#-----------------------------------------------------------\n\nbinSize = 6\n\nneighborsDictTrain, neighborsRemoved, neighborsAdded = getNeighbors(binSize = binSize, \n                                                                                   yPred = yPred)\n\ntest_eq(list(neighborsDictTrain.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTrain[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [0, 1, 2, 3, 4, 5])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 2, 3])\n\ntest_eq(neighborsDictTest[0], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [0, 1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = yPred,\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), len(yPred))\n\ntest_eq(weightsData[1][0], weightsData[2][0])\ntest_eq(weightsData[1][1], weightsData[2][1])\ntest_eq(weightsData[3][0], weightsData[4][0])\ntest_eq(weightsData[3][1], weightsData[4][1])\ntest_eq(weightsData[3][0], weightsData[5][0])\ntest_eq(weightsData[3][1], weightsData[5][1])\n\nweights1 = np.array([1] + [1]*2 + [1]*3)\nweights1 = weights1 / weights1.sum()\nindices1 = np.arange(6)\nweights2 = np.array([1] + [1]*2 + [1]*3)\nweights2 = weights2 / weights2.sum()\nindices2 = np.arange(6)\nweights3 = np.array([1] + [1]*2 + [1]*3)\nweights3 = weights3 / weights3.sum()\nindices3 = np.arange(6)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights2)\ntest_eq(weightsData[1][1], indices2)\ntest_eq(weightsData[3][0], weights3)\ntest_eq(weightsData[3][1], indices3)\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([-1, 4]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [-1, 4])\n\ntest_eq(neighborsDictTest[-1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[4],  [0, 1, 2, 3, 4, 5])\n\nweightsData = getKernelValues(yPred = np.array([-1, 4]),\n                              yPredTrain = yPred,\n                              neighborsDictTest = neighborsDictTest,\n                              neighborsDictTrain = neighborsDictTrain,\n                              neighborsRemoved = neighborsRemoved,\n                              neighborsAdded = neighborsAdded,\n                              binSize = binSize,\n                              efficientRAM = False)\n\ntest_eq(len(weightsData), 2)\n\ntest_eq(weightsData[0][0], weights1)\ntest_eq(weightsData[0][1], indices1)\ntest_eq(weightsData[1][0], weights3)\ntest_eq(weightsData[1][1], indices3)\n\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 194.71 MB\n\n\n\nyPred = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])\n\nbinSize = 1\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0])\ntest_eq(neighborsDictTrain[2], [1, 2])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\ntest_eq(neighborsDictTrain[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0])\ntest_eq(neighborsDictTest[2], [1, 2])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\ntest_eq(neighborsDictTest[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0])\ntest_eq(neighborsDictTest[5],  [6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [6, 7, 8, 9])\n\n#---\n\nbinSize = 2\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2])\ntest_eq(neighborsDictTrain[2], [1, 2])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\ntest_eq(neighborsDictTrain[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2])\ntest_eq(neighborsDictTest[2], [1, 2])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\ntest_eq(neighborsDictTest[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2])\ntest_eq(neighborsDictTest[5],  [6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [6, 7, 8, 9])\n\n#---\n\nbinSize = 3\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [3, 4, 5])\ntest_eq(neighborsDictTrain[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [3, 4, 5])\ntest_eq(neighborsDictTest[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2])\ntest_eq(neighborsDictTest[5],  [6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [6, 7, 8, 9])\n\n#---\n\nbinSize = 4\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[5],  [6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [6, 7, 8, 9])\n\n#---\n\nbinSize = 5\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[5],  [3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [3, 4, 5, 6, 7, 8, 9])\n\n#---\n\nbinSize = 6\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5])\ntest_eq(neighborsDictTest[5],  [3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [3, 4, 5, 6, 7, 8, 9])\n\n#---\n\nbinSize = 7\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[5],  [3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [3, 4, 5, 6, 7, 8, 9])\n\n#---\n\nbinSize = 8\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[5],  [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n#---\n\nbinSize = 9\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[3], [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[5],  [1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\n#---\n\nbinSize = 10\n\nneighborsDictTrain = getNeighbors(binSize = binSize, \n                                            yPred = yPred)[0]\n\ntest_eq(list(neighborsDictTrain.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTrain[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTrain[4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = yPred,\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [1, 2, 3, 4])\n\ntest_eq(neighborsDictTest[1], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[2], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[4], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\n\nneighborsDictTest = getNeighborsTest(binSize = binSize,\n                                                    yPred = np.array([0, 5, 10]),\n                                                    yPredTrain = yPred,\n                                                    neighborsDictTrain = neighborsDictTrain)\n\ntest_eq(list(neighborsDictTest.keys()), [0, 5, 10])\n\ntest_eq(neighborsDictTest[0],  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[5],  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntest_eq(neighborsDictTest[10], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB\nAfter Loop: Memory used by Jupyter notebook: 194.71 MB"
  },
  {
    "objectID": "99_unitTests.html#lsx-nn-kernel",
    "href": "99_unitTests.html#lsx-nn-kernel",
    "title": "Generate Neighborhoods",
    "section": "LSx NN Kernel",
    "text": "LSx NN Kernel\n\nBrute Force Version\n\nclass LevelSetKDEx_NN_bruteForce(BaseWeightsBasedEstimator, BaseLSx):\n    \"\"\"\n     `LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n    into an estimator of the condititional density of the underlying distribution.\n    The basic idea of each level-set based approach is to interprete the point forecast\n    generated by the underlying point predictor as a similarity measure of samples.\n    In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n    'binSize'-many training samples are computed whose point forecast is closest\n    to the point forecast of the new sample.\n    The resulting empirical distribution of these 'nearest' training samples are \n    viewed as our estimation of the conditional distribution of each the new sample \n    at hand.\n    \n    NOTE: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n    `LevelSetKDEx_kNN` to arbitrary dimensional point predictors.\n    \"\"\"\n    \n    def __init__(self, \n                 estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n                 binSize: int=None, # Size of the bins created while running fit.\n                 ):\n        \n        super(BaseEstimator, self).__init__(estimator = estimator)\n        \n        self.binSize = binSize\n        self.yTrain = None\n        self.yPredTrain = None\n        self.nearestNeighborsOnPreds = None\n        self.fitted = False\n        \n    #---\n    \n    def fit(self: LevelSetKDEx, \n            X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n            y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n            ):\n        \"\"\"\n        Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n        predictions of the samples specified by `X` based on `estimator`. \n        \"\"\"\n        \n        # Checks\n        if self.binSize is None:\n            raise ValueError(\"'binSize' must be specified to fit the LSx estimator!\")\n            \n        if self.binSize &gt; y.shape[0]:\n            raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n            \n        if X.shape[0] != y.shape[0]:\n            raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n            \n        # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n        # problems later on.\n        if isinstance(y, pd.Series):\n            y = y.ravel()\n        \n        #---\n        \n        try:\n            yPred = self.estimator.predict(X)\n            \n        except NotFittedError:\n            try:\n                self.estimator.fit(X = X, y = y)                \n            except:\n                raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n            else:\n                yPred = self.estimator.predict(X)\n\n        #---\n        \n        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n        \n        nn = NearestNeighbors(algorithm = 'kd_tree')\n        nn.fit(X = yPred_reshaped)\n        \n        distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n                                                         n_neighbors = self.binSize + 1)\n        \n        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n        distanceCheck = np.where(distancesMatrix[:, self.binSize - 1] == distancesMatrix[:, self.binSize])\n        indicesToMod = distanceCheck[0]\n\n        for index in indicesToMod:\n            distanceExtremePoint = np.absolute(yPred[index] - yPred[neighborsMatrixTrain[index, self.binSize-1]])\n\n            neighborsByRadius = nn.radius_neighbors(X = yPred_reshaped[index:index + 1], \n                                                    radius = distanceExtremePoint, \n                                                    return_distance = False)[0]\n            neighborsList[index] = neighborsByRadius\n\n        #---\n\n        self.yTrain = y\n        self.yPredTrain = yPred\n        self.yTrainNeighborsList = neighborsList\n        self._nearestNeighborsOnPreds = nn\n        self._fitted = True\n        \n    #---\n    \n    def getWeights(self, \n                   X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n                   # Specifies structure of the returned density estimates. One of: \n                   # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n                   outputType: str='onlyPositiveWeights', \n                   # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n                   # density of each sample for scaling purposes.\n                   scalingList: list=None, \n                   ) -&gt; list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n        \n        __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n        \n        if not self._fitted:\n            raise NotFittedError(\"This LevelSetKDEx_kNN instance is not fitted yet. Call 'fit' with \"\n                                 \"appropriate arguments before trying to compute weights.\")\n            \n        #---\n        \n        neighborsListTrain = self.yTrainNeighborsList\n        nn = self._nearestNeighborsOnPreds\n        \n        #---\n        \n        yPred = self.estimator.predict(X)   \n        yPred_reshaped = np.reshape(yPred, newshape = (len(yPred), 1))\n\n        distancesMatrix, neighborsMatrix = nn.kneighbors(X = yPred_reshaped, \n                                                         n_neighbors = self.binSize + 1)\n        \n        neighborsList = list(neighborsMatrix[:, 0:self.binSize])\n        distanceCheck = np.where(distancesMatrix[:, self.binSize - 1] == distancesMatrix[:, self.binSize])\n        indicesToMod = distanceCheck[0]\n\n        for index in indicesToMod:\n            distanceExtremePoint = np.absolute(yPred[index] - self.yPredTrain[neighborsMatrix[index, self.binSize-1]])\n\n            neighborsByRadius = nn.radius_neighbors(X = yPred_reshaped[index:index + 1], \n                                                    radius = distanceExtremePoint, return_distance = False)[0]\n            neighborsList[index] = neighborsByRadius\n        \n        #---\n        \n        weightsDataList = list()\n        \n        for neighbors in neighborsList:\n            \n            weights = list()\n            indicesPosWeight = list()\n            \n            for i in range(len(neighborsListTrain)):\n                weight = 2 * len(set(neighbors) & set(neighborsListTrain[i])) / (len(neighbors) + len(neighborsListTrain[i]))\n                \n                if weight &gt; 0:\n                    weights.append(weight)\n                    indicesPosWeight.append(i)\n            \n            weights = np.array(weights) / sum(weights)\n            weightsDataList.append((weights, np.array(indicesPosWeight)))\n                            \n        weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n                                                     outputType = outputType, \n                                                     y = self.yTrain,\n                                                     scalingList = scalingList,\n                                                     equalWeights = True)\n\n        return weightsDataList\n\n\nLSKDEx_NN_bruteForce = LevelSetKDEx_NN_bruteForce(binSize = 4,\n                                                  estimator = LGBM)\n\nLSKDEx_NN_bruteForce.fit(XTrain, yTrain)\nweightsDataBruteForce = LSKDEx_NN_bruteForce.getWeights(XTest)\n\n\nLSKDEx_NN = LevelSetKDEx_NN(binSize = 4,\n                            estimator = LGBM)\n\nLSKDEx_NN.fit(XTrain, yTrain)\nweightsData = LSKDEx_NN.getWeights(XTest)\n\nAfter Loop: Memory used by Jupyter notebook: 330.02 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 365.29 MB\n\n\n\nfor i in range(XTest.shape[0]):\n    assert np.array_equal(weightsDataBruteForce[i][0], weightsData[i][0])\n    assert np.array_equal(weightsDataBruteForce[i][1], weightsData[i][1])\n\n\n\nEfficientRAM Algorithm\n\nLSKDEx_NN = LevelSetKDEx_NN(binSize = 500,\n                            estimator = LGBM,\n                            efficientRAM = False)\n\nLSKDEx_NN.fit(XTrain, yTrain)\n\nLSKDEx_NN2 = LevelSetKDEx_NN(binSize = 500,\n                             estimator = LGBM,\n                             efficientRAM = True)\n\nLSKDEx_NN2.fit(XTrain, yTrain)\n\nAfter Loop: Memory used by Jupyter notebook: 365.55 MB\nAfter Loop: Memory used by Jupyter notebook: 365.55 MB\n\n\n\nweightsData = LSKDEx_NN.getWeights(XTest)\nweightsDataEfficient = LSKDEx_NN2.getWeights(XTest)\n\ntest_eq(len(weightsData), len(weightsDataEfficient))\n\nAfter Kernel Values: Memory used by Jupyter notebook: 376.37 MB\nAfter Kernel Values: Memory used by Jupyter notebook: 394.26 MB\n\n\n\nfor i in range(XTest.shape[0]):\n    weights = weightsData[i][0]\n    indices = weightsData[i][1]\n    \n    weightsEfficient = weightsDataEfficient[i][0]\n    indicesEfficient = weightsDataEfficient[i][1]\n    \n    sortedIndices = np.argsort(indicesEfficient)\n    weightsEfficient = weightsEfficient[sortedIndices]\n    indicesEfficient = indicesEfficient[sortedIndices]\n    \n    assert np.allclose(weights, weightsEfficient)\n    test_eq(indices, indicesEfficient)\n    \n    assert np.allclose(weights.sum(), 1)\n    assert np.allclose(weightsEfficient.sum(), 1)\n\n\ni\n\n1273\n\n\n\nweights[0:10]\n\narray([0.00214096, 0.00053643, 0.00069308, 0.00026109, 0.00100165,\n       0.00121527, 0.00155232, 0.00036078, 0.00236882, 0.00020887])\n\n\n\nweightsEfficient[0:10]\n\narray([0.00214096, 0.00053643, 0.00069308, 0.00026109, 0.00100165,\n       0.00121527, 0.00155232, 0.00036078, 0.00236882, 0.00020887])"
  },
  {
    "objectID": "99_unitTests.html#saa",
    "href": "99_unitTests.html#saa",
    "title": "Generate Neighborhoods",
    "section": "SAA",
    "text": "SAA\n\nSAA = SampleAverageApproximation()\n\n\nSAA.fit(y = np.arange(100))\nweightsData = SAA.getWeights(outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsData), 1)\ntest_eq(weightsData[0][0], np.repeat(0.01, 100))\ntest_eq(weightsData[0][1], np.arange(100))\n\nweightsData = SAA.getWeights(X = np.identity(10))\ntest_eq(len(weightsData), 10)\n\nfor i in range(10):\n    assert np.array_equal(weightsData[i][0], weightsData[0][0])\n    assert np.array_equal(weightsData[i][1], weightsData[0][1])\n\n\nSAA.fit(y = np.repeat(np.arange(10), 2))\nweightsData = SAA.getWeights(outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsData), 1)\ntest_eq(weightsData[0][0], np.repeat(0.05, 20))\ntest_eq(weightsData[0][1], np.arange(20))\n\nweightsData = SAA.getWeights(X = np.identity(10))\ntest_eq(len(weightsData), 10)\n\nfor i in range(10):\n    assert np.array_equal(weightsData[i][0], weightsData[0][0])\n    assert np.array_equal(weightsData[i][1], weightsData[0][1])"
  },
  {
    "objectID": "99_unitTests.html#loading-yaz-data",
    "href": "99_unitTests.html#loading-yaz-data",
    "title": "Generate Neighborhoods",
    "section": "Loading Yaz Data",
    "text": "Loading Yaz Data\n\ntestDays = 182\ndaysToCut = 300\n\ndata, XTrain, yTrain, XTest, yTest = loadDataYaz(returnXY = True)\nscalingList = data.loc[data['label'] == 'test', 'scalingValue'].tolist()\n\n\nassert XTest.shape[0] == len(data['id'].unique()) * testDays \nassert yTest.shape[0] == len(data['id'].unique()) * testDays\n\nassert XTrain.shape[0] == data.shape[0] - len(data['id'].unique()) * testDays\nassert yTrain.shape[0] == data.shape[0] - len(data['id'].unique()) * testDays"
  },
  {
    "objectID": "99_unitTests.html#grouped-time-series-split",
    "href": "99_unitTests.html#grouped-time-series-split",
    "title": "Generate Neighborhoods",
    "section": "Grouped Time Series Split",
    "text": "Grouped Time Series Split\n\nnIDs = len(data['id'].unique())\nkFolds = 4\ntestLength = 7\ntimeFeature = 'dayIndex'\ngroupFeature = 'id'\n\ncvFolds = groupedTimeSeriesSplit(data = data, \n                                 kFolds = kFolds, \n                                 testLength = testLength, \n                                 groupFeature = groupFeature, \n                                 timeFeature = timeFeature)\n\ntest_eq(len(cvFolds), 4)\n\nfor i in range(len(cvFolds)):\n    fold = cvFolds[i]\n    \n    test_eq(len(fold[1]), testLength * nIDs)\n    test_eq(len(fold[0]), (data.shape[0] - nIDs * testLength * (kFolds - i - 1)) - len(fold[1]))\n    test_eq(len(set(fold[0]) & set(fold[1])), 0)\n    \n    dataTrainToCheck = data.iloc[fold[0]]\n    dataTestToCheck = data.iloc[fold[1]]\n    \n    timeMaxGroupTrain = dataTrainToCheck.groupby(groupFeature)[timeFeature].max()\n    timeMinGroupTest = dataTestToCheck.groupby(groupFeature)[timeFeature].min()\n    \n    assert (timeMaxGroupTrain &lt; timeMinGroupTest).all()\n\n\nLGBM = LGBMRegressor(max_depth = 4, n_jobs = 1)\nLGBM.fit(X = XTrain, y = yTrain)\n\nLGBMRegressor(max_depth=4, n_jobs=1)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LGBMRegressorLGBMRegressor(max_depth=4, n_jobs=1)"
  },
  {
    "objectID": "99_unitTests.html#cross-validation",
    "href": "99_unitTests.html#cross-validation",
    "title": "Generate Neighborhoods",
    "section": "Cross-Validation",
    "text": "Cross-Validation\n\nfrom sklearn.model_selection import ParameterGrid\n\nyPredTrain = LGBM.predict(XTrain)\nyTestPred = LGBM.predict(XTest)\n\ndataTrain = data[data['label'] == 'train']\n\n\nWasserstein Distance\n\n# ONE DIMENSIONAL TARGET VALUES\ndensities = [(np.array([0.4, 0.6]), np.array([2, 4])), \n             (np.array([0.5, 0.5]), np.array([3, 6]))]\n\ny = np.array([3, 4])\n\nwassersteinDists = getWassersteinDistances(densities = densities, \n                                           yTest = y, \n                                           p = 1)\n\ndistsByHand = np.array([0.4 * 1 + 0.6 * 1, 0.5 * 1 + 0.5 * 2])\n\nassert np.allclose(wassersteinDists, distsByHand)\n\n#---\n\n# MULTI DIMENSIONAL TARGET VALUES\ndensities = [(np.array([0.4, 0.6]), np.array([[2, 4], [4, 4]])), \n             (np.array([0.5, 0.5]), np.array([[3, 6], [2, 3]]))]\n\ny = np.array([[3, 4], \n              [4, 2]])\n\nwassersteinDists = getWassersteinDistances(densities = densities, \n                                           yTest = y,\n                                           p = 1)\n\ndistsByHand = np.array([0.4 * (1 + 0) + 0.6 * (1 + 0), \n                        0.5 * (1 + 4) + 0.5 * (2 + 1)])\n\nassert np.allclose(wassersteinDists, distsByHand)\n\n\n\nCross Validation - General Quantile Predictors\n\nLSKDEx as Estimator\n\nLSKDEx = LevelSetKDEx(estimator = LGBM,\n                      weightsByDistance = False)\n\nkFolds = 2\ncvFolds = groupedTimeSeriesSplit(data = dataTrain, \n                                 kFolds = kFolds, \n                                 testLength = 28, \n                                 groupFeature = 'id', \n                                 timeFeature = 'dayIndex')\n\nprobs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\nparameters = {'binSize': [100, 1000],\n              'weightsByDistance': [False]}\n\nparameterGrid = ParameterGrid(parameters)\n\nCV = QuantileCrossValidation(estimator = LSKDEx, \n                             parameterGrid = parameters,\n                             cvFolds = cvFolds, \n                             probs = probs,\n                             refitPerProb = True,\n                             n_jobs = None)\n\nCV.fit(X = XTrain, y = yTrain)\n\nresIndex = [(100, False), (1000, False)]\n\n#---\n\ntest_eq(CV.cvFolds, cvFolds)\ntest_eq(CV.probs, probs)\nassert CV.refitPerProb\n\n#---\n\n# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n# LGBM == LGBM2 consequently only returns true when both names are refering to \n# the exact same object in memory, which shouldn't be the case here because we \n# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n# should be copies of each other though.\nassert CV.estimator.estimator is not LGBM\ntest_eq(CV.estimator.estimator.predict(XTrain), LGBM.predict(XTrain))\ntest_eq(CV.estimator.estimator.predict(XTest), LGBM.predict(XTest))\n\n#---\n\n# CV results raw\nassert isinstance(CV.cvResults_raw, list)\ntest_eq(len(CV.cvResults_raw), kFolds)\n\nfor resDf in CV.cvResults_raw:\n    test_eq(resDf.shape, (len(resIndex), len(probs)))\n    test_eq(list(resDf.index), resIndex)\n    test_eq(resDf.columns, probs)\n    assert np.all(resDf &gt;= 0)\n    \n#---\n\n# CV results aggregated\nmeanCostMatrix = 0\nfor i in range(0, kFolds, 1):\n    meanCostMatrix += CV.cvResults_raw[i]\n    \nmeanCostMatrix = meanCostMatrix / kFolds\n\nassert np.allclose(CV.cvResults, meanCostMatrix)\n\ntest_eq(CV.cvResults.shape, (len(resIndex), len(probs)))\ntest_eq(list(CV.cvResults.index), resIndex)\ntest_eq(CV.cvResults.columns, probs)\nassert np.all(resDf &gt;= 0)\n\n#---\n\n# BEST PARAMETER SETTING\naverageCostsPerParam = CV.cvResults.mean(axis = 1)\nparamsBestTest = CV.cvResults.index[np.argmin(averageCostsPerParam)]\nparamsBestTest = dict(zip(CV.cvResults.index.names, paramsBestTest))\ntest_eq(CV.bestParams, paramsBestTest)\nassert CV.bestParams in parameterGrid\n\n#---\n\n# BEST PARAMETER SETTING PER PROB\ntest_eq(len(CV.bestParams_perProb), len(probs))\nassert all([params in parameterGrid for params in CV.bestParams_perProb.values()])\n\nparamsBestPerProbTest = CV.cvResults.idxmin(axis = 0)\nparamsBestPerProbTest = {prob: dict(zip(CV.cvResults.index.names, paramsBestPerProbTest.loc[prob])) for prob in probs}\ntest_eq(CV.bestParams_perProb, paramsBestPerProbTest)\n\n#---\n\n# REFITTED QUANTILE ESTIMATOR\nassert isinstance(CV.bestEstimator, LevelSetKDEx)\ntest_eq(CV.bestEstimator.binSize, paramsBestTest['binSize'])\n\n# Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n# LGBM == LGBM2 consequently only returns true when both names are refering to \n# the exact same object in memory, which is not (!!) the case here)\nassert CV.bestEstimator.estimator is not LGBM\ntest_eq(CV.bestEstimator.estimator.predict(XTrain), LGBM.predict(XTrain))\ntest_eq(CV.bestEstimator.estimator.predict(XTest), LGBM.predict(XTest))\n\n#---\n\nfor prob in probs:\n    estimator = CV.bestEstimator_perProb[prob]\n    test_eq(estimator.binSize, paramsBestPerProbTest[prob]['binSize'])\n\n\n\nLSKDEx_kNN as Estimator\n\nLSKDEx = LevelSetKDEx_kNN(estimator = LGBM,\n                          weightsByDistance = False)\n\nkFolds = 2\ncvFolds = groupedTimeSeriesSplit(data = dataTrain, \n                                 kFolds = kFolds, \n                                 testLength = 28, \n                                 groupFeature = 'id', \n                                 timeFeature = 'dayIndex')\n\nprobs = [0.001, 0.01, 0.1, 0.5, 0.9, 0.99, 0.999]\nparameters = {'binSize': [100, 1000],\n              'weightsByDistance': [True]}\n\nparameterGrid = ParameterGrid(parameters)\n\nCV = QuantileCrossValidation(estimator = LSKDEx, \n                             parameterGrid = parameters,\n                             cvFolds = cvFolds, \n                             probs = probs,\n                             refitPerProb = True,\n                             n_jobs = None)\n\nCV.fit(X = XTrain, y = yTrain)\n\nresIndex = [(100, True), (1000, True)]\n\n#---\n\ntest_eq(CV.cvFolds, cvFolds)\ntest_eq(CV.probs, probs)\nassert CV.refitPerProb\n\n#---\n\n# Estimator the same? Note: No __eq__ method is implemented for LGBMRegressor. \n# LGBM == LGBM2 consequently only returns true when both names are refering to \n# the exact same object in memory, which shouldn't be the case here because we \n# create a deepcopy of LGBM when initiating LS_KDEx. The point estimators\n# should be copies of each other though.\nassert CV.estimator.estimator is not LGBM\ntest_eq(CV.estimator.estimator.predict(XTrain), LGBM.predict(XTrain))\ntest_eq(CV.estimator.estimator.predict(XTest), LGBM.predict(XTest))\n\n#---\n\n# CV results raw\nassert isinstance(CV.cvResults_raw, list)\ntest_eq(len(CV.cvResults_raw), kFolds)\n\nfor resDf in CV.cvResults_raw:\n    test_eq(resDf.shape, (len(resIndex), len(probs)))\n    test_eq(list(resDf.index), resIndex)\n    test_eq(resDf.columns, probs)\n    assert np.all(resDf &gt;= 0)\n    \n#---\n\n# CV results aggregated\nmeanCostMatrix = 0\nfor i in range(0, kFolds, 1):\n    meanCostMatrix += CV.cvResults_raw[i]\n    \nmeanCostMatrix = meanCostMatrix / kFolds\n\nassert np.allclose(CV.cvResults, meanCostMatrix)\n\ntest_eq(CV.cvResults.shape, (len(resIndex), len(probs)))\ntest_eq(list(CV.cvResults.index), resIndex)\ntest_eq(CV.cvResults.columns, probs)\nassert np.all(resDf &gt;= 0)\n\n#---\n\n# BEST PARAMETER SETTING\naverageCostsPerParam = CV.cvResults.mean(axis = 1)\nparamsBestTest = CV.cvResults.index[np.argmin(averageCostsPerParam)]\nparamsBestTest = dict(zip(CV.cvResults.index.names, paramsBestTest))\ntest_eq(CV.bestParams, paramsBestTest)\nassert CV.bestParams in parameterGrid\n\n#---\n\n# BEST PARAMETER SETTING PER PROB\ntest_eq(len(CV.bestParams_perProb), len(probs))\nassert all([params in parameterGrid for params in CV.bestParams_perProb.values()])\n\nparamsBestPerProbTest = CV.cvResults.idxmin(axis = 0)\nparamsBestPerProbTest = {prob: dict(zip(CV.cvResults.index.names, paramsBestPerProbTest.loc[prob])) for prob in probs}\ntest_eq(CV.bestParams_perProb, paramsBestPerProbTest)\n\n#---\n\n# REFITTED QUANTILE ESTIMATOR\nassert isinstance(CV.bestEstimator, LevelSetKDEx_kNN)\ntest_eq(CV.bestEstimator.binSize, paramsBestTest['binSize'])\n\n# Estimator the same? (Note: No __eq__ method is implemented for LGBMRegressor. \n# LGBM == LGBM2 consequently only returns true when both names are refering to \n# the exact same object in memory, which is not (!!) the case here)\nassert CV.bestEstimator.estimator is not LGBM\ntest_eq(CV.bestEstimator.estimator.predict(XTrain), LGBM.predict(XTrain))\ntest_eq(CV.bestEstimator.estimator.predict(XTest), LGBM.predict(XTest))\n\n#---\n\nfor prob in probs:\n    estimator = CV.bestEstimator_perProb[prob]\n    test_eq(estimator.binSize, paramsBestPerProbTest[prob]['binSize'])"
  },
  {
    "objectID": "99_unitTests.html#ls_kdex",
    "href": "99_unitTests.html#ls_kdex",
    "title": "Generate Neighborhoods",
    "section": "LS_KDEx",
    "text": "LS_KDEx\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\nLS_KDEx.fit(XTrain, yTrain)\n\n# Check if nothing weird happened to y and yPred\ntest_eq(LS_KDEx.yTrain, yTrain)\ntest_eq(LS_KDEx.yPredTrain, LGBM.predict(XTrain))\n\n# Check if fitted has been set correctly\nassert LS_KDEx.fitted\n\n\nStandard Attributes\n\n# All train-indices must be part of indicesPerBin\n# and duplicates mustn't exist\nindicesList = list()\n\nfor values in LS_KDEx.indicesPerBin.values():\n    indicesList.extend(values)\n    \ntest_eq(set(indicesList), set(np.arange(XTrain.shape[0])))\ntest_eq(len(indicesList), XTrain.shape[0])\n\n\n\nLower Bounds\n\n# Lower-bound structure has to be correct\nyPred = LS_KDEx.yPredTrain\nindicesPerBin = LS_KDEx.indicesPerBin\nlowerBoundPerBin = LS_KDEx.lowerBoundPerBin\n\nfor i in range(len(indicesPerBin)):\n    binIndex = list(indicesPerBin.keys())[i]\n    indices = indicesPerBin[binIndex]\n    \n    minValue = yPred[indices].min()\n    maxValue = yPred[indices].max()\n    \n    assert minValue &gt;= lowerBoundPerBin.loc[binIndex]\n    \n    if binIndex &lt; max(list(indicesPerBin.keys())):\n        assert maxValue &lt; lowerBoundPerBin.loc[binIndex + 1]\n\n\n\ngetWeights\n\nStandard Settings\n\n# Weights-Output Test\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\nLS_KDEx.fit(XTrain, yTrain)\n\n#---\n\nindicesPerBin = LS_KDEx.indicesPerBin\nlowerBoundPerBin = LS_KDEx.lowerBoundPerBin\nyPredTrain = LGBM.predict(XTrain)\nyPredTest = LGBM.predict(XTest)\nbinPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\nindicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n\n#---\n\nweightsAll = LS_KDEx.getWeights(X = XTest, outputType = 'all')\n\n# Check if every bin contains at least 100 observations\nbinSizesReal = [sum(weightsAll[i] &gt; 0) for i in range(XTest.shape[0])]\nassert (np.array(binSizesReal) &gt;= 100).all()\n\ntest_eq(len(weightsAll), XTest.shape[0])\n\nfor i in range(len(weightsAll)):\n    weights = weightsAll[i]\n    \n    assert all(weights &gt;= 0)\n    assert isclose(weights.sum(), 1)\n    \n    test_eq(np.where(weights &gt; 0)[0], np.sort(indicesPerPred[i]))\n\n#---\n\nweightsOnlyPos = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\n# Check if every bin contains at least 100 observations\nbinSizesReal = [len(weightsOnlyPos[i][1]) for i in range(XTest.shape[0])]\nassert (np.array(binSizesReal) &gt;= 100).all()\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    weights = weightsOnlyPos[i][0]\n    indices = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    test_eq(indices, indicesPerPred[i])\n    \n    if len(indices) &gt; 100:\n        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n        assert checkLastBin or checkBinExtension\n        \n#---\n\nweightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized')\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(yTrain[indicesPerPred[i]]), set(values))\n    \n#---\n\nweightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n\n# Check if every bin contains at least 100 observations\nbinSizesReal = [len(weightsCumDistr[i][1]) for i in range(XTest.shape[0])]\nassert (np.array(binSizesReal) &gt;= 100).all()\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n    \n    test_eq(values, np.sort(yTrain[indicesPerPred[i]]))\n\n#---\n\nweightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]])))\n\n\n\nDistance Based Weights\n\n# Weights-Output Test\n\n# Modifying XTrain to enforce test-predictions being identical to train predictions\nXTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\nyTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = True)\nLS_KDEx.fit(XTrainMod, yTrainMod)\n\n#---\n\nindicesPerBin = LS_KDEx.indicesPerBin\nlowerBoundPerBin = LS_KDEx.lowerBoundPerBin\nyPredTrain = LGBM.predict(XTrainMod)\nyPredTest = LGBM.predict(XTest)\nbinPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\nindicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n\npredDistances = [np.abs(yPredTrain[indicesPerPred[i]] - yPredTest[i]) for i in range(XTest.shape[0])]\n\n#---\n\nweightsList = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\n# Check if all bins either contain at least 100 observations or if not all weights have to equal\nbinSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\n\nfor i in range(len(binSizesReal)):\n    if binSizesReal[i] &lt; 100:\n        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n        \n# Because of our above modification of XTrain and yTrain, for the first and second test observation \n# the special case applies where the test prediction is identical to at least 1 train prediction.\nassert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\nassert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n\nassert 0 in weightsList[0][1]\nassert 1 in weightsList[1][1]\n\n#---\n\nweightsAll = LS_KDEx.getWeights(X = XTest, outputType = 'all')\n\ntest_eq(len(weightsAll), XTest.shape[0])\n\nfor i in range(len(weightsAll)):\n    neighbors = indicesPerPred[i]\n    distances = predDistances[i]\n    weights = weightsAll[i]\n    \n    assert all(weights &gt;= 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights &gt; 0)[0]))\n        \n    else:\n        inverseDistances = 1 / distances\n        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n        test_eq(np.sort(neighbors), np.sort(np.where(weights &gt; 0)[0]))\n\n#---\n\nweightsOnlyPos = LS_KDEx.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    neighbors = indicesPerPred[i]\n    distances = predDistances[i]\n    weights = weightsOnlyPos[i][0]\n    indices = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n            \n    else:\n        inverseDistances = 1 / distances\n        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n        test_eq(np.sort(neighbors), np.sort(indices))\n    \n    if len(indices) &gt; 100:\n        checkLastBin = yPredTrain.max() == yPredTrain[indices].max()\n        checkBinExtension = yPredTrain[indices[99]] == yPredTrain[indices[100]]\n        assert checkLastBin or checkBinExtension\n    \n#---\n\nweightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized')\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    neighbors = indicesPerPred[i]\n    distances = predDistances[i]\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n            \n    else:\n        valuesByHand = yTrainMod[neighbors]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(valuesByHand), set(values))\n    \n#---\n\nweightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    neighbors = indicesPerPred[i]\n    distances = predDistances[i]\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n        nCloseZero = sum(predDistanceCloseZero)\n        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n        \n    else:\n        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n        # cumulated distribution function, but it has for the exact value testing we are doing here.\n        inverseDistances = 1 / distances\n        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n        valuesByHandIndicesSort = np.argsort(valuesByHand)\n        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n    \n    test_eq(values, np.sort(values))\n    test_eq(np.sort(valuesByHand), values)\n\n#---\n\nweightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    neighbors = indicesPerPred[i]\n    distances = predDistances[i]\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n    \n    else:\n        inverseDistances = 1 / distances\n        valuesByHand = yTrainMod[neighbors]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(values, np.sort(values))\n    test_eq(set(valuesByHand), set(values))\n\n\n\nScalingList\n\n# Testing scalingList \n\nLS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\nLS_KDEx.fit(XTrain, yTrain)\n\n#---\n\nindicesPerBin = LS_KDEx.indicesPerBin\nlowerBoundPerBin = LS_KDEx.lowerBoundPerBin\nyPredTest = LGBM.predict(XTest)\nbinPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\nindicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\n\n#---\n\nweightsSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(yTrain[indicesPerPred[i]] * scalingList[i]), set(values))\n    \n#---\n\nweightsCumDistr = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    \n    test_eq(values, np.sort(yTrain[indicesPerPred[i]]) * scalingList[i])\n\n#---\n\nweightsDistrSummarized = LS_KDEx.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(values), set(np.sort(yTrain[indicesPerPred[i]]) * scalingList[i]))\n\n\n\npredict\n\n# Testing predict-method\nLS_KDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\nLS_KDEx.fit(XTrain, yTrain)\n\n#---\n\nindicesPerBin = LS_KDEx.indicesPerBin\nlowerBoundPerBin = LS_KDEx.lowerBoundPerBin\nyPredTest = LGBM.predict(XTest)\nbinPerPred = np.searchsorted(a = lowerBoundPerBin, v = yPredTest, side = 'right') - 1\nindicesPerPred = [indicesPerBin[binIndex] for binIndex in binPerPred]\nyTrainPerPred = [yTrain[indices] for indices in indicesPerPred]\n\n#---\n\nprobs = [0.001, 0.5, 0.999]\nquantileDict = LS_KDEx.predict(X = XTest, probs = probs, scalingList = None)\nquantileDf = LS_KDEx.predict(X = XTest, probs = probs, scalingList = None)\n\ntest_eq(list(quantileDf.columns), probs)\n\nfor i in range(quantileDf.shape[0]):\n    assert((np.diff(quantileDf.iloc[i,:]) &gt;= 0).all())\n    test_eq(yTrainPerPred[i].min(), quantileDf.loc[i, 0.001])\n    test_eq(yTrainPerPred[i].max(), quantileDf.loc[i, 0.999])\n    test_eq(np.quantile(a = yTrainPerPred[i], q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])\n\n\n\n\nSet and Get Parameters\n\n\nPoint Estimator Fit and Predict\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nassert 'fitted_' not in dir(LS_KDEx.estimator)\nLS_KDEx.fit(XTrain, yTrain)\nassert LS_KDEx.estimator.fitted_\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)\n\n#---\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nassert 'fitted_' not in dir(LS_KDEx.estimator)\nLS_KDEx.refitPointEstimator(XTrain, yTrain)\nassert LS_KDEx.estimator.fitted_\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)\n\n#---\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx = LevelSetKDEx(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nLS_KDEx.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n\nassert 'fitted_' not in dir(LS_KDEx.estimator)\nLS_KDEx.refitPointEstimator(XTrain, yTrain)\nassert LS_KDEx.estimator.fitted_\ntest_eq(len(np.unique(LS_KDEx.estimator.predict(XTest))), 1)\ntest_eq(len(np.unique(LS_KDEx.pointPredict(XTest))), 1)\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)"
  },
  {
    "objectID": "99_unitTests.html#ls_kdex_knn",
    "href": "99_unitTests.html#ls_kdex_knn",
    "title": "Generate Neighborhoods",
    "section": "LS_KDEx_kNN",
    "text": "LS_KDEx_kNN\n\nStandard Attributes\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100)\nLS_KDEx_kNN.fit(XTrain, yTrain)\n\n# Check if nothing weird happened to y and yPred\ntest_eq(LS_KDEx_kNN.yTrain, yTrain)\ntest_eq(LS_KDEx_kNN.yPredTrain, LGBM.predict(XTrain))\n\n# Check if fitted has been set correctly\nassert LS_KDEx_kNN.fitted\n\n\n\ngetWeights\n\nStandard Settings\n\n# Weights-Output Test\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100, weightsByDistance = False)\nLS_KDEx_kNN.fit(XTrain, yTrain)\n\nnn = LS_KDEx_kNN.nearestNeighborsOnPreds\nyPredTest = LGBM.predict(XTest)\nyPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n\nweightsList = LS_KDEx_kNN.getWeights(X = XTest, \n                                     outputType = 'onlyPositiveWeights')\n\nbinSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\ndistancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n\n# Check if all bins contain at least 100 observations\nassert np.all((np.array(binSizesReal) &gt;= 100))\n\n#---\n\nweightsAll = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'all')\n\ntest_eq(len(weightsAll), XTest.shape[0])\n\nfor i in range(len(weightsAll)):\n    weights = weightsAll[i]\n    \n    assert all(weights &gt;= 0)\n    assert isclose(weights.sum(), 1)\n    assert np.allclose(weights[weights &gt; 0], 1 / binSizesReal[i])\n    \n    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(np.where(weights &gt; 0)[0]))\n\n#---\n\nweightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    weights = weightsOnlyPos[i][0]\n    indices = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    assert np.allclose(weights, 1 / binSizesReal[i])\n    \n    test_eq(set(neighborsMatrix[i, 0:binSizesReal[i]]), set(indices))\n    \n    if len(indices) &gt; 100:\n        assert np.allclose(np.diff(distancesMatrix[i, 99:binSizesReal[i]]), 0)\n    \n#---\n\nweightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    assert np.all(weights &gt;= 1 / binSizesReal[i])\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(valuesByHand), set(values))\n    \n#---\n\nweightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    assert np.allclose(np.diff(cumProb), np.diff(cumProb)[0])\n    \n    test_eq(values, np.sort(values))\n    test_eq(np.sort(valuesByHand), values)\n\n#---\n\nweightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizesReal[i]]]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(values, np.sort(values))\n    test_eq(set(valuesByHand), set(values))\n\n\n\nDistance Based Weights\n\n# Weights-Output Test\n\n# Modifying XTrain to enforce test-predictions being identical to train predictions\nXTrainMod = np.concatenate([XTest[0:2, :], XTrain], axis = 0)\nyTrainMod = np.concatenate([yTest[0:2], yTrain], axis = 0)\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 100, weightsByDistance = True,)\nLS_KDEx_kNN.fit(XTrainMod, yTrainMod)\n\n#---\n\nnn = LS_KDEx_kNN.nearestNeighborsOnPreds\nyPredTest = LGBM.predict(XTest)\nyPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n\nweightsList = LS_KDEx_kNN.getWeights(X = XTest,  \n                                     outputType = 'onlyPositiveWeights')\n\n#---\n\nbinSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\ndistancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n\n# Check if all bins either contain at least 100 observations or if not all weights have to equal\nfor i in range(len(binSizesReal)):\n    if binSizesReal[i] &lt; 100:\n        assert np.allclose(weightsList[i][0], 1 / len(weightsList[i][0]))\n        \n# Because of our above modification of XTrain and yTrain, for the first and second test observation \n# the special case applies where the test prediction is identical to at least 1 train prediction.\nassert np.allclose(weightsList[0][0], 1 / len(weightsList[0][0]))\nassert np.allclose(weightsList[1][0], 1 / len(weightsList[0][0]))\n\nassert 0 in weightsList[0][1]\nassert 1 in weightsList[1][1]\n\n#---\n\nweightsAll = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'all')\n\ntest_eq(len(weightsAll), XTest.shape[0])\n\nfor i in range(len(weightsAll)):\n    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n    distances = distancesMatrix[i, 0:binSizesReal[i]]\n    weights = weightsAll[i]\n    \n    assert all(weights &gt;= 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        assert np.allclose(weights[neighborsPredDistanceZero], 1 / sum(predDistanceCloseZero))\n        test_eq(np.sort(neighborsPredDistanceZero), np.sort(np.where(weights &gt; 0)[0]))\n        \n    else:\n        inverseDistances = 1 / distances\n        np.allclose(np.sort(weights[neighbors]), np.sort(inverseDistances / sum(inverseDistances)))\n        test_eq(np.sort(neighbors), np.sort(np.where(weights &gt; 0)[0]))\n\n#---\n\nweightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n    distances = distancesMatrix[i, 0:binSizesReal[i]]\n    weights = weightsOnlyPos[i][0]\n    indices = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        assert np.allclose(weights, 1 / sum(predDistanceCloseZero))\n        test_eq(np.sort(neighborsPredDistanceZero), np.sort(indices))\n            \n    else:\n        inverseDistances = 1 / distances\n        assert np.allclose(weights, inverseDistances / sum(inverseDistances))\n        test_eq(np.sort(neighbors), np.sort(indices))\n    \n    if len(indices) &gt; 100:\n        assert np.allclose(np.diff(distancesMatrix[i, 99:binSizesReal[i]]), 0)\n    \n#---\n\nweightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n    distances = distancesMatrix[i, 0:binSizesReal[i]]\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n            \n    else:\n        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(set(valuesByHand), set(values))\n    \n#---\n\nweightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution')\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n    distances = distancesMatrix[i, 0:binSizesReal[i]]\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n        nCloseZero = sum(predDistanceCloseZero)\n        assert np.allclose(cumProb, np.cumsum(np.repeat(1 / nCloseZero, nCloseZero)))\n        \n    else:\n        # The following test works if we use 'valuesByHand = yTrainMod[weightsOnlyPos[i][1]' to grab the yTrain values\n        # because the getWeights-function does nothing else. If we grab them differently here (e.g. via neighborsMatrix),\n        # the sorting can become different for identical yTrain values which will change the cumulated probabilities\n        # for exactly those indices (and only these). This has no practical implications for the usage of the computed\n        # cumulated distribution function, but it has for the exact value testing we are doing here.\n        inverseDistances = 1 / distances\n        valuesByHand = yTrainMod[weightsOnlyPos[i][1]]\n        valuesByHandIndicesSort = np.argsort(valuesByHand)\n        assert np.allclose(cumProb, np.cumsum((inverseDistances / sum(inverseDistances))[valuesByHandIndicesSort]))\n    \n    test_eq(values, np.sort(values))\n    test_eq(np.sort(valuesByHand), values)\n\n#---\n\nweightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized')\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    neighbors = neighborsMatrix[i, 0:binSizesReal[i]]\n    distances = distancesMatrix[i, 0:binSizesReal[i]]\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    \n    \n    assert all(cumProb &gt; 0)\n    assert isclose(cumProb.max(), 1)\n    test_eq(cumProb, np.sort(cumProb))\n    \n    predDistanceCloseZero = np.isclose(distances, 0)\n    \n    if np.any(predDistanceCloseZero):\n        neighborsPredDistanceZero = neighbors[np.where(predDistanceCloseZero)[0]]\n        valuesByHand = yTrainMod[neighborsPredDistanceZero]\n    \n    else:\n        inverseDistances = 1 / distances\n        valuesByHand = yTrainMod[neighborsMatrix[i, 0:binSizesReal[i]]]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(values, np.sort(values))\n    test_eq(set(valuesByHand), set(values))\n\n\n\nArtificially Big Bins\n\n# Enforcing bins with size bigger than binSize\nbinSize = 10\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n\n# Done to ensure that bins with binSize &gt; 100 happen\nXTrainDuplicated = np.concatenate([XTrain] * (binSize + 1), axis = 0)\nyTrainDuplicated = np.concatenate([yTrain] * (binSize + 1), axis = 0)\n\nLS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n\n#---\n\nnn = LS_KDEx_kNN.nearestNeighborsOnPreds\nyPredTest = LGBM.predict(XTest)\nyPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n\ndistancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize + 1)\n\n#---\n\nweightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    weights = weightsOnlyPos[i][0]\n    indices = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    assert set(neighborsMatrix[i, 0:binSize]) &lt;= set(indices)\n    \n    if len(indices) &gt; 100:\n        test_eq(distancesMatrix[i, binSize-1], distancesMatrix[i, binSize])\n\n\n\nBins with only 1 Unique Value\n\n# Enforcing bins with only one unique value\nbinSize = 10\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = 10)\n\n# Done to ensure that bins with binSize &gt; 100 happen\nXTrainDuplicated = np.concatenate([XTrain] * binSize, axis = 0)\nyTrainDuplicated = np.concatenate([yTrain] * binSize, axis = 0)\n\nLS_KDEx_kNN.fit(XTrainDuplicated, yTrainDuplicated)\n\n#---\n\nweightsOnlyPos = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized')\n\ntest_eq(len(weightsOnlyPos), XTest.shape[0])\n\nfor i in range(len(weightsOnlyPos)):\n    weights = weightsOnlyPos[i][0]\n    values = weightsOnlyPos[i][1]\n    \n    assert all(weights &gt; 0)\n    assert isclose(weights.sum(), 1)\n    \n    test_eq(len(values), 1)\n\n\n\nScalingList\n\n# Testing scalingList \nbinSize = 20\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n\n#---\n\nLS_KDEx_kNN.fit(XTrain, yTrain)\nnn = LS_KDEx_kNN.nearestNeighborsOnPreds\nyPredTest = LGBM.predict(XTest)\nyPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n\ndistancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = binSize)\n\n#---\n\nweightsSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'summarized', scalingList = scalingList)\n\ntest_eq(len(weightsSummarized), XTest.shape[0])\n\nfor i in range(len(weightsSummarized)):\n    weights = weightsSummarized[i][0]\n    values = weightsSummarized[i][1]\n    \n    test_eq(len(values), len(np.unique(values)))\n    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) &lt;= set(values)\n    \n#---\n\nweightsCumDistr = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistribution', scalingList = scalingList)\n\ntest_eq(len(weightsCumDistr), XTest.shape[0])\n\nfor i in range(len(weightsCumDistr)):\n    cumProb = weightsCumDistr[i][0]\n    values = weightsCumDistr[i][1]\n    \n    test_eq(values, np.sort(values))\n    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) &lt;= set(values)\n\n#---\n\nweightsDistrSummarized = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'cumulativeDistributionSummarized', scalingList = scalingList)\n\ntest_eq(len(weightsDistrSummarized), XTest.shape[0])\n\nfor i in range(len(weightsDistrSummarized)):\n    cumProb = weightsDistrSummarized[i][0]\n    values = weightsDistrSummarized[i][1]\n    \n    test_eq(len(values), len(np.unique(values)))\n    test_eq(values, np.sort(values))\n    assert set(yTrain[neighborsMatrix[i, :]] * scalingList[i]) &lt;= set(values)\n\n\n\n\npredict\n\n# Testing predict-method\nbinSize = 15\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM, binSize = binSize)\n\nLS_KDEx_kNN.fit(XTrain, yTrain)\nnn = LS_KDEx_kNN.nearestNeighborsOnPreds\nyPredTest = LGBM.predict(XTest)\nyPredTest_reshaped = np.reshape(yPredTest, newshape = (len(yPredTest), 1))\n\nweightsList = LS_KDEx_kNN.getWeights(X = XTest, outputType = 'onlyPositiveWeights')\nbinSizesReal = [len(weightsList[i][1]) for i in range(XTest.shape[0])]\ndistancesMatrix, neighborsMatrix = nn.kneighbors(X = yPredTest_reshaped, n_neighbors = max(binSizesReal))\n\n#---\n\nprobs = [0.001, 0.5, 0.999]\nquantileDict = LS_KDEx_kNN.predict(X = XTest, probs = probs, scalingList = None)\nquantileDf = LS_KDEx_kNN.predict(X = XTest, probs = probs, scalingList = None)\n\ntest_eq(list(quantileDf.columns), probs)\n\nfor i in range(quantileDf.shape[0]):\n    \n    assert((np.diff(quantileDf.iloc[i,:]) &gt;= 0).all())\n    \n    binSizeReal = binSizesReal[i]\n    valuesByHand = yTrain[neighborsMatrix[i, 0:binSizeReal]]\n    \n    test_eq(valuesByHand.min(), quantileDf.loc[i, 0.001])\n    test_eq(valuesByHand.max(), quantileDf.loc[i, 0.999])\n    test_eq(np.quantile(a = valuesByHand, q = 0.5, method = 'inverted_cdf'), quantileDf.loc[i, 0.5])\n\n\n\nSet and Get Parameters\n\n\nPoint Estimator Fit and Predict\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nassert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\nLS_KDEx_kNN.fit(XTrain, yTrain)\nassert LS_KDEx_kNN.estimator.fitted_\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)\n\n#---\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nassert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\nLS_KDEx_kNN.refitPointEstimator(XTrain, yTrain)\nassert LS_KDEx_kNN.estimator.fitted_\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)\n\n#---\n\nLGBM2 = LGBMRegressor(n_jobs = 1, max_depth = 2)\n\nLS_KDEx_kNN = LevelSetKDEx_kNN(estimator = LGBM2, binSize = 100, weightsByDistance = False)\nLS_KDEx_kNN.set_params(estimator = LGBMRegressor(min_child_samples = 10000))\n\nassert 'fitted_' not in dir(LS_KDEx_kNN.estimator)\nLS_KDEx_kNN.refitPointEstimator(XTrain, yTrain)\nassert LS_KDEx_kNN.estimator.fitted_\ntest_eq(len(np.unique(LS_KDEx_kNN.estimator.predict(XTest))), 1)\ntest_eq(len(np.unique(LS_KDEx_kNN.pointPredict(XTest))), 1)\n\n# Check whether original estimator has been unintentionally modified\nassert 'fitted_' not in dir(LGBM2)"
  },
  {
    "objectID": "99_unitTests.html#generate-bins",
    "href": "99_unitTests.html#generate-bins",
    "title": "Generate Neighborhoods",
    "section": "Generate Bins",
    "text": "Generate Bins\n\n# Testing various artificial inputs of 'generateBins'\n\nyPred = np.arange(100)\nindicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n\ntest_eq(list(indicesPerBin.keys()), [i for i in range(10)])\n\nindicesPerBinTest = {0: np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n                     1: np.array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19]),\n                     2: np.array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n                     3: np.array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39]),\n                     4: np.array([40, 41, 42, 43, 44, 45, 46, 47, 48, 49]),\n                     5: np.array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59]),\n                     6: np.array([60, 61, 62, 63, 64, 65, 66, 67, 68, 69]),\n                     7: np.array([70, 71, 72, 73, 74, 75, 76, 77, 78, 79]),\n                     8: np.array([80, 81, 82, 83, 84, 85, 86, 87, 88, 89]),\n                     9: np.array([90, 91, 92, 93, 94, 95, 96, 97, 98, 99])}\n\nindicesTracker = list()\nfor i in range(len(indicesPerBin)):\n    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n    \n    indicesTracker.extend(indicesPerBin[i].tolist())\n\ntest_eq(len(indicesTracker), len(np.unique(indicesTracker)))\ntest_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n\nlowerBoundPerBinTest = [np.NINF, 9.5, 19.5, 29.5, 39.5, 49.5, 59.5, 69.5, 79.5, 89.5]\ntest_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\ntest_eq(list(lowerBoundPerBin.index), [i for i in range(10)])\n\n#---\n\nyPred = np.append(np.arange(100), np.arange(100))\nindicesPerBin, lowerBoundPerBin = generateBins(binSize = 10, yPred = yPred)\n\ntest_eq(list(indicesPerBin.keys()), [i for i in range(20)])\n\nindicesPerBinTest = {0: np.array([   0, 100,   1, 101,   2, 102,   3, 103,   4, 104]),\n                     1: np.array([   5, 105,   6, 106,   7, 107,   8, 108,   9, 109]),\n                     2: np.array([  10, 110,  11, 111,  12, 112,  13, 113,  14, 114]),\n                     3: np.array([  15, 115,  16, 116,  17, 117,  18, 118,  19, 119]),\n                     4: np.array([  20, 120,  21, 121,  22, 122,  23, 123,  24, 124]),\n                     5: np.array([  25, 125,  26, 126,  27, 127,  28, 128,  29, 129]),\n                     6: np.array([  30, 130,  31, 131,  32, 132,  33, 133,  34, 134]),\n                     7: np.array([  35, 135,  36, 136,  37, 137,  38, 138,  39, 139]),\n                     8: np.array([  40, 140,  41, 141,  42, 142,  43, 143,  44, 144]),\n                     9: np.array([  45, 145,  46, 146,  47, 147,  48, 148,  49, 149]),\n                     10: np.array([ 50, 150,  51, 151,  52, 152,  53, 153,  54, 154]),\n                     11: np.array([ 55, 155,  56, 156,  57, 157,  58, 158,  59, 159]),\n                     12: np.array([ 60, 160,  61, 161,  62, 162,  63, 163,  64, 164]),\n                     13: np.array([ 65, 165,  66, 166,  67, 167,  68, 168,  69, 169]),\n                     14: np.array([ 70, 170,  71, 171,  72, 172,  73, 173,  74, 174]),\n                     15: np.array([ 75, 175,  76, 176,  77, 177,  78, 178,  79, 179]),\n                     16: np.array([ 80, 180,  81, 181,  82, 182,  83, 183,  84, 184]),\n                     17: np.array([ 85, 185,  86, 186,  87, 187,  88, 188,  89, 189]),\n                     18: np.array([ 90, 190,  91, 191,  92, 192,  93, 193,  94, 194]),\n                     19: np.array([ 95, 195,  96, 196,  97, 197,  98, 198,  99, 199])}\n\nindicesTracker = list()\nfor i in range(len(indicesPerBin)):\n    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n    \n    indicesTracker.extend(indicesPerBin[i].tolist())\n\ntest_eq(len(indicesTracker), len(np.unique(indicesTracker)))\ntest_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n    \nlowerBoundPerBinTest = [np.NINF] + list(np.arange(4.5, 99.5, 5))\ntest_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\ntest_eq(list(lowerBoundPerBin.index), [i for i in range(20)])\n\n#---\n\n# Check if creation of last bin works correctly\nyPred = np.append(np.arange(10), np.arange(10))\nindicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n\ntest_eq(list(indicesPerBin.keys()), [i for i in range(3)])\n\nindicesPerBinTest = {0: np.array([ 0, 10,  1, 11,  2, 12]),\n                     1: np.array([ 3, 13,  4, 14,  5, 15]),\n                     2: np.array([ 6, 16,  7, 17,  8, 18,  9, 19])}\n\nindicesTracker = list()\nfor i in range(len(indicesPerBin)):\n    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n    \n    indicesTracker.extend(indicesPerBin[i].tolist())\n\ntest_eq(len(indicesTracker), len(np.unique(indicesTracker)))\ntest_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n    \nlowerBoundPerBinTest = [np.NINF, 2.5, 5.5]\ntest_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\ntest_eq(list(lowerBoundPerBin.index), [i for i in range(3)])\n\n#---\n\n# yPred.unique() == 1\nyPred = np.repeat(1, 100)\nindicesPerBin, lowerBoundPerBin = generateBins(binSize = 5, yPred = yPred)\n\ntest_eq(list(indicesPerBin.keys()), [0])\n\nindicesPerBinTest = {0: np.arange(0, 100, 1)}\n\nindicesTracker = list()\nfor i in range(len(indicesPerBin)):\n    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n    \n    indicesTracker.extend(indicesPerBin[i].tolist())\n\ntest_eq(len(indicesTracker), len(np.unique(indicesTracker)))\ntest_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n    \nlowerBoundPerBinTest = [np.NINF]\ntest_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\ntest_eq(list(lowerBoundPerBin.index), [i for i in range(1)])\n\n#---\n\n# binSize &gt; len(yPred)\nyPred = np.arange(10)\nindicesPerBin, lowerBoundPerBin = generateBins(binSize = 100, yPred = yPred)\n\ntest_eq(list(indicesPerBin.keys()), [0])\n\nindicesPerBinTest = {0: np.arange(0, 10, 1)}\n\nindicesTracker = list()\nfor i in range(len(indicesPerBin)):\n    test_eq(set(indicesPerBin[i]), set(indicesPerBinTest[i]))\n    test_eq(len(indicesPerBin[i]), len(np.unique(indicesPerBin[i])))\n    \n    indicesTracker.extend(indicesPerBin[i].tolist())\n\ntest_eq(len(indicesTracker), len(np.unique(indicesTracker)))\ntest_eq(np.sort(indicesTracker), np.arange(len(yPred)))\n    \nlowerBoundPerBinTest = [np.NINF]\ntest_eq(list(lowerBoundPerBin), lowerBoundPerBinTest)\ntest_eq(list(lowerBoundPerBin.index), [i for i in range(1)])\n\n\n# # LevelSetKDEx.getWeights() and LevelSetKDEx_kNN.getWeights()\n# for i in range(len(neighborsList)):\n#     if len(neighborsList[i]) &lt; self.binSize:\n#         ipdb.set_trace()\n\n\n# # generateBins\n# indices = np.array([])\n# for k in range(len(indicesPerBin.keys())):\n#     indices = np.append(indices, indicesPerBin[k])\n\n# if len(indices) != len(yPred):\n#     ipdb.set_trace()\n\n# predCheck = np.array([pred in binPerPred.keys() for pred in yPred])\n# keyCheck = np.array([key in yPred for key in binPerPred.keys()])\n\n# if (all(predCheck) & all(keyCheck)) is False:\n#     ipdb.set_trace()\n\n\n# # LevelSetKDEx.getWeights()\n# check = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) &gt; 100]\n# check2 = [i for i in range(len(weightsDataList)) if len(weightsDataList[i][1]) &gt; 100 and binPerPred[i] != self.lowerBoundPerBin.index.max()]"
  },
  {
    "objectID": "utils.html#restructure-weights-data-list",
    "href": "utils.html#restructure-weights-data-list",
    "title": "Helper Functions",
    "section": "Restructure Weights Data List",
    "text": "Restructure Weights Data List\n\nsource\n\nrestructureWeightsDataList\n\n restructureWeightsDataList (weightsDataList,\n                             outputType='onlyPositiveWeights', y=None,\n                             scalingList=None, equalWeights=False)\n\n\n\nSummarize Weights Data\n\nsource\n\n\nsummarizeWeightsData\n\n summarizeWeightsData (weightsPos, yWeightPos, equalWeights=False)"
  },
  {
    "objectID": "utils.html#restructure-weights-data-list---multivariate",
    "href": "utils.html#restructure-weights-data-list---multivariate",
    "title": "Helper Functions",
    "section": "Restructure Weights Data List - Multivariate",
    "text": "Restructure Weights Data List - Multivariate\n\nsource\n\nrestructureWeightsDataList_multivariate\n\n restructureWeightsDataList_multivariate (weightsDataList,\n                                          outputType='onlyPositiveWeights'\n                                          , y=None, scalingList=None,\n                                          equalWeights=False)\n\n\n\nSummarize Weights Data - Multivariate\n\nsource\n\n\nsummarizeWeightsData_multivariate\n\n summarizeWeightsData_multivariate (weightsPos, yWeightPos,\n                                    equalWeights=False)"
  },
  {
    "objectID": "utils.html#generate-output",
    "href": "utils.html#generate-output",
    "title": "Helper Functions",
    "section": "Generate Output",
    "text": "Generate Output\n\nsource\n\ngenerateFinalOutput\n\n generateFinalOutput (dataOriginal, dataDecisions,\n                      targetVariable='demand', mergeOn=None,\n                      variablesToAdd=None, scaleBy=None,\n                      includeTraining=False, sortBy=None,\n                      longFormat=False, **kwargs)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "",
    "text": "pip install dddex"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "",
    "text": "pip install dddex"
  },
  {
    "objectID": "index.html#what-is-dddex",
    "href": "index.html#what-is-dddex",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "What is dddex?",
    "text": "What is dddex?\nThe package name dddex stands for Data-Driven Density Estimaton x. New approaches are being implemented for estimating conditional densities without any parametric assumption about the underlying distribution. All those approaches take an arbitrary point forecaster as input and turn them into a new object that outputs an estimation of the conditional density based on the point predictions of the original point forecaster. The x in the name emphasizes that the approaches can be applied to any point forecaster. In this package several approaches are being implementing via the following classes:\n\nLevelSetKDEx\nLevelSetKDEx_kNN\nLevelSetKDEx_NN\nLevelSetKDEx_multivariate\n\nIn the following we are going to work exclusively with the class LevelSetKDEx because the most important methods are all pretty much the same. All models can be run easily with only a few lines of code and are designed to be compatible with the well known Scikit-Learn framework."
  },
  {
    "objectID": "index.html#how-to-use-levelsetkdex",
    "href": "index.html#how-to-use-levelsetkdex",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "How to use: LevelSetKDEx",
    "text": "How to use: LevelSetKDEx\nTo ensure compatibility with Scikit-Learn, as usual the class LevelSetKDEx implements a fit and predict method. As the purposes of both classes is to compute estimations of conditional densities, the predict method outputs p-quantiles rather than point forecasts.\nOur choice of the class-names is supposed to be indicative of the underlying models: The name LevelSet stems from the fact that both methods operate with the underlying assumption that the values of point forecasts generated by the same point forecaster can be interpreted as a similarity measure between samples. KDE is short for Kernel Density Estimator and the x yet again signals that the classes can be initialized with any point forecasting model.\nIn the following, we demonstrate how to use the class LevelSetKDEx to compute estimations of the conditional densities and quantiles for the Yaz Data Set. As explained above, LevelSetKDEx is always based on a point forecaster that is being specified by the user. In our example we use the well known LightGBMRegressor as the underlying point predictor.\n\nfrom dddex.levelSetKDEx_univariate import LevelSetKDEx, LevelSetKDEx_kNN, LevelSetKDEx_NN\nfrom dddex.levelSetKDEx_multivariate import LevelSetKDEx_multivariate\n\nfrom dddex.loadData import loadDataYaz\nfrom lightgbm import LGBMRegressor\n\n\ndataYaz, XTrain, yTrain, XTest, yTest = loadDataYaz(returnXY = True)\nLGBM = LGBMRegressor(n_jobs = 1)\n\nThere are three parameters for LevelSetKDEx:\n\nestimator: A point forecasting model that must have a predict method.\nbinSize: The amount of training samples considered to compute the conditional densities (for more details, see To be written).\nweightsByDistance: If False, all considered training samples are weighted equally. If True, training samples are weighted by the inverse of the distance of their respective point forecast to the point forecast of the test sample at hand.\n\n\nLSKDEx = LevelSetKDEx(estimator = LGBM, \n                      binSize = 100,\n                      weightsByDistance = False)\n\nThere is no need to run fit on the point forecasting model before initializing LevelSetKDEx, because the fit method of LevelSetKDEx automatically checks whether the provided model has been fitted already or not and runs the respective fit method of the point forecaster if needed.\nIt should be noted, that running fit for the LevelSetKDEx approaches takes exceptionally little time even for datasets with \\(&gt;10^6\\) samples (provided, of course, that the underlying point forecasting model has been fitted before hand).\n\nLSKDEx.fit(X = XTrain, y = yTrain)\n\nIn order to compute conditional densities for test samples now, we simply run the getWeights method.\n\nconditionalDensities = LSKDEx.getWeights(X = XTest,\n                                         outputType = 'summarized')\n\nprint(f\"probabilities: {conditionalDensities[0][0]}\")\nprint(f\"demand values: {conditionalDensities[0][1]}\")\n\nprobabilities: [0.49 0.01 0.21 0.01 0.16 0.07 0.04 0.01]\ndemand values: [0.         0.01075269 0.04       0.04878049 0.08       0.12\n 0.16       0.2       ]\n\n\nHere, conditionalDensities is a list whose elements correspond to the samples specified via X. Every element contains a tuple, whose first entry constitutes probabilities and the second entry corresponding demand values (side note: The demand values have been scaled to lie in \\([0, 1]\\)). In the above example, we can for example see that our model estimates that for the first test sample the demand will be 0 with a probability of 49%.\nLike the input argument outputType of getWeights suggests, we can output the conditional density estimations in various different forms. All in all, there are currently 5 output types specifying how the output for each sample looks like:\n\nall: An array with the same length as the number of training samples. Each entry represents the probability of each training sample.\nonlyPositiveWeights: A tuple. The first element of the tuple represents the probabilities and the second one the indices of the corresponding training sample. Only probalities greater than zero are returned. Note: This is the most memory and computationally efficient output type.\nsummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\ncumulativeDistribution: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain.\ncumulativeDistributionSummarized: A tuple. The first element of the tuple represents the probabilities and the second one the corresponding value of yTrain. The probabilities corresponding to identical values of yTrain are aggregated.\n\nFor example, by setting outputType = 'cumulativeDistributionSummarized' we can compute an estimation of the conditional cumulative distribution function for each sample. Below, we can see that our model predicts the demand of the first sample to be lower or equal than 0.16 with a probability of 99%.\n\ncumulativeDistributions = LSKDEx.getWeights(X = XTest,\n                                            outputType = 'cumulativeDistributionSummarized')\n\nprint(f\"cumulated probabilities: {cumulativeDistributions[0][0]}\")\nprint(f\"demand values: {cumulativeDistributions[0][1]}\")\n\ncumulated probabilities: [0.49 0.5  0.71 0.72 0.88 0.95 0.99 1.  ]\ndemand values: [0.         0.01075269 0.04       0.04878049 0.08       0.12\n 0.16       0.2       ]\n\n\nWe can also compute estimations of quantiles using the predict method. The parameter probs specifies the quantiles we want to predict.\n\npredRes = LSKDEx.predict(X = XTest,\n                         probs = [0.1, 0.5, 0.75, 0.99])\nprint(predRes.iloc[0:6, :].to_markdown())\n\n|    |       0.1 |       0.5 |   0.75 |   0.99 |\n|---:|----------:|----------:|-------:|-------:|\n|  0 | 0         | 0.0107527 |   0.08 |   0.16 |\n|  1 | 0         | 0.08      |   0.12 |   0.2  |\n|  2 | 0.04      | 0.0967742 |   0.12 |   0.24 |\n|  3 | 0.056338  | 0.12      |   0.16 |   0.28 |\n|  4 | 0.04      | 0.0967742 |   0.12 |   0.24 |\n|  5 | 0.0666667 | 0.16      |   0.2  |   0.32 |"
  },
  {
    "objectID": "index.html#how-to-tune-binsize-parameter-of-levelsetkdex",
    "href": "index.html#how-to-tune-binsize-parameter-of-levelsetkdex",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "How to tune binSize parameter of LevelSetKDEx",
    "text": "How to tune binSize parameter of LevelSetKDEx\ndddex also comes with the class QuantileCrossValidations that allows to tune quantile predictors in an efficient manner. The class is designed in a very similar fashion to the cross-validation classes of Scikit-Learn. As such, at first QuantileCrossValidationis initialized with all the settings for the cross-validation.\n\nestimator: A model that must have a set_params, fit and predict method. Additionally, the predict method must (!) have a function argument called prob that allows to specify which quantiles to predict.\ncvFolds: An iterable yielding (train, test) splits as arrays of indices\nparameterGrid: The candidate values of to evaluate. Must be a dict.\nprobs: The probabilities for which quantiles are computed and evaluated.\nrefitPerProb: If True, for ever probability a fitted copy of estimator with the best parameter Setting for the respective p-quantile is stored in the attribute bestEstimator_perProb.\nn_jobs: How many cross-validation split results to compute in parallel.\n\nAfter specifying the settings, fit has to be called to compute the results of the cross validation. The performance of every parameter setting is being evaluated by computing the relative reduction of the pinball loss in comparison to the quantile estimations generated by SAA (Sample Average Approximation) for every quantile.\n\nfrom dddex.crossValidation import groupedTimeSeriesSplit, QuantileCrossValidation\n\ndataTrain = dataYaz[dataYaz['label'] == 'train']\ncvFolds = groupedTimeSeriesSplit(data = dataTrain, \n                                 kFolds = 3,\n                                 testLength = 28,\n                                 groupFeature = 'id',\n                                 timeFeature = 'dayIndex')\n\nLSKDEx = LevelSetKDEx(estimator = LGBM)\nparamGrid = {'binSize': [20, 100, 400, 1000],\n             'weightsByDistance': [True, False]}\n\nCV = QuantileCrossValidation(estimator = LSKDEx,\n                             parameterGrid = paramGrid,\n                             cvFolds = cvFolds,\n                             probs = [0.01, 0.25, 0.5, 0.75, 0.99],\n                             refitPerProb = True,\n                             n_jobs = 3)\n\nCV.fit(X = XTrain, y = yTrain)\n\nThe best value for binSize can either be computed for every quantile separately or for all quantiles at once by computing the average cost reduction over all quantiles.\n\nprint(f\"Best binSize over all quantiles: {CV.bestParams}\")\nCV.bestParams_perProb\n\nBest binSize over all quantiles: {'binSize': 1000, 'weightsByDistance': False}\n\n\n{0.01: {'binSize': 1000, 'weightsByDistance': False},\n 0.25: {'binSize': 20, 'weightsByDistance': False},\n 0.5: {'binSize': 100, 'weightsByDistance': False},\n 0.75: {'binSize': 100, 'weightsByDistance': False},\n 0.99: {'binSize': 1000, 'weightsByDistance': False}}\n\n\nThe exact results are also stored as attributes. The easiest way to view the results is given via cv_results, which depicts the average results over all cross-validation folds:\n\nprint(CV.cvResults.to_markdown())\n\n|               |    0.01 |     0.25 |      0.5 |     0.75 |    0.99 |\n|:--------------|--------:|---------:|---------:|---------:|--------:|\n| (20, True)    | 3.79553 | 0.946626 | 0.89631  | 0.974659 | 2.98365 |\n| (20, False)   | 3.23956 | 0.849528 | 0.808262 | 0.854069 | 2.46195 |\n| (100, True)   | 3.11384 | 0.92145  | 0.871266 | 0.922703 | 2.22249 |\n| (100, False)  | 1.65191 | 0.857026 | 0.803632 | 0.835323 | 1.81003 |\n| (400, True)   | 2.57563 | 0.908214 | 0.851471 | 0.900311 | 2.03445 |\n| (400, False)  | 1.64183 | 0.860281 | 0.812806 | 0.837641 | 1.57534 |\n| (1000, True)  | 2.34575 | 0.893628 | 0.843721 | 0.888143 | 1.82368 |\n| (1000, False) | 1.54641 | 0.869606 | 0.854369 | 0.88065  | 1.52644 |\n\n\nThe attentive reader will certainly notice that values greater than 1 imply that the respective model performed worse than SAA. This is, of course, simply due to the fact, that we didn’t tune the hyperparameters of the underlying LGBMRegressor point predictor and instead used the default parameter values. The LevelSetKDExclasses are able to produce highly accurate density estimations, but are obviously not able to turn a terrible point predictor into a highly performant conditional density estimator. The performance of the underlying point predictor and the constructed LevelSetKDEx model go hand in hand.\nWe can also access the results for every fold separately via cv_results_raw, which is a list with one entry per fold:\n\nCV.cvResults_raw\n\n[                               0.01      0.25      0.50      0.75      0.99\n binSize weightsByDistance                                                  \n 20      True               3.730363  0.977152  0.949944  1.093261  4.590650\n         False              3.068598  0.854633  0.855041  0.953362  3.663885\n 100     True               3.359961  0.945510  0.922778  1.027477  3.475501\n         False              1.626054  0.871327  0.833379  0.907911  2.591117\n 400     True               2.663854  0.928036  0.907505  0.995238  3.149022\n         False              1.732673  0.860440  0.828015  0.890643  2.190292\n 1000    True               2.463221  0.914308  0.897978  0.979345  2.753553\n         False              1.464534  0.873277  0.858563  0.891858  1.830334,\n                                0.01      0.25      0.50      0.75      0.99\n binSize weightsByDistance                                                  \n 20      True               4.725018  0.958236  0.891472  0.914408  2.253200\n         False              4.157297  0.841141  0.795929  0.830544  1.883320\n 100     True               3.687090  0.933531  0.876655  0.875718  1.551640\n         False              1.752709  0.862970  0.812126  0.819613  1.416013\n 400     True               3.061210  0.920190  0.851794  0.873496  1.464974\n         False              2.085622  0.887758  0.839370  0.859290  1.296445\n 1000    True               2.784076  0.903801  0.840009  0.856845  1.381658\n         False              1.767468  0.869484  0.860893  0.876293  1.464460,\n                                0.01      0.25      0.50      0.75      0.99\n binSize weightsByDistance                                                  \n 20      True               2.931208  0.904490  0.847513  0.916307  2.107091\n         False              2.492787  0.852811  0.773815  0.778301  1.838642\n 100     True               2.294471  0.885308  0.814365  0.864913  1.640339\n         False              1.576956  0.836781  0.765390  0.778446  1.422947\n 400     True               2.001828  0.876417  0.795114  0.832198  1.489340\n         False              1.107203  0.832645  0.771034  0.762992  1.239275\n 1000    True               1.789944  0.862776  0.793177  0.828237  1.335825\n         False              1.407221  0.866058  0.843651  0.873799  1.284521]\n\n\nThe models with the best binSize parameter are automatically computed while running fit and can be accessed via bestEstimator. If refitPerProb = True, then bestEstimator is a dictionary whose keys are the probabilities specified via the paramater probs.\n\nLSKDEx_best99 = CV.bestEstimator_perProb[0.99]\npredRes = LSKDEx_best99.predict(X = XTest,\n                                probs = 0.99)\nprint(predRes.iloc[0:6, ].to_markdown())\n\n|    |   0.99 |\n|---:|-------:|\n|  0 |   0.32 |\n|  1 |   0.32 |\n|  2 |   0.32 |\n|  3 |   0.32 |\n|  4 |   0.32 |\n|  5 |   0.32 |"
  },
  {
    "objectID": "index.html#benchmarks-random-forest-wsaa",
    "href": "index.html#benchmarks-random-forest-wsaa",
    "title": "dddex: Data-Driven Density Estimation x",
    "section": "Benchmarks: Random Forest wSAA",
    "text": "Benchmarks: Random Forest wSAA\nThe dddex package also contains useful non-parametric benchmark models to compare the performance of the LevelSetKDEx models to other state of the art non-parametric models capable of generating conditional density estimations. In a meta analysis conducted by S. Butler et al. the most performant model has been found to be weighted sample average approximation (wSAA) based on Random Forest. This model has been implemented in a Scikit-Learn fashion as well.\n\nfrom dddex.wSAA import RandomForestWSAA\nRF = RandomForestWSAA()\n\nRandomForestWSAA is a class derived from the original RandomForestRegressor class from Scikit-Learn, that has been extended to be able to generate conditional density estimations in the manner described by Bertsimas et al. in their paper From Predictive to prescriptive analytics. The Random Forest modell is being fitted in exactly the same way as the original RandomForestRegressor:\n\nRF.fit(X = XTrain, y = yTrain)\n\nIdentical to the LevelSetKDEx and LevelSetKDEx_kNN classes, an identical method called getWeights and predictare implemented to compute conditional density estimations and quantiles. The output is the same as before.\n\nconditionalDensities = RF.getWeights(X = XTest,\n                                     outputType = 'summarized')\n\nprint(f\"probabilities: {conditionalDensities[0][0]}\")\nprint(f\"demand values: {conditionalDensities[0][1]}\")\n\nprobabilities: [0.08334138 0.17368071 0.2987331  0.10053752 0.1893534  0.09121861\n 0.04362338 0.0145119  0.005     ]\ndemand values: [0.   0.04 0.08 0.12 0.16 0.2  0.24 0.28 0.32]\n\n\n\npredRes = RF.predict(X = XTest,\n                     probs = [0.01, 0.5, 0.99])\nprint(predRes.iloc[0:6, :].to_markdown())\n\n|    |   0.01 |   0.5 |   0.99 |\n|---:|-------:|------:|-------:|\n|  0 |      0 |  0.08 |   0.28 |\n|  1 |      0 |  0.12 |   0.32 |\n|  2 |      0 |  0.12 |   0.32 |\n|  3 |      0 |  0.12 |   0.32 |\n|  4 |      0 |  0.12 |   0.32 |\n|  5 |      0 |  0.2  |   0.4  |\n\n\nThe original predict method of the RandomForestRegressor has been renamed to pointPredict:\n\nRF.pointPredict(X = XTest)[0:6]\n\narray([0.1064    , 0.1184    , 0.1324    , 0.1324    , 0.1364    ,\n       0.18892683])"
  },
  {
    "objectID": "crossvalidation.html",
    "href": "crossvalidation.html",
    "title": "Cross Validation Functions",
    "section": "",
    "text": "source\n\n\n\n QuantileCrossValidation (estimator, cvFolds, parameterGrid:dict,\n                          randomSearch:bool=False, nIter:int=None,\n                          probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n                          0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n                          0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n                          0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n                          0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n                          0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n                          0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n                          0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n                          0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n                          0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n                          0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n                          0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n                          0.95, 0.96, 0.97, 0.98, 0.99],\n                          refitPerProb:bool=False, n_jobs:int=None,\n                          random_state:int=None)\n\nClass to efficiently tune the binSize parameter of all Level-Set based models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nAn object with a predict method that must (!) have an argument called probsthat specifies which quantiles to predict. Further, estimator needsa set_params and fit method.\n\n\ncvFolds\n\n\nAn iterable yielding (train, test) splits as arrays of indices.\n\n\nparameterGrid\ndict\n\ndict or list of dicts with parameters names (str) as keys and distributionsor lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nrandomSearch\nbool\nFalse\nWhether to use randomized search or grid search\n\n\nnIter\nint\nNone\nNumber of parameter settings that are sampled if randomSearch == True. n_iter trades off runtime vs quality of the solution.\n\n\nprobs\nlist\n[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]\niterable of floats between 0 and 1. These determine the p-quantiles being predicted to evaluate performance of each parameter setting.\n\n\nrefitPerProb\nbool\nFalse\nIf True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n\n\nn_jobs\nint\nNone\nNumber of jobs to run in parallel.\n\n\nrandom_state\nint\nNone\nPseudo random number generator state used for random uniform sampling of parameter candidate values.Pass an int for reproducible output across multiple function calls.\n\n\n\n\nsource\n\n\n\n\n QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix (has to work with the folds specified via cvFolds)\n\n\ny\nnp.ndarray\nTarget values (has to work with the folds specified via cvFolds)\n\n\n\n\n\n\nsource\n\n\n\n\n\n getFoldScore (estimator, parameterGrid, cvFold, probs, X, y)"
  },
  {
    "objectID": "crossvalidation.html#cv---pinball-loss",
    "href": "crossvalidation.html#cv---pinball-loss",
    "title": "Cross Validation Functions",
    "section": "",
    "text": "source\n\n\n\n QuantileCrossValidation (estimator, cvFolds, parameterGrid:dict,\n                          randomSearch:bool=False, nIter:int=None,\n                          probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n                          0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n                          0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n                          0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n                          0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n                          0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n                          0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n                          0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n                          0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n                          0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n                          0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n                          0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n                          0.95, 0.96, 0.97, 0.98, 0.99],\n                          refitPerProb:bool=False, n_jobs:int=None,\n                          random_state:int=None)\n\nClass to efficiently tune the binSize parameter of all Level-Set based models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nAn object with a predict method that must (!) have an argument called probsthat specifies which quantiles to predict. Further, estimator needsa set_params and fit method.\n\n\ncvFolds\n\n\nAn iterable yielding (train, test) splits as arrays of indices.\n\n\nparameterGrid\ndict\n\ndict or list of dicts with parameters names (str) as keys and distributionsor lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nrandomSearch\nbool\nFalse\nWhether to use randomized search or grid search\n\n\nnIter\nint\nNone\nNumber of parameter settings that are sampled if randomSearch == True. n_iter trades off runtime vs quality of the solution.\n\n\nprobs\nlist\n[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]\niterable of floats between 0 and 1. These determine the p-quantiles being predicted to evaluate performance of each parameter setting.\n\n\nrefitPerProb\nbool\nFalse\nIf True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n\n\nn_jobs\nint\nNone\nNumber of jobs to run in parallel.\n\n\nrandom_state\nint\nNone\nPseudo random number generator state used for random uniform sampling of parameter candidate values.Pass an int for reproducible output across multiple function calls.\n\n\n\n\nsource\n\n\n\n\n QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix (has to work with the folds specified via cvFolds)\n\n\ny\nnp.ndarray\nTarget values (has to work with the folds specified via cvFolds)\n\n\n\n\n\n\nsource\n\n\n\n\n\n getFoldScore (estimator, parameterGrid, cvFold, probs, X, y)"
  },
  {
    "objectID": "crossvalidation.html#cv---combined---pinball-loss",
    "href": "crossvalidation.html#cv---combined---pinball-loss",
    "title": "Cross Validation Functions",
    "section": "CV - Combined - Pinball Loss",
    "text": "CV - Combined - Pinball Loss\n\nsource\n\nQuantileCrossValidationLSx\n\n QuantileCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n                             parameterGridEstimator:dict,\n                             randomSearchLSx:bool=False,\n                             randomSearchEstimator:bool=False,\n                             nIterLSx:int=None, nIterEstimator:int=None,\n                             probs:list=[0.01, 0.02, 0.03, 0.04, 0.05,\n                             0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n                             0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n                             0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n                             0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33,\n                             0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4,\n                             0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n                             0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n                             0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61,\n                             0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68,\n                             0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n                             0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n                             0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89,\n                             0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,\n                             0.97, 0.98, 0.99], refitPerProb:bool=False,\n                             n_jobs:int=None, random_state:int=None)\n\nClass to efficiently tune the binSize parameter of all Level-Set based models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimatorLSx\n\n\nA Level-Set based model.\n\n\ncvFolds\n\n\nAn iterable yielding (train, test) splits as arrays of indices.\n\n\nparameterGridLSx\ndict\n\ndict or list of dicts with LSx parameters names (str) as keys and distributionsor lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nparameterGridEstimator\ndict\n\ndict or list of dicts with parameters names (str) of the point predictor as keysand distributions or lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nrandomSearchLSx\nbool\nFalse\nWhether to use randomized search or grid search for the LSx parameters.\n\n\nrandomSearchEstimator\nbool\nFalse\nWhether to use randomized search or grid search for the point predictor parameters.\n\n\nnIterLSx\nint\nNone\nNumber of parameter settings of the LSx model that are sampled if randomSearchLSx == True. LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settingsare evaluated for each point predictor parameter setting.\n\n\nnIterEstimator\nint\nNone\nNumber of parameter settings of the underlying point predictor that are sampled if randomSearchEstimator == True. nIterEstimator trades off runtime vs quality of the solution.\n\n\nprobs\nlist\n[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]\niterable of floats between 0 and 1. These determine the p-quantiles being predicted to evaluate performance of each parameter setting.\n\n\nrefitPerProb\nbool\nFalse\nIf True, for each p-quantile a fitted LSF with best binSize to predict it is returned. Otherwise only one LSF is returned that is best over all probs.\n\n\nn_jobs\nint\nNone\nnumber of folds being computed in parallel.\n\n\nrandom_state\nint\nNone\nPseudo random number generator state used for random uniform sampling of parameter candidate values.Pass an int for reproducible output across multiple function calls.\n\n\n\n\nsource\n\n\nQuantileCrossValidationLSx.fit\n\n QuantileCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix (has to work with the folds specified via cvFolds)\n\n\ny\nnp.ndarray\nTarget values (has to work with the folds specified via cvFolds)\n\n\n\n\n# show_doc(CrossValidationLSx_combined.fit)\n\n\nScores for Single Fold\n\nsource\n\n\n\ngetFoldScoreLSx\n\n getFoldScoreLSx (estimatorLSx, parameterGridLSx, parameterGridEstimator,\n                  cvFold, probs, X, y)"
  },
  {
    "objectID": "crossvalidation.html#cv---wasserstein-distance",
    "href": "crossvalidation.html#cv---wasserstein-distance",
    "title": "Cross Validation Functions",
    "section": "CV - Wasserstein Distance",
    "text": "CV - Wasserstein Distance\n\nsource\n\nDensityCrossValidation\n\n DensityCrossValidation (estimator, cvFolds, parameterGrid:dict,\n                         randomSearch:bool=False, nIter:int=None, p:int=1,\n                         n_jobs:int=None, random_state:int=None)\n\nClass to efficiently tune the binSize parameter of all Level-Set based models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimator\n\n\nAn object with a predict method that must (!) have an argument called probsthat specifies which quantiles to predict. Further, estimator needsa set_params and fit method.\n\n\ncvFolds\n\n\nAn iterable yielding (train, test) splits as arrays of indices.\n\n\nparameterGrid\ndict\n\ndict or list of dicts with parameters names (str) as keys and distributionsor lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nrandomSearch\nbool\nFalse\nWhether to use randomized search or grid search\n\n\nnIter\nint\nNone\nNumber of parameter settings that are sampled if randomSearch == True. n_iter trades off runtime vs quality of the solution.\n\n\np\nint\n1\nThe order of the wasserstein distance to evaluate each hyperparameter settings.\n\n\nn_jobs\nint\nNone\nNumber of jobs to run in parallel.\n\n\nrandom_state\nint\nNone\nPseudo random number generator state used for random uniform sampling of parameter candidate values.Pass an int for reproducible output across multiple function calls.\n\n\n\n\nsource\n\n\nDensityCrossValidation.fit\n\n DensityCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix (has to work with the folds specified via cvFolds)\n\n\ny\nnp.ndarray\nTarget values (has to work with the folds specified via cvFolds)\n\n\n\n\nScores for Single Fold\n\nsource\n\n\n\ngetFoldScore_wasserstein\n\n getFoldScore_wasserstein (estimator, parameterGrid, cvFold, p, X, y)"
  },
  {
    "objectID": "crossvalidation.html#cv---combined---wasserstein-distance",
    "href": "crossvalidation.html#cv---combined---wasserstein-distance",
    "title": "Cross Validation Functions",
    "section": "CV - Combined - Wasserstein Distance",
    "text": "CV - Combined - Wasserstein Distance\n\nsource\n\nDensityCrossValidationLSx\n\n DensityCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n                            parameterGridEstimator:dict,\n                            randomSearchLSx:bool=False,\n                            randomSearchEstimator:bool=False,\n                            nIterLSx:int=None, nIterEstimator:int=None,\n                            p:int=1, n_jobs:int=None,\n                            random_state:int=None)\n\nClass to efficiently tune the binSize parameter of all Level-Set based models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nestimatorLSx\n\n\nA Level-Set based model.\n\n\ncvFolds\n\n\nAn iterable yielding (train, test) splits as arrays of indices.\n\n\nparameterGridLSx\ndict\n\ndict or list of dicts with LSx parameters names (str) as keys and distributionsor lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nparameterGridEstimator\ndict\n\ndict or list of dicts with parameters names (str) of the point predictor as keysand distributions or lists of parameters to try. Distributions must provide a rvsmethod for sampling (such as those from scipy.stats.distributions).\n\n\nrandomSearchLSx\nbool\nFalse\nWhether to use randomized search or grid search for the LSx parameters.\n\n\nrandomSearchEstimator\nbool\nFalse\nWhether to use randomized search or grid search for the point predictor parameters.\n\n\nnIterLSx\nint\nNone\nNumber of parameter settings of the LSx model that are sampled if randomSearchLSx == True. LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settingsare evaluated for each point predictor parameter setting.\n\n\nnIterEstimator\nint\nNone\nNumber of parameter settings of the underlying point predictor that are sampled if randomSearchEstimator == True. nIterEstimator trades off runtime vs quality of the solution.\n\n\np\nint\n1\nThe order of the wasserstein distance to evaluate each hyperparameter settings.\n\n\nn_jobs\nint\nNone\nnumber of folds being computed in parallel.\n\n\nrandom_state\nint\nNone\nPseudo random number generator state used for random uniform sampling of parameter candidate values.Pass an int for reproducible output across multiple function calls.\n\n\n\n\nsource\n\n\nDensityCrossValidationLSx.fit\n\n DensityCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nX\nnp.ndarray\nFeature matrix (has to work with the folds specified via cvFolds)\n\n\ny\nnp.ndarray\nTarget values (has to work with the folds specified via cvFolds)\n\n\n\n\n# show_doc(CrossValidationLSx_combined.fit)\n\n\nScores for Single Fold\n\nsource\n\n\n\ngetFoldScoreLSx_wasserstein\n\n getFoldScoreLSx_wasserstein (estimatorLSx, parameterGridLSx,\n                              parameterGridEstimator, cvFold, p, X, y)"
  },
  {
    "objectID": "crossvalidation.html#helper-functions",
    "href": "crossvalidation.html#helper-functions",
    "title": "Cross Validation Functions",
    "section": "Helper Functions",
    "text": "Helper Functions\n\nGet Pinball Loss\n\nsource\n\n\ngetPinballLoss\n\n getPinballLoss (decisions, yTest, prob)\n\n\n\nGet Wasserstein Distances\n\nsource\n\n\ngetWassersteinDistances\n\n getWassersteinDistances (densities, yTest, p)\n\n\n\nGrouped Time Series Split\n\nsource\n\n\ngroupedTimeSeriesSplit\n\n groupedTimeSeriesSplit (data, kFolds, testLength, groupFeature,\n                         timeFeature)"
  },
  {
    "objectID": "loaddata.html",
    "href": "loaddata.html",
    "title": "Load Datasets",
    "section": "",
    "text": "source\n\n\n\n loadDataYaz (returnXY=True)\n\n\nsource\n\n\n\n\n loadDataYaz_multivariate (returnXY=True)"
  },
  {
    "objectID": "loaddata.html#yaz",
    "href": "loaddata.html#yaz",
    "title": "Load Datasets",
    "section": "",
    "text": "source\n\n\n\n loadDataYaz (returnXY=True)\n\n\nsource\n\n\n\n\n loadDataYaz_multivariate (returnXY=True)"
  },
  {
    "objectID": "loaddata.html#bakery",
    "href": "loaddata.html#bakery",
    "title": "Load Datasets",
    "section": "Bakery",
    "text": "Bakery\n\nsource\n\nloadDataBakery\n\n loadDataBakery (returnXY=True)"
  }
]