{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn\n",
    "  any point predictor into a conditional kernel density estimator.\n",
    "output-file: levelsetkdex_multivariate.html\n",
    "title: Level-Set Based Kernel Density Estimation for multivariate Predictors\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72025364-2e34-4aba-87de-ff5a8b382900",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81c92985-188d-484f-b270-521f5d2497bb",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate\n",
       "\n",
       ">      LevelSetKDEx_multivariate (estimator, binSize:int=None,\n",
       ">                                 equalBins:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | None | Size of the bins created while running fit. |\n",
       "| equalBins | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate\n",
       "\n",
       ">      LevelSetKDEx_multivariate (estimator, binSize:int=None,\n",
       ">                                 equalBins:bool=False)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | None | Size of the bins created while running fit. |\n",
       "| equalBins | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_multivariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f41ff",
   "metadata": {},
   "source": [
    "## LSx Multivariate Version with Theoretical Asymptotic Optimality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L264){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate_opt\n",
       "\n",
       ">      LevelSetKDEx_multivariate_opt (estimator, nClusters:int=None,\n",
       ">                                     minClusterSize:int=None)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "In this version of the LSx algorithm, we are grouping the point predictions of the samples specified via `X`\n",
       "based on a k-means clustering algorithm. The number of clusters is determined by the `nClusters` parameter.  \n",
       "In order to ensure theoretical asymptotic optimality of the algorithm, it has to be ensured that the number\n",
       "of training observations receiving positive weight is at least minClusterSize, while minClusterSize has to be \n",
       "an element of o(N) meaning minClusterSize / N -> 0 as N -> infinity.\n",
       "To ensure this, each cluster is checked for its size and clusters being smaller than minClusterSize have to be\n",
       "modified. For every cluster that is too small, we are recurvely searching for the closest other cluster until\n",
       "the size of the combined cluster is at least minClusterSize. The clusters are not actually merged in the traditional\n",
       "sense, though. Instead, we are creating new overlapping sets of samples that are used to compute the weights. \n",
       "Let's say we have three clusters A, B and C, minClusterSize = 10, the sizes of the clusters are 4, 4 and 20. Furthermore,\n",
       "assume B is closest to A and C closest to B. The set of indices are given then as follows:\n",
       "A: A + B + C\n",
       "B: B + C\n",
       "C: C\n",
       "This way it is ensured that the number of training observations receiving positive weight is at least 10 for every cluster. \n",
       "At the same time, the above algorithm ensure that the distance of the samples receiving positive weight*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | None | Number of clusters being created while running fit. |\n",
       "| minClusterSize | int | None | Minimum size of a cluster. If a cluster is smaller than this value, it will be merged with another cluster. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L264){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate_opt\n",
       "\n",
       ">      LevelSetKDEx_multivariate_opt (estimator, nClusters:int=None,\n",
       ">                                     minClusterSize:int=None)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "In this version of the LSx algorithm, we are grouping the point predictions of the samples specified via `X`\n",
       "based on a k-means clustering algorithm. The number of clusters is determined by the `nClusters` parameter.  \n",
       "In order to ensure theoretical asymptotic optimality of the algorithm, it has to be ensured that the number\n",
       "of training observations receiving positive weight is at least minClusterSize, while minClusterSize has to be \n",
       "an element of o(N) meaning minClusterSize / N -> 0 as N -> infinity.\n",
       "To ensure this, each cluster is checked for its size and clusters being smaller than minClusterSize have to be\n",
       "modified. For every cluster that is too small, we are recurvely searching for the closest other cluster until\n",
       "the size of the combined cluster is at least minClusterSize. The clusters are not actually merged in the traditional\n",
       "sense, though. Instead, we are creating new overlapping sets of samples that are used to compute the weights. \n",
       "Let's say we have three clusters A, B and C, minClusterSize = 10, the sizes of the clusters are 4, 4 and 20. Furthermore,\n",
       "assume B is closest to A and C closest to B. The set of indices are given then as follows:\n",
       "A: A + B + C\n",
       "B: B + C\n",
       "C: C\n",
       "This way it is ensured that the number of training observations receiving positive weight is at least 10 for every cluster. \n",
       "At the same time, the above algorithm ensure that the distance of the samples receiving positive weight*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | None | Number of clusters being created while running fit. |\n",
       "| minClusterSize | int | None | Minimum size of a cluster. If a cluster is smaller than this value, it will be merged with another cluster. |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_multivariate_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a831ecfe",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L492){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_DT\n",
       "\n",
       ">      LevelSetKDEx_DT (estimator, max_depth:int=8, min_samples_leaf:int=100)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| max_depth | int | 8 | Maximum depth of the decision tree used to generate the bins. |\n",
       "| min_samples_leaf | int | 100 | Minimum number of samples required to be in a bin. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L492){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_DT\n",
       "\n",
       ">      LevelSetKDEx_DT (estimator, max_depth:int=8, min_samples_leaf:int=100)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| max_depth | int | 8 | Maximum depth of the decision tree used to generate the bins. |\n",
       "| min_samples_leaf | int | 100 | Minimum number of samples required to be in a bin. |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30884783",
   "metadata": {},
   "source": [
    "## LSx Multivariate Gessaman Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L636){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate_bin\n",
       "\n",
       ">      LevelSetKDEx_multivariate_bin (estimator, nBinsPerDim:int=None)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "In this version of the LSx algorithm, we are applying the so-called Gessaman rule to create statistically\n",
       "equivalent blocks of samples. In essence, the algorithm is a multivariate extension of the univariate\n",
       "LevelSetKDEx algorithm based on bin-building. \n",
       "We are creating equally sized bins of samples based on the point predictions of the samples specified via `X`\n",
       "for every coordinate axis. Every bin of one axis is combined with the bins of all other axes resulting in\n",
       "a total of nBinsPerDim^dim many bins. \n",
       "Example: Let's say we have 100000 samples, the binSize is given as 20 and the number of dimension\n",
       "is 3. As the binSize is given as 20, we want to create 5000 bins alltogether. Hence, there have to be\n",
       "5000^(1/dim) = 5000^(1/3) = 17 bins per dimension. \n",
       "IMPORTANT NOTE: The getWeights function is not yet finished and has to be completed.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nBinsPerDim | int | None | Number of samples belonging to each bin. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_multivariate.py#L636){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_multivariate_bin\n",
       "\n",
       ">      LevelSetKDEx_multivariate_bin (estimator, nBinsPerDim:int=None)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. \n",
       "In this version of the LSx algorithm, we are applying the so-called Gessaman rule to create statistically\n",
       "equivalent blocks of samples. In essence, the algorithm is a multivariate extension of the univariate\n",
       "LevelSetKDEx algorithm based on bin-building. \n",
       "We are creating equally sized bins of samples based on the point predictions of the samples specified via `X`\n",
       "for every coordinate axis. Every bin of one axis is combined with the bins of all other axes resulting in\n",
       "a total of nBinsPerDim^dim many bins. \n",
       "Example: Let's say we have 100000 samples, the binSize is given as 20 and the number of dimension\n",
       "is 3. As the binSize is given as 20, we want to create 5000 bins alltogether. Hence, there have to be\n",
       "5000^(1/dim) = 5000^(1/3) = 17 bins per dimension. \n",
       "IMPORTANT NOTE: The getWeights function is not yet finished and has to be completed.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nBinsPerDim | int | None | Number of samples belonging to each bin. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_multivariate_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8dc43-8377-41b9-a5a7-aa5904038841",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f055de-89ce-4943-8242-8f434ee8a3f1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# import ipdb\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from datasetsDynamic.loadDataYaz import loadDataYaz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34541b1d-b3a9-4310-ae57-0918cbd18c14",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(testDays = 14,\n",
    "#                                                  daysToCut = 0,\n",
    "#                                                  normalizeDemand = True,\n",
    "#                                                  unstacked = True,\n",
    "#                                                  returnXY = True)\n",
    "\n",
    "# RF = RandomForestRegressor(n_estimators = 10, n_jobs = 1)\n",
    "# RF.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "# # Duplicate XTrain and yTrain m times\n",
    "# m = 1000\n",
    "# XTrain = np.vstack([XTrain for i in range(m)])\n",
    "# yTrain = np.vstack([yTrain for i in range(m)])\n",
    "\n",
    "# print(XTrain.shape)\n",
    "# print(yTrain.shape)\n",
    "\n",
    "# # Add gaussian to XTrain and yTrain\n",
    "# XTrain = XTrain + np.random.normal(0, 0.1, XTrain.shape)\n",
    "# yTrain = yTrain + np.random.normal(0, 0.1, yTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d36f76",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LSKDEx = LevelSetKDEx_multivariate_opt(estimator = RF, nClusters = 100, minClusterSize = 20)\n",
    "# LSKDEx.fit(X = XTrain, y = yTrain)\n",
    "\n",
    "# yPred = LSKDEx.estimator.predict(XTest).astype(np.float32)\n",
    "# clusters = LSKDEx.kmeans.assign(yPred)[1]\n",
    "\n",
    "# weightsDataList = LSKDEx.getWeights(X = XTest, outputType='onlyPositiveWeights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faa5708",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# centers = LSKDEx.centers\n",
    "# yPred = LSKDEx.yPredTrain\n",
    "\n",
    "# distances = cdist(yPred, centers, metric = 'euclidean')\n",
    "\n",
    "# minCenters = np.argmin(distances, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e14eb7",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 20 20 20 30 28 38 22 30 20 36 36 22 38]\n",
      "20\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# nPosValues = np.array([len(weightsDataList[i][0]) for i in range(len(weightsDataList))])\n",
    "# print(nPosValues)\n",
    "\n",
    "# lenIndices = np.array([len(LSKDEx.indicesPerBin[i]) for i in range(len(LSKDEx.indicesPerBin))])\n",
    "# print(min(lenIndices))\n",
    "# print(max(lenIndices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
