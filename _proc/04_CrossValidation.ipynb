{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Fill in a module description here\n",
    "output-file: crossvalidation.html\n",
    "title: Cross Validation Functions\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a800fac0-995f-41b1-b679-bf1eb76d7253",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6d5baf3-bf86-48cb-a771-3e6102407c0c",
   "metadata": {},
   "source": [
    "## CV - Pinball Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L30){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation\n",
       "\n",
       ">      QuantileCrossValidation (estimator, cvFolds, parameterGrid:dict,\n",
       ">                               randomSearch:bool=False, nIter:int=None,\n",
       ">                               probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       ">                               0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                               0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n",
       ">                               0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n",
       ">                               0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n",
       ">                               0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n",
       ">                               0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                               0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n",
       ">                               0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n",
       ">                               0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n",
       ">                               0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n",
       ">                               0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                               0.95, 0.96, 0.97, 0.98, 0.99],\n",
       ">                               refitPerProb:bool=False, n_jobs:int=None,\n",
       ">                               random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `estimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L30){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation\n",
       "\n",
       ">      QuantileCrossValidation (estimator, cvFolds, parameterGrid:dict,\n",
       ">                               randomSearch:bool=False, nIter:int=None,\n",
       ">                               probs:list=[0.01, 0.02, 0.03, 0.04, 0.05, 0.06,\n",
       ">                               0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14,\n",
       ">                               0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22,\n",
       ">                               0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3,\n",
       ">                               0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38,\n",
       ">                               0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46,\n",
       ">                               0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                               0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62,\n",
       ">                               0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7,\n",
       ">                               0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78,\n",
       ">                               0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86,\n",
       ">                               0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94,\n",
       ">                               0.95, 0.96, 0.97, 0.98, 0.99],\n",
       ">                               refitPerProb:bool=False, n_jobs:int=None,\n",
       ">                               random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `estimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L101){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation.fit\n",
       "\n",
       ">      QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L101){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidation.fit\n",
       "\n",
       ">      QuantileCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidation.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51812a-41e2-45c7-a653-ea662a3bff33",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore\n",
       "\n",
       ">      getFoldScore (estimator, parameterGrid, cvFold, probs, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L177){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore\n",
       "\n",
       ">      getFoldScore (estimator, parameterGrid, cvFold, probs, X, y)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35127f5a-0da0-496a-b35f-15afa09d8865",
   "metadata": {},
   "source": [
    "## CV - Combined - Pinball Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L248){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidationLSx\n",
       "\n",
       ">      QuantileCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n",
       ">                                  parameterGridEstimator:dict,\n",
       ">                                  randomSearchLSx:bool=False,\n",
       ">                                  randomSearchEstimator:bool=False,\n",
       ">                                  nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                  probs:list=[0.01, 0.02, 0.03, 0.04, 0.05,\n",
       ">                                  0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       ">                                  0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n",
       ">                                  0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n",
       ">                                  0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33,\n",
       ">                                  0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4,\n",
       ">                                  0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
       ">                                  0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                                  0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61,\n",
       ">                                  0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68,\n",
       ">                                  0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       ">                                  0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       ">                                  0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89,\n",
       ">                                  0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,\n",
       ">                                  0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                                  n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L248){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidationLSx\n",
       "\n",
       ">      QuantileCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n",
       ">                                  parameterGridEstimator:dict,\n",
       ">                                  randomSearchLSx:bool=False,\n",
       ">                                  randomSearchEstimator:bool=False,\n",
       ">                                  nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                  probs:list=[0.01, 0.02, 0.03, 0.04, 0.05,\n",
       ">                                  0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12,\n",
       ">                                  0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n",
       ">                                  0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26,\n",
       ">                                  0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33,\n",
       ">                                  0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4,\n",
       ">                                  0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
       ">                                  0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54,\n",
       ">                                  0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61,\n",
       ">                                  0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68,\n",
       ">                                  0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75,\n",
       ">                                  0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82,\n",
       ">                                  0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89,\n",
       ">                                  0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96,\n",
       ">                                  0.97, 0.98, 0.99], refitPerProb:bool=False,\n",
       ">                                  n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| probs | list | [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99] | iterable of floats between 0 and 1. These determine the p-quantiles being predicted <br>to evaluate performance of each parameter setting. |\n",
       "| refitPerProb | bool | False | If True, for each p-quantile a fitted LSF with best binSize to predict it is returned. <br>Otherwise only one LSF is returned that is best over all probs. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidationLSx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L353){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidationLSx.fit\n",
       "\n",
       ">      QuantileCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L353){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### QuantileCrossValidationLSx.fit\n",
       "\n",
       ">      QuantileCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(QuantileCrossValidationLSx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebcd6d0-7e5c-44c4-8916-22179a1d4bed",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(CrossValidationLSx_combined.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b971a422-b346-462d-81fd-79044fd43fc9",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L470){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScoreLSx\n",
       "\n",
       ">      getFoldScoreLSx (estimatorLSx, parameterGridLSx, parameterGridEstimator,\n",
       ">                       cvFold, probs, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L470){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScoreLSx\n",
       "\n",
       ">      getFoldScoreLSx (estimatorLSx, parameterGridLSx, parameterGridEstimator,\n",
       ">                       cvFold, probs, X, y)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScoreLSx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d81b7de-bc53-4a11-a063-c8c5346ec221",
   "metadata": {},
   "source": [
    "## CV - Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L562){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidation\n",
       "\n",
       ">      DensityCrossValidation (estimator, cvFolds, parameterGrid:dict,\n",
       ">                              randomSearch:bool=False, nIter:int=None, p:int=1,\n",
       ">                              n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `estimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| p | int | 1 | The order of the wasserstein distance to evaluate each hyperparameter settings. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L562){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidation\n",
       "\n",
       ">      DensityCrossValidation (estimator, cvFolds, parameterGrid:dict,\n",
       ">                              randomSearch:bool=False, nIter:int=None, p:int=1,\n",
       ">                              n_jobs:int=None, random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | An object with a `predict` method that must (!) have an argument called `probs`<br>that specifies which quantiles to predict. Further, `estimator` needs<br>a `set_params` and `fit` method. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGrid | dict |  | dict or list of dicts with parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearch | bool | False | Whether to use randomized search or grid search |\n",
       "| nIter | int | None | Number of parameter settings that are sampled if `randomSearch == True`. <br>n_iter trades off runtime vs quality of the solution. |\n",
       "| p | int | 1 | The order of the wasserstein distance to evaluate each hyperparameter settings. |\n",
       "| n_jobs | int | None | Number of jobs to run in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DensityCrossValidation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidation.fit\n",
       "\n",
       ">      DensityCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidation.fit\n",
       "\n",
       ">      DensityCrossValidation.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DensityCrossValidation.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f7b904-8f36-43ec-8fea-a13881f85ca4",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L670){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore_wasserstein\n",
       "\n",
       ">      getFoldScore_wasserstein (estimator, parameterGrid, cvFold, p, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L670){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScore_wasserstein\n",
       "\n",
       ">      getFoldScore_wasserstein (estimator, parameterGrid, cvFold, p, X, y)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScore_wasserstein)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c1cee6-9806-4618-8540-4e46a751076c",
   "metadata": {},
   "source": [
    "## CV - Combined - Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L737){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidationLSx\n",
       "\n",
       ">      DensityCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n",
       ">                                 parameterGridEstimator:dict,\n",
       ">                                 randomSearchLSx:bool=False,\n",
       ">                                 randomSearchEstimator:bool=False,\n",
       ">                                 nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                 p:int=1, n_jobs:int=None,\n",
       ">                                 random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| p | int | 1 | The order of the wasserstein distance to evaluate each hyperparameter settings. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L737){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidationLSx\n",
       "\n",
       ">      DensityCrossValidationLSx (estimatorLSx, cvFolds, parameterGridLSx:dict,\n",
       ">                                 parameterGridEstimator:dict,\n",
       ">                                 randomSearchLSx:bool=False,\n",
       ">                                 randomSearchEstimator:bool=False,\n",
       ">                                 nIterLSx:int=None, nIterEstimator:int=None,\n",
       ">                                 p:int=1, n_jobs:int=None,\n",
       ">                                 random_state:int=None)\n",
       "\n",
       "*Class to efficiently tune the `binSize` parameter of all Level-Set based models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimatorLSx |  |  | A Level-Set based model. |\n",
       "| cvFolds |  |  | An iterable yielding (train, test) splits as arrays of indices. |\n",
       "| parameterGridLSx | dict |  | dict or list of dicts with LSx parameters names (`str`) as keys and distributions<br>or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| parameterGridEstimator | dict |  | dict or list of dicts with parameters names (`str`) of the point predictor as keys<br>and distributions or lists of parameters to try. Distributions must provide a ``rvs``<br>method for sampling (such as those from scipy.stats.distributions). |\n",
       "| randomSearchLSx | bool | False | Whether to use randomized search or grid search for the LSx parameters. |\n",
       "| randomSearchEstimator | bool | False | Whether to use randomized search or grid search for the point predictor parameters. |\n",
       "| nIterLSx | int | None | Number of parameter settings of the LSx model that are sampled if `randomSearchLSx == True`. <br>LSx parameter settings are usually relatively cheap to evaluate, so all sampled LSx paramater settings<br>are evaluated for each point predictor parameter setting. |\n",
       "| nIterEstimator | int | None | Number of parameter settings of the underlying point predictor that are sampled if <br>`randomSearchEstimator == True`. nIterEstimator trades off runtime vs quality of the solution. |\n",
       "| p | int | 1 | The order of the wasserstein distance to evaluate each hyperparameter settings. |\n",
       "| n_jobs | int | None | number of folds being computed in parallel. |\n",
       "| random_state | int | None | Pseudo random number generator state used for random uniform sampling of parameter candidate values.<br>Pass an int for reproducible output across multiple function calls. |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DensityCrossValidationLSx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L831){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidationLSx.fit\n",
       "\n",
       ">      DensityCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L831){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DensityCrossValidationLSx.fit\n",
       "\n",
       ">      DensityCrossValidationLSx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | Feature matrix (has to work with the folds specified via `cvFolds`) |\n",
       "| y | ndarray | Target values (has to work with the folds specified via `cvFolds`) |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DensityCrossValidationLSx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568ec34-a9b7-4fb0-8ef8-d989565dd27f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(CrossValidationLSx_combined.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43405f85-b449-4604-b6a6-3f5963b55a7f",
   "metadata": {},
   "source": [
    "#### Scores for Single Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L893){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScoreLSx_wasserstein\n",
       "\n",
       ">      getFoldScoreLSx_wasserstein (estimatorLSx, parameterGridLSx,\n",
       ">                                   parameterGridEstimator, cvFold, p, X, y)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L893){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getFoldScoreLSx_wasserstein\n",
       "\n",
       ">      getFoldScoreLSx_wasserstein (estimatorLSx, parameterGridLSx,\n",
       ">                                   parameterGridEstimator, cvFold, p, X, y)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getFoldScoreLSx_wasserstein)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fada52-3351-4323-b0f0-d529a995de89",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb64052-b2ba-4cad-969b-8ee841266d9f",
   "metadata": {},
   "source": [
    "### Get Pinball Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L976){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getPinballLoss\n",
       "\n",
       ">      getPinballLoss (decisions, yTest, prob)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L976){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getPinballLoss\n",
       "\n",
       ">      getPinballLoss (decisions, yTest, prob)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getPinballLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff88d88-4610-47d4-9158-1134fa87ff2e",
   "metadata": {},
   "source": [
    "### Get Wasserstein Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L986){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getWassersteinDistances\n",
       "\n",
       ">      getWassersteinDistances (densities, yTest, p)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L986){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getWassersteinDistances\n",
       "\n",
       ">      getWassersteinDistances (densities, yTest, p)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getWassersteinDistances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a628cfb-028a-4d7e-ae23-5e459995d6e3",
   "metadata": {},
   "source": [
    "### Grouped Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L1015){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### groupedTimeSeriesSplit\n",
       "\n",
       ">      groupedTimeSeriesSplit (data, kFolds, testLength, groupFeature,\n",
       ">                              timeFeature)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/crossValidation.py#L1015){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### groupedTimeSeriesSplit\n",
       "\n",
       ">      groupedTimeSeriesSplit (data, kFolds, testLength, groupFeature,\n",
       ">                              timeFeature)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(groupedTimeSeriesSplit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f92782a-5fef-40fa-a501-01b0f5e99186",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4618d1-5d08-422c-a933-de29a16fc5a2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# from dddex.levelSetKDEx_univariate import *\n",
    "# from dddex.loadData import *\n",
    "\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# import time\n",
    "# import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a84312-b5f5-4bbe-8a3b-8df14742ddf8",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# data, XTrain, yTrain, XTest, yTest = loadDataBakery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00188f25-e9c4-4ee0-9cfc-efc5d0c6cef2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LGBM = LGBMRegressor(n_jobs = 1)\n",
    "# LGBM.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec950c1-d6d3-4f72-90db-d54ddffdf6fc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# dataTrain = data[data.label == 'train']\n",
    "\n",
    "# cvFolds = groupedTimeSeriesSplit(data = dataTrain, \n",
    "#                                  kFolds = 3, \n",
    "#                                  testLength = 28, \n",
    "#                                  groupFeature = 'id', \n",
    "#                                  timeFeature = 'dayIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac2395-da9b-4384-926b-3a6e15d9e19e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# paramGridEstimator = {'num_leaves': [20, 40, 60, 80, 100, 150],\n",
    "#                       'max_depth': [-1, 3, 4, 5, 6, 7],\n",
    "#                       'min_child_samples': [2, 4, 6, 8, 10, 13, 16, 20, 25, 50, 75, 100, 150, 200, 300, 400],\n",
    "#                       'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "#                       'n_estimators': [100, 200, 300, 400, 500, 600],\n",
    "#                       'subsample': [0.05, 0.1, 0.2, 0.3, 0.5, 0.75, 1],\n",
    "#                       'colsample_bytree': [0.05, 0.1, 0.2, 0.3, 0.5, 0.75, 1]}\n",
    "\n",
    "# CVEstimator = RandomizedSearchCV(estimator = LGBM,\n",
    "#                                  cv = cvFolds,\n",
    "#                                  param_distributions = paramGridEstimator,\n",
    "#                                  scoring = 'neg_mean_squared_error',\n",
    "#                                  n_iter = 100,\n",
    "#                                  refit = True,\n",
    "#                                  n_jobs = len(cvFolds),\n",
    "#                                  return_train_score = True,\n",
    "#                                  verbose = 0)\n",
    "\n",
    "# CVEstimator.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff99d3bd-5951-4043-bd80-bc8a30b6cafc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# # LSKDEx = LevelSetKDEx(estimator = CVEstimator.best_estimator_)\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM)\n",
    "\n",
    "# paramGridLSx = {'binSize': [10, 20, 35, 50, 75, 100, 150, 200, 250, 400, 600, 800, 1000],\n",
    "#                 'weightsByDistance': [True, False]}\n",
    "\n",
    "# CV = DensityCrossValidation(estimator = LSKDEx,\n",
    "#                             cvFolds = cvFolds,\n",
    "#                             parameterGrid = paramGridLSx,\n",
    "#                             n_jobs = len(cvFolds),\n",
    "#                             randomSearch = True,\n",
    "#                             nIter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a7337-fddd-4390-9a1a-5bba3a2ebd98",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# ps = ParameterSampler(param_distributions = paramGridLSx, n_iter = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc17feb-677a-4cbd-a18c-506ba4d2376b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# list(ps.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bcbea6-959a-44e2-aef0-38eb3b01ba09",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# CV.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d897af8-d8fd-4170-a1ed-7702d2ea2cca",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# CV.cvResults"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddex",
   "language": "python",
   "name": "dddex"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
