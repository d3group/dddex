{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn\n",
    "  any point predictor into a conditional kernel density estimator.\n",
    "output-file: levelsetkdex_univariate.html\n",
    "title: Level-Set Based Kernel Density Estimation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b8315b-c072-4e14-b477-5856b5d922fe",
   "metadata": {},
   "source": [
    "In the following we define the classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) where KDE is short for 'Kernel Density Estimator' and the 'x' is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name 'LevelSet' stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument `estimator` and must have a `.predict()`-method and should have been trained before hand. \n",
    "\n",
    "Both classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) fulfill the same task: By first running `.fit(XTrain, yTrain)` and then calling `.generateWeights(XTest)`, they both output an estimation of the conditional density of every sample specified by 'XTest'. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via `estimator.predict(XTrain)` and `estimator.predict(XTest)`, respectively. Based on this comparison, we select 'binSize'-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn). Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\n",
    "\n",
    "Further details on how both approaches work approaches can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Bin Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=100, weightsByDistance:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=100, weightsByDistance:bool=False)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7fdb5bf-f39d-470f-b7cc-8679e733b2c6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L73){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.fit\n",
       "\n",
       ">      LevelSetKDEx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "*Fit [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) model by grouping the point predictions of the samples specified via `X`\n",
       "according to their value. Samples are recursively sorted into bins until each bin contains\n",
       "`binSize` many samples. For details, checkout the function [`generateBins`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#generatebins) which does the\n",
       "heavy lifting.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L73){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.fit\n",
       "\n",
       ">      LevelSetKDEx.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "*Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n",
       "according to their value. Samples are recursively sorted into bins until each bin contains\n",
       "`binSize` many samples. For details, checkout the function `generateBins` which does the\n",
       "heavy lifting.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cca538d-96ff-48df-9e29-8573a6442a05",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.getWeights\n",
       "\n",
       ">      LevelSetKDEx.getWeights (X:numpy.ndarray,\n",
       ">                               outputType:str='onlyPositiveWeights',\n",
       ">                               scalingList:list=None)\n",
       "\n",
       "*Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx.getWeights\n",
       "\n",
       ">      LevelSetKDEx.getWeights (X:numpy.ndarray,\n",
       ">                               outputType:str='onlyPositiveWeights',\n",
       ">                               scalingList:list=None)\n",
       "\n",
       "*Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e147-5acc-4593-b3a5-e93f2d82447f",
   "metadata": {},
   "source": [
    "#### Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450b9d07-e1af-49e1-8709-5575002f1bdb",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L394){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the bin-structure used by [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L394){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the bin-structure used by `LevelSetKDEx` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(generateBins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a53ad6",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on DRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefe1ce",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| export\n",
    "\n",
    "# from drf import drf \n",
    "\n",
    "# class LevelSetKDEx_DRF(BaseWeightsBasedEstimator, BaseLSx):\n",
    "#     \"\"\"\n",
    "#     `LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
    "#     The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
    "#     as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
    "#     recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
    "#     a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
    "#     would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
    "#     of this test sample.    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     def __init__(self, \n",
    "#                  estimator, # Model with a .fit and .predict-method (implementing the scikit-learn estimator interface).\n",
    "#                  binSize: int=100, # Size of the bins created while running fit.\n",
    "#                  ):\n",
    "        \n",
    "#         super(BaseEstimator, self).__init__(estimator = estimator)\n",
    "\n",
    "#         # Check if binSize is integer\n",
    "#         if not isinstance(binSize, (int, np.int32, np.int64)):\n",
    "#             raise ValueError(\"'binSize' must be an integer!\")\n",
    "\n",
    "#         self.binSize = binSize\n",
    "        \n",
    "#         self.yTrain = None\n",
    "#         self.yPredTrain = None\n",
    "#         self.drf = None\n",
    "#         self.fitted = False\n",
    "    \n",
    "#     #---\n",
    "    \n",
    "#     def fit(self: LevelSetKDEx_DRF, \n",
    "#             X: np.ndarray, # Feature matrix used by `estimator` to predict `y`.\n",
    "#             y: np.ndarray, # 1-dimensional target variable corresponding to the feature matrix `X`.\n",
    "#             ):\n",
    "#         \"\"\"\n",
    "#         Fit `LevelSetKDEx` model by grouping the point predictions of the samples specified via `X`\n",
    "#         according to their value. Samples are recursively sorted into bins until each bin contains\n",
    "#         `binSize` many samples. For details, checkout the function `generateBins` which does the\n",
    "#         heavy lifting.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Checks\n",
    "#         if not isinstance(self.binSize, (int, np.int32, np.int64)):\n",
    "#             raise ValueError(\"'binSize' must be an integer!\")\n",
    "            \n",
    "#         if self.binSize > y.shape[0]:\n",
    "#             raise ValueError(\"'binSize' mustn't be bigger than the size of 'y'!\")\n",
    "        \n",
    "#         if X.shape[0] != y.shape[0]:\n",
    "#             raise ValueError(\"'X' and 'y' must contain the same number of samples!\")\n",
    "        \n",
    "#         #---\n",
    "        \n",
    "#         try:\n",
    "#             yPred = self.estimator.predict(X)\n",
    "            \n",
    "#         except NotFittedError:\n",
    "#             try:\n",
    "#                 self.estimator.fit(X = X, y = y)                \n",
    "#             except:\n",
    "#                 raise ValueError(\"Couldn't fit 'estimator' with user specified 'X' and 'y'!\")\n",
    "#             else:\n",
    "#                 yPred = self.estimator.predict(X)\n",
    "        \n",
    "#         #---\n",
    "        \n",
    "#         yPred = pd.DataFrame(yPred)\n",
    "#         y = pd.Series(y)\n",
    "\n",
    "#         DRF = drf(min_node_size = self.binSize, num_trees = 100, num_features = 1, honesty = False, sample_fraction = 0.5, response_scaling = False, mtry = 1, num_threads = 16)\n",
    "#         DRF.fit(X = yPred, Y = y)\n",
    "        \n",
    "#         #---\n",
    "        \n",
    "#         # IMPORTANT: In case 'y' is given as a pandas.Series, we can potentially run into indexing \n",
    "#         # problems later on.\n",
    "#         self.yTrain = y.ravel()\n",
    "        \n",
    "#         self.yPredTrain = yPred\n",
    "#         self.drf = DRF\n",
    "#         self.fitted = True\n",
    "        \n",
    "#     #---\n",
    "    \n",
    "#     def getWeights(self: LevelSetKDEx_DRF, \n",
    "#                    X: np.ndarray, # Feature matrix for which conditional density estimates are computed.\n",
    "#                    # Specifies structure of the returned density estimates. One of: \n",
    "#                    # 'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized'\n",
    "#                    outputType: str='onlyPositiveWeights', \n",
    "#                    # Optional. List with length X.shape[0]. Values are multiplied to the estimated \n",
    "#                    # density of each sample for scaling purposes.\n",
    "#                    scalingList: list=None, \n",
    "#                    ) -> list: # List whose elements are the conditional density estimates for the samples specified by `X`.\n",
    "        \n",
    "#         # __annotations__ = BaseWeightsBasedEstimator.getWeights.__annotations__\n",
    "#         __doc__ = BaseWeightsBasedEstimator.getWeights.__doc__\n",
    "        \n",
    "#         if not self.fitted:\n",
    "#             raise NotFittedError(\"This LevelSetKDEx instance is not fitted yet. Call 'fit' with \"\n",
    "#                                  \"appropriate arguments before trying to compute weights.\")\n",
    "        \n",
    "#         #---\n",
    "        \n",
    "#         yPred = self.estimator.predict(X)\n",
    "#         yPred = pd.DataFrame(yPred)\n",
    "        \n",
    "#         weightsArray = self.drf.predict(yPred).weights\n",
    "#         weightsList = list(weightsArray)\n",
    "#         weightsDataList = [(weights[weights > 0], np.where(weights > 0)[0]) for weights in weightsList]\n",
    "\n",
    "#         weightsDataList = restructureWeightsDataList(weightsDataList = weightsDataList, \n",
    "#                                                      outputType = outputType, \n",
    "#                                                      y = self.yTrain,\n",
    "#                                                      scalingList = scalingList,\n",
    "#                                                      equalWeights = True)\n",
    "        \n",
    "#         return weightsDataList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad7d9c-07e5-488d-81e5-21f94259ed1a",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L435){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_RBF\n",
       "\n",
       ">      LevelSetKDEx_RBF (estimator, lengthScale:float=1)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| lengthScale | float | 1 | Size of the bins created while running fit. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L435){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_RBF\n",
       "\n",
       ">      LevelSetKDEx_RBF (estimator, lengthScale:float=1)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| lengthScale | float | 1 | Size of the bins created while running fit. |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd550e-ae6e-44fe-a91b-f0ffee0096bc",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L540){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int=100,\n",
       ">                        weightsByDistance:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE: In contrast to the standard [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex), it is possible to apply\n",
       "[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) to arbitrary dimensional point predictors.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L540){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int=100,\n",
       ">                        weightsByDistance:bool=False)\n",
       "\n",
       "*`LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
       "`LevelSetKDEx_kNN` to arbitrary dimensional point predictors.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9daa50-ef7b-4858-b343-b212f07a02b9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L585){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.fit\n",
       "\n",
       ">      LevelSetKDEx_kNN.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "*Fit [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) model by applying the nearest neighbors algorithm to the point\n",
       "predictions of the samples specified by `X` based on `estimator`.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L585){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.fit\n",
       "\n",
       ">      LevelSetKDEx_kNN.fit (X:numpy.ndarray, y:numpy.ndarray)\n",
       "\n",
       "*Fit `LevelSetKDEx_kNN` model by applying the nearest neighbors algorithm to the point\n",
       "predictions of the samples specified by `X` based on `estimator`.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | np.ndarray | Feature matrix used by `estimator` to predict `y`. |\n",
       "| y | np.ndarray | 1-dimensional target variable corresponding to the feature matrix `X`. |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_kNN.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97f4603-b305-464c-a67b-45ff7be439ae",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L640){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.getWeights\n",
       "\n",
       ">      LevelSetKDEx_kNN.getWeights (X:numpy.ndarray,\n",
       ">                                   outputType:str='onlyPositiveWeights',\n",
       ">                                   scalingList:list=None)\n",
       "\n",
       "*Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L640){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN.getWeights\n",
       "\n",
       ">      LevelSetKDEx_kNN.getWeights (X:numpy.ndarray,\n",
       ">                                   outputType:str='onlyPositiveWeights',\n",
       ">                                   scalingList:list=None)\n",
       "\n",
       "*Computes estimated conditional density for each sample specified by `X`. The concrete structure of each element \n",
       "of the returned list depends on the specified value of `outputType`:\n",
       "\n",
       "- **all**: An array with the same length as the number of training samples. Each entry represents the probability \n",
       "  of each training sample.\n",
       "- **onlyPositiveWeights**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the indices of the corresponding training sample. Only probalities greater than zero are returned. \n",
       "  Note: This is the most memory and computationally efficient output type.\n",
       "- **summarized**: A tuple. The first element of the tuple represents the probabilities and the second one the \n",
       "  corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.\n",
       "- **cumDistribution**: A tuple. The first element of the tuple represents the probabilities and the second \n",
       "  one the corresponding value of `yTrain`.\n",
       "- **cumDistributionSummarized**: A tuple. The first element of the tuple represents the probabilities and \n",
       "  the second one the corresponding value of `yTrain`. The probabilities corresponding to identical values of `yTrain` are aggregated.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | np.ndarray |  | Feature matrix for which conditional density estimates are computed. |\n",
       "| outputType | str | onlyPositiveWeights | Specifies structure of the returned density estimates. One of: <br>'all', 'onlyPositiveWeights', 'summarized', 'cumDistribution', 'cumDistributionSummarized' |\n",
       "| scalingList | list | None | Optional. List with length X.shape[0]. Values are multiplied to the estimated <br>density of each sample for scaling purposes. |\n",
       "| **Returns** | **list** |  | **List whose elements are the conditional density estimates for the samples specified by `X`.** |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_kNN.getWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10822979-f3a5-4612-bfed-c6cca4b341a6",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L727){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_NN\n",
       "\n",
       ">      LevelSetKDEx_NN (estimator, binSize:int=100, efficientRAM:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE: In contrast to the standard [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex), it is possible to apply\n",
       "[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) to arbitrary dimensional point predictors.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| efficientRAM | bool | False | Setting 'efficientRAM = TRUE' is only necessary when there are roughly umore than 200k training observations to avoid<br>an overusage of RAM. This setting causes the run-time of the algorithm of the weights computation to linearly depend on <br>'binSize'. Because of that the algorithm becomes quite slow for 'binSize' > 10k'. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L727){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_NN\n",
       "\n",
       ">      LevelSetKDEx_NN (estimator, binSize:int=100, efficientRAM:bool=False)\n",
       "\n",
       "*`LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.\n",
       "\n",
       "NOTE: In contrast to the standard `LevelSetKDEx`, it is possible to apply\n",
       "`LevelSetKDEx_kNN` to arbitrary dimensional point predictors.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| efficientRAM | bool | False | Setting 'efficientRAM = TRUE' is only necessary when there are roughly umore than 200k training observations to avoid<br>an overusage of RAM. This setting causes the run-time of the algorithm of the weights computation to linearly depend on <br>'binSize'. Because of that the algorithm becomes quite slow for 'binSize' > 10k'. |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f7a117-4626-4d16-b690-77632727bc7b",
   "metadata": {},
   "source": [
    "### Get Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L870){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighbors\n",
       "\n",
       ">      getNeighbors (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the neighboorhoods used by [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L870){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighbors\n",
       "\n",
       ">      getNeighbors (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the neighboorhoods used by `LevelSetKDEx` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getNeighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bdbc68-a9ce-4384-a9f3-00b7a6adcf33",
   "metadata": {},
   "source": [
    "### Get Neighbor Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1084){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighborsTest\n",
       "\n",
       ">      getNeighborsTest (binSize:int, yPred:numpy.ndarray,\n",
       ">                        yPredTrain:numpy.ndarray, neighborsDictTrain:dict)\n",
       "\n",
       "*Used to generate the neighboorhoods used by [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |\n",
       "| yPredTrain | np.ndarray | 1-dimensional array of predicted train values. |\n",
       "| neighborsDictTrain | dict | Dict containing the neighbors of all train samples. Keys are the train predictions. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1084){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighborsTest\n",
       "\n",
       ">      getNeighborsTest (binSize:int, yPred:numpy.ndarray,\n",
       ">                        yPredTrain:numpy.ndarray, neighborsDictTrain:dict)\n",
       "\n",
       "*Used to generate the neighboorhoods used by `LevelSetKDEx` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | np.ndarray | 1-dimensional array of predicted values. |\n",
       "| yPredTrain | np.ndarray | 1-dimensional array of predicted train values. |\n",
       "| neighborsDictTrain | dict | Dict containing the neighbors of all train samples. Keys are the train predictions. |"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getNeighborsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7168278-74bf-4af3-ba23-525d490d2bfb",
   "metadata": {},
   "source": [
    "### Get Kernel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1185){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getKernelValues\n",
       "\n",
       ">      getKernelValues (yPred, yPredTrain, neighborsDictTest,\n",
       ">                       neighborsDictTrain, neighborsRemoved, neighborsAdded,\n",
       ">                       binSize, efficientRAM=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1185){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getKernelValues\n",
       "\n",
       ">      getKernelValues (yPred, yPredTrain, neighborsDictTest,\n",
       ">                       neighborsDictTrain, neighborsRemoved, neighborsAdded,\n",
       ">                       binSize, efficientRAM=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getKernelValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc893f",
   "metadata": {},
   "source": [
    "## Level-Set Approach based on Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1308){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_clustering\n",
       "\n",
       ">      LevelSetKDEx_clustering (estimator, nClusters:int=10)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1308){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_clustering\n",
       "\n",
       ">      LevelSetKDEx_clustering (estimator, nClusters:int=10)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1464){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_clustering2\n",
       "\n",
       ">      LevelSetKDEx_clustering2 (estimator, nClusters:int=10)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1464){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_clustering2\n",
       "\n",
       ">      LevelSetKDEx_clustering2 (estimator, nClusters:int=10)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_clustering2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81936321-7fe7-4b27-91e3-a4a1444bd29e",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523b02c-ce7b-4969-81e7-d09e60db3446",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataBakery(returnXY = True)\n",
    "\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbeb117",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# LSKDEx_drf = LevelSetKDEx_DRF(estimator = LGBM, binSize = 100)\n",
    "# LSKDEx_drf.fit(XTrain, yTrain)\n",
    "\n",
    "# weightsDataList = LSKDEx_drf.getWeights(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68573e98",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# weights = LSKDEx.getWeights(XTest)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb537e0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb0dd13",
   "metadata": {},
   "source": [
    "# LSx based on DRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f87b4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# import ipdb\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from dddex.loadData import *\n",
    "# from dddex.wSAA import RandomForestWSAA, SampleAverageApproximation\n",
    "# import time \n",
    "# import psutil\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# from drf import drf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802f3d5-dd37-4e08-b192-1b2fe558170e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# data, XTrain, yTrain, XTest, yTest = loadDataBakery(returnXY = True)\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)\n",
    "\n",
    "# LSKDEx = LevelSetKDEx_RBF(estimator = LGBM, lengthScale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e058f-1b3f-458e-a57a-28a9d278886a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LSKDEx.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bf9b0-c2a2-4a5d-ab60-e71ce3c04257",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# weightsData = LSKDEx.getWeights(XTest[100:200], outputType = 'summarized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928c9b5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(returnXY = True)\n",
    "\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)\n",
    "# yPredTrain = LGBM.predict(XTrain)\n",
    "# yPredTest = LGBM.predict(XTest)\n",
    "\n",
    "# yPredTrain = pd.DataFrame(yPredTrain)\n",
    "# yPredTest = pd.DataFrame(yPredTest)\n",
    "# yTrain = pd.Series(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bddde6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# DRF = drf(min_node_size = 100, num_trees = 500, num_features = 1, honesty = False, sample_fraction = 0.5, response_scaling = False, mtry = 1, num_threads = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591c551",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# DRF.fit(yPredTrain, yTrain)\n",
    "# weights = DRF.predict(yPredTest).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059af05",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    366.000000\n",
       "mean       0.002732\n",
       "std        0.002423\n",
       "min        0.000020\n",
       "25%        0.000590\n",
       "50%        0.001994\n",
       "75%        0.004667\n",
       "max        0.009120\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "\n",
    "# # Get statistic of weights of first row#\n",
    "# weightsRow = weights[0]\n",
    "# pd.Series(weightsRow[weightsRow > 0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29717899",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx_clustering2(estimator = LGBM, nClusters = 100)\n",
    "\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# weights = LSKDEx.getWeights(XTest)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9c86d-137e-4d85-a4dc-211987b98589",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# path = '/home/kagu/SID/data/dataSID.csv'\n",
    "# data = pd.read_csv(path)\n",
    "\n",
    "# ids = data.id.unique()[0:30]\n",
    "# filtering = [ID in ids for ID in data.id]\n",
    "# data = data[filtering]\n",
    "\n",
    "# X = np.array(data.drop(['demand', 'date', 'id', 'label'], axis = 1))\n",
    "# Y = np.array(data['demand'])\n",
    "\n",
    "# indicesTrain = data['label'] == 'train'\n",
    "# indicesTest = data['label'] == 'test'\n",
    "\n",
    "# XTrain = X[indicesTrain]\n",
    "# yTrain = Y[indicesTrain]\n",
    "\n",
    "# XTest = X[indicesTest]\n",
    "# yTest = Y[indicesTest]\n",
    "\n",
    "# dataTrain = data[indicesTrain]\n",
    "# dataTest = data[indicesTest]\n",
    "\n",
    "# scalingList = dataTest['scalingValue'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6e066-7688-4d99-9dff-b7b2b0ce8859",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9e826-dadc-45ba-872f-a66e4fd72c8b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# process = psutil.Process(os.getpid())\n",
    "# print(f\"Memory used by Jupyter notebook: {process.memory_info().rss / 2**20:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764f024-c9fd-429b-b1f9-fe4503e0ecbb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beaf70-9c79-4704-82d9-5a284e0823ad",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 5000)\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# print(time.time() - start)\n",
    "\n",
    "# yPredTrain = LSKDEx.yPredTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523732cb-67da-467e-acf2-186df68d5569",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTrain[LSKDEx.neighborsDictTrain[list(LSKDEx.neighborsDictTrain.keys())[100]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322eb337-a075-4f47-aa2e-780b1a05fe6d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTrain[LSKDEx.neighborsDictTrain[np.array(list(LSKDEx.neighborsDictTrain.keys()))[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388de86-a5f8-41d8-90d8-aecb3e576ae2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# weights = LSKDEx.getWeights(XTest, efficientRAM = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1a641-e3f3-49da-9dbe-9a9f60467161",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# res = LSKDEx.predict(XTest,\n",
    "#                      probs = [0.1, 0.5], \n",
    "#                      scalingList = scalingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53d7c1-72a5-4525-9b13-e6db6dd9f02a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# process = psutil.Process(os.getpid())\n",
    "# print(f\"Memory used by Jupyter notebook: {process.memory_info().rss / 2**20:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3ba66-1f21-44e0-b3d9-183b8c44d9ec",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# XTrainMod = XTrain[0:10000]\n",
    "# yTrainMod = yTrain[0:10000]\n",
    "# XTestMod = XTest[0:10]\n",
    "\n",
    "# yPredTrainMod = LGBM.predict(XTrainMod)\n",
    "# yPredTestMod = LGBM.predict(XTestMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36723cd7-309b-462d-8d26-829b1854f54e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "# LSKDEx.fit(XTrainMod, yTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ccaac-40eb-4023-a71d-50c5914dc940",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# #| hide\n",
    "\n",
    "# res = LSKDEx.solveKernelGLS(X = XTrainMod, sigma = 0.5, c = yPredTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a97a0-0779-4d0f-ae4c-f2ca0a61ed3d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# #| hide\n",
    "# res = LSKDEx.getKernelVectorProduct(X1 = XTrainMod, c = yPredTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17f57e-d639-4d71-a0cf-652aff9ebebc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# mean, cov = LSKDEx.getGaussianPosterior(XTrain = XTrainMod, \n",
    "#                                         XTest = XTestMod,\n",
    "#                                         yTrain = yTrainMod,\n",
    "#                                         sigma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e6185-06ec-4182-8719-5a75d2712d95",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTest = LSKDEx.estimator.predict(XTest)\n",
    "# binPerPredTest = np.searchsorted(a = LSKDEx.lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "\n",
    "# binVectorsTest = [(binPerPredTest == i).reshape(-1, 1) * 1 for i in range(len(LSKDEx.lowerBoundPerBin))]\n",
    "# binVectorsToSliceTest = [np.where(binVector)[0] for binVector in binVectorsTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2273a6-a5c4-4e5f-bf9f-f9fe5a6f432f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# v = binVectorsToSliceTest[2]\n",
    "# cov[v[:, None],  v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8dbd5-5255-4646-86b9-494611148717",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d65fd-a8b4-4649-aea5-e73d04723d81",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# pd.Series(np.ravel(mean)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2db3cb-f6d6-406d-be91-5bcccf5acb7e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# pd.Series(yTest).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebeec7-8a14-46f7-8c85-c19fa6bde752",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPred = np.concatenate([np.arange(5000)] * 2, axis = 0)\n",
    "# yPredTrain = np.concatenate([np.arange(50000)] * 2, axis = 0)\n",
    "# binSize = 200\n",
    "\n",
    "# neighborsDictTrain, neighborsRemoved, neighborsAdded = generateNeighborhoodsUnique(binSize = binSize,\n",
    "#                                                                                yPred = yPredTrain)\n",
    "\n",
    "# neighborsDictTest = generateNeighborhoodsTestUnique(binSize = binSize,\n",
    "#                                                 yPred = yPred,\n",
    "#                                                 yPredTrain = yPredTrain,\n",
    "#                                                 neighborsDictTrain = neighborsDictTrain)\n",
    "\n",
    "# start = time.time()\n",
    "# kernelValuesList = getKernelValues(binSize = binSize,\n",
    "#                                    yPred = yPred,\n",
    "#                                    yPredTrain = yPredTrain,\n",
    "#                                    neighborsDictTest = neighborsDictTest,\n",
    "#                                    neighborsDictTrain = neighborsDictTrain,\n",
    "#                                    neighborsRemoved = neighborsRemoved,\n",
    "#                                    neighborsAdded = neighborsAdded)\n",
    "# print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
