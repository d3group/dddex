{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Defining the classes `LevelSetKDEx` and `LevelSetKDEx_kNN` which turn\n",
    "  any point predictor into a conditional kernel density estimator.\n",
    "output-file: levelsetkdex_univariate.html\n",
    "title: Level-Set Based Kernel Density Estimation\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61516f21-8606-49d3-8907-c0190315ac26",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21b8315b-c072-4e14-b477-5856b5d922fe",
   "metadata": {},
   "source": [
    "In the following we define the classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) where KDE is short for 'Kernel Density Estimator' and the 'x' is supposed to signal that both classes can be defined based on any arbitrary point predictor. The name 'LevelSet' stems from the fact that every approach presented in this notebook interprets the values of the point forecasts as a similarity measure between samples. The point predictor is specified by the argument `estimator` and must have a `.predict()`-method and should have been trained before hand. \n",
    "\n",
    "Both classes [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) fulfill the same task: By first running `.fit(XTrain, yTrain)` and then calling `.generateWeights(XTest)`, they both output an estimation of the conditional density of every sample specified by 'XTest'. The basic idea for both approaches is also identical: Suppose we have a single test sample at hand. At first, we compare the value of the point prediction of this sample and the values of the point predictions of the training samples computed via `estimator.predict(XTrain)` and `estimator.predict(XTest)`, respectively. Based on this comparison, we select 'binSize'-many training samples that we deem the most similar to the test sample at hand. The concrete way we select the training samples constitutes the only difference between [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) and [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn). Finally, the empirical distribution of the y-values of these training samples then acts as our estimation of the conditional distribution.\n",
    "\n",
    "Further details on how both approaches work approaches can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a75d0-8a2c-4482-b372-6e67bf394d86",
   "metadata": {},
   "source": [
    "## LSx Bin Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=100, weightsByDistance:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L33){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx\n",
       "\n",
       ">      LevelSetKDEx (estimator, binSize:int=100, weightsByDistance:bool=False)\n",
       "\n",
       "*`LevelSetKDEx` turns any point forecasting model into an estimator of the underlying conditional density.\n",
       "The name 'LevelSet' stems from the fact that this approach interprets the values of the point forecasts\n",
       "as a similarity measure between samples. The point forecasts of the training samples are sorted and \n",
       "recursively assigned to a bin until the size of the current bin reaches `binSize` many samples. Then\n",
       "a new bin is created and so on. For a new test sample we check into which bin its point prediction\n",
       "would have fallen and interpret the training samples of that bin as the empirical distribution function\n",
       "of this test sample.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661e147-5acc-4593-b3a5-e93f2d82447f",
   "metadata": {},
   "source": [
    "### Generate Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L394){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the bin-structure used by [`LevelSetKDEx`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L394){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### generateBins\n",
       "\n",
       ">      generateBins (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the bin-structure used by `LevelSetKDEx` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(generateBins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3ed69f-e3f7-49f7-a7a0-872a5c4b9446",
   "metadata": {},
   "source": [
    "## LSx Neighbors-Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L435){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_NN\n",
       "\n",
       ">      LevelSetKDEx_NN (estimator, binSize:int=100, efficientRAM:bool=False)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| efficientRAM | bool | False | Setting 'efficientRAM = TRUE' is only necessary when there are roughly umore than 200k training observations to avoid<br>an overusage of RAM. This setting causes the run-time of the algorithm of the weights computation to linearly depend on <br>'binSize'. Because of that the algorithm becomes quite slow for 'binSize' > 10k'. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L435){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_NN\n",
       "\n",
       ">      LevelSetKDEx_NN (estimator, binSize:int=100, efficientRAM:bool=False)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| efficientRAM | bool | False | Setting 'efficientRAM = TRUE' is only necessary when there are roughly umore than 200k training observations to avoid<br>an overusage of RAM. This setting causes the run-time of the algorithm of the weights computation to linearly depend on <br>'binSize'. Because of that the algorithm becomes quite slow for 'binSize' > 10k'. |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e85ced-5275-4e54-a939-063e76c28cec",
   "metadata": {},
   "source": [
    "### Get Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L565){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighbors\n",
       "\n",
       ">      getNeighbors (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the neighboorhoods used by [`LevelSetKDEx_NN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_nn) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L565){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighbors\n",
       "\n",
       ">      getNeighbors (binSize:int, yPred:numpy.ndarray)\n",
       "\n",
       "*Used to generate the neighboorhoods used by `LevelSetKDEx_NN` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getNeighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6457cc1c-536a-41e7-8531-ff4f3ceed01d",
   "metadata": {},
   "source": [
    "### Get Neighbor Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L779){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighborsTest\n",
       "\n",
       ">      getNeighborsTest (binSize:int, yPred:numpy.ndarray,\n",
       ">                        yPredTrain:numpy.ndarray, neighborsDictTrain:dict)\n",
       "\n",
       "*Used to generate the neighboorhoods used by [`LevelSetKDEx_NN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_nn) to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |\n",
       "| yPredTrain | ndarray | 1-dimensional array of predicted train values. |\n",
       "| neighborsDictTrain | dict | Dict containing the neighbors of all train samples. Keys are the train predictions. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L779){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getNeighborsTest\n",
       "\n",
       ">      getNeighborsTest (binSize:int, yPred:numpy.ndarray,\n",
       ">                        yPredTrain:numpy.ndarray, neighborsDictTrain:dict)\n",
       "\n",
       "*Used to generate the neighboorhoods used by `LevelSetKDEx_NN` to compute density estimations.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| binSize | int | Size of the bins of values of `yPred` being grouped together. |\n",
       "| yPred | ndarray | 1-dimensional array of predicted values. |\n",
       "| yPredTrain | ndarray | 1-dimensional array of predicted train values. |\n",
       "| neighborsDictTrain | dict | Dict containing the neighbors of all train samples. Keys are the train predictions. |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getNeighborsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fddef80-4efa-44e0-857e-3ccf94cccce4",
   "metadata": {},
   "source": [
    "### Get Kernel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L880){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getKernelValues\n",
       "\n",
       ">      getKernelValues (yPred, yPredTrain, neighborsDictTest,\n",
       ">                       neighborsDictTrain, neighborsRemoved, neighborsAdded,\n",
       ">                       binSize, efficientRAM=False)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L880){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### getKernelValues\n",
       "\n",
       ">      getKernelValues (yPred, yPredTrain, neighborsDictTest,\n",
       ">                       neighborsDictTrain, neighborsRemoved, neighborsAdded,\n",
       ">                       binSize, efficientRAM=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(getKernelValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8e94a-11ab-4edf-9a9e-94be53e5324f",
   "metadata": {},
   "source": [
    "## LSx kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1003){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int=100,\n",
       ">                        weightsByDistance:bool=False)\n",
       "\n",
       "*[`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the [`LevelSetKDEx_kNN`](https://kaiguender.github.io/dddex/levelsetkdex_univariate.html#levelsetkdex_knn) defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1003){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kNN\n",
       "\n",
       ">      LevelSetKDEx_kNN (estimator, binSize:int=100,\n",
       ">                        weightsByDistance:bool=False)\n",
       "\n",
       "*`LevelSetKDEx_kNN` turns any point predictor that has a .predict-method \n",
       "into an estimator of the condititional density of the underlying distribution.\n",
       "The basic idea of each level-set based approach is to interprete the point forecast\n",
       "generated by the underlying point predictor as a similarity measure of samples.\n",
       "In the case of the `LevelSetKDEx_kNN` defined here, for every new samples\n",
       "'binSize'-many training samples are computed whose point forecast is closest\n",
       "to the point forecast of the new sample.\n",
       "The resulting empirical distribution of these 'nearest' training samples are \n",
       "viewed as our estimation of the conditional distribution of each the new sample \n",
       "at hand.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| binSize | int | 100 | Size of the bins created while running fit. |\n",
       "| weightsByDistance | bool | False | Determines behaviour of method `getWeights`. If False, all weights receive the same  <br>value. If True, the distance of the point forecasts is taking into account. |"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a2cda-9bda-4e7a-8d17-71e02b52b6c1",
   "metadata": {},
   "source": [
    "## LSx kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1187){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kMeans\n",
       "\n",
       ">      LevelSetKDEx_kMeans (estimator, nClusters:int=10)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1187){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_kMeans\n",
       "\n",
       ">      LevelSetKDEx_kMeans (estimator, nClusters:int=10)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| nClusters | int | 10 | Number of clusters to form as well as number of centroids to generate. |"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_kMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad7d9c-07e5-488d-81e5-21f94259ed1a",
   "metadata": {},
   "source": [
    "## LSx Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1324){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_RBF\n",
       "\n",
       ">      LevelSetKDEx_RBF (estimator, lengthScale:float=1)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| lengthScale | float | 1 | Size of the bins created while running fit. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/kaiguender/dddex/blob/main/dddex/levelSetKDEx_univariate.py#L1324){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### LevelSetKDEx_RBF\n",
       "\n",
       ">      LevelSetKDEx_RBF (estimator, lengthScale:float=1)\n",
       "\n",
       "*TBD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| estimator |  |  | Model with a .fit and .predict-method (implementing the scikit-learn estimator interface). |\n",
       "| lengthScale | float | 1 | Size of the bins created while running fit. |"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(LevelSetKDEx_RBF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81936321-7fe7-4b27-91e3-a4a1444bd29e",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523b02c-ce7b-4969-81e7-d09e60db3446",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataBakery(returnXY = True)\n",
    "\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbeb117",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# LSKDEx_drf = LevelSetKDEx_DRF(estimator = LGBM, binSize = 100)\n",
    "# LSKDEx_drf.fit(XTrain, yTrain)\n",
    "\n",
    "# weightsDataList = LSKDEx_drf.getWeights(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68573e98",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# import time\n",
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100)\n",
    "\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# weights = LSKDEx.getWeights(XTest)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb537e0",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb0dd13",
   "metadata": {},
   "source": [
    "## LSx based on DRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f87b4",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# import ipdb\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from dddex.loadData import *\n",
    "# from dddex.wSAA import RandomForestWSAA, SampleAverageApproximation\n",
    "# import time \n",
    "# import psutil\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# from drf import drf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802f3d5-dd37-4e08-b192-1b2fe558170e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# data, XTrain, yTrain, XTest, yTest = loadDataBakery(returnXY = True)\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)\n",
    "\n",
    "# LSKDEx = LevelSetKDEx_RBF(estimator = LGBM, lengthScale = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e058f-1b3f-458e-a57a-28a9d278886a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LSKDEx.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39bf9b0-c2a2-4a5d-ab60-e71ce3c04257",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# weightsData = LSKDEx.getWeights(XTest[100:200], outputType = 'summarized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d928c9b5",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# data, XTrain, yTrain, XTest, yTest = loadDataYaz(returnXY = True)\n",
    "\n",
    "# LGBM = LGBMRegressor(n_jobs = 1).fit(XTrain, yTrain)\n",
    "# yPredTrain = LGBM.predict(XTrain)\n",
    "# yPredTest = LGBM.predict(XTest)\n",
    "\n",
    "# yPredTrain = pd.DataFrame(yPredTrain)\n",
    "# yPredTest = pd.DataFrame(yPredTest)\n",
    "# yTrain = pd.Series(yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bddde6",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# DRF = drf(min_node_size = 100, num_trees = 500, num_features = 1, honesty = False, sample_fraction = 0.5, response_scaling = False, mtry = 1, num_threads = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591c551",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# DRF.fit(yPredTrain, yTrain)\n",
    "# weights = DRF.predict(yPredTest).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059af05",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    366.000000\n",
       "mean       0.002732\n",
       "std        0.002423\n",
       "min        0.000020\n",
       "25%        0.000590\n",
       "50%        0.001994\n",
       "75%        0.004667\n",
       "max        0.009120\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #| hide\n",
    "\n",
    "# # Get statistic of weights of first row#\n",
    "# weightsRow = weights[0]\n",
    "# pd.Series(weightsRow[weightsRow > 0]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29717899",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx_clustering2(estimator = LGBM, nClusters = 100)\n",
    "\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# weights = LSKDEx.getWeights(XTest)\n",
    "# print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe9c86d-137e-4d85-a4dc-211987b98589",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# path = '/home/kagu/SID/data/dataSID.csv'\n",
    "# data = pd.read_csv(path)\n",
    "\n",
    "# ids = data.id.unique()[0:30]\n",
    "# filtering = [ID in ids for ID in data.id]\n",
    "# data = data[filtering]\n",
    "\n",
    "# X = np.array(data.drop(['demand', 'date', 'id', 'label'], axis = 1))\n",
    "# Y = np.array(data['demand'])\n",
    "\n",
    "# indicesTrain = data['label'] == 'train'\n",
    "# indicesTest = data['label'] == 'test'\n",
    "\n",
    "# XTrain = X[indicesTrain]\n",
    "# yTrain = Y[indicesTrain]\n",
    "\n",
    "# XTest = X[indicesTest]\n",
    "# yTest = Y[indicesTest]\n",
    "\n",
    "# dataTrain = data[indicesTrain]\n",
    "# dataTest = data[indicesTest]\n",
    "\n",
    "# scalingList = dataTest['scalingValue'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff6e066-7688-4d99-9dff-b7b2b0ce8859",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f9e826-dadc-45ba-872f-a66e4fd72c8b",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# process = psutil.Process(os.getpid())\n",
    "# print(f\"Memory used by Jupyter notebook: {process.memory_info().rss / 2**20:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764f024-c9fd-429b-b1f9-fe4503e0ecbb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# LGBM = LGBMRegressor(boosting_type = 'gbdt',\n",
    "#                      n_jobs = 1)\n",
    "\n",
    "# LGBM.fit(X = XTrain, y = yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beaf70-9c79-4704-82d9-5a284e0823ad",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 5000)\n",
    "# LSKDEx.fit(XTrain, yTrain)\n",
    "# print(time.time() - start)\n",
    "\n",
    "# yPredTrain = LSKDEx.yPredTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523732cb-67da-467e-acf2-186df68d5569",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTrain[LSKDEx.neighborsDictTrain[list(LSKDEx.neighborsDictTrain.keys())[100]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322eb337-a075-4f47-aa2e-780b1a05fe6d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTrain[LSKDEx.neighborsDictTrain[np.array(list(LSKDEx.neighborsDictTrain.keys()))[-1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388de86-a5f8-41d8-90d8-aecb3e576ae2",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# weights = LSKDEx.getWeights(XTest, efficientRAM = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1a641-e3f3-49da-9dbe-9a9f60467161",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# res = LSKDEx.predict(XTest,\n",
    "#                      probs = [0.1, 0.5], \n",
    "#                      scalingList = scalingList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53d7c1-72a5-4525-9b13-e6db6dd9f02a",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# process = psutil.Process(os.getpid())\n",
    "# print(f\"Memory used by Jupyter notebook: {process.memory_info().rss / 2**20:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3ba66-1f21-44e0-b3d9-183b8c44d9ec",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# XTrainMod = XTrain[0:10000]\n",
    "# yTrainMod = yTrain[0:10000]\n",
    "# XTestMod = XTest[0:10]\n",
    "\n",
    "# yPredTrainMod = LGBM.predict(XTrainMod)\n",
    "# yPredTestMod = LGBM.predict(XTestMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36723cd7-309b-462d-8d26-829b1854f54e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# #| hide\n",
    "\n",
    "# LSKDEx = LevelSetKDEx(estimator = LGBM, binSize = 100, weightsByDistance = False)\n",
    "# LSKDEx.fit(XTrainMod, yTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ccaac-40eb-4023-a71d-50c5914dc940",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# #| hide\n",
    "\n",
    "# res = LSKDEx.solveKernelGLS(X = XTrainMod, sigma = 0.5, c = yPredTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4a97a0-0779-4d0f-ae4c-f2ca0a61ed3d",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# #| hide\n",
    "# res = LSKDEx.getKernelVectorProduct(X1 = XTrainMod, c = yPredTrainMod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17f57e-d639-4d71-a0cf-652aff9ebebc",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "\n",
    "# mean, cov = LSKDEx.getGaussianPosterior(XTrain = XTrainMod, \n",
    "#                                         XTest = XTestMod,\n",
    "#                                         yTrain = yTrainMod,\n",
    "#                                         sigma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e6185-06ec-4182-8719-5a75d2712d95",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPredTest = LSKDEx.estimator.predict(XTest)\n",
    "# binPerPredTest = np.searchsorted(a = LSKDEx.lowerBoundPerBin, v = yPredTest, side = 'right') - 1\n",
    "\n",
    "# binVectorsTest = [(binPerPredTest == i).reshape(-1, 1) * 1 for i in range(len(LSKDEx.lowerBoundPerBin))]\n",
    "# binVectorsToSliceTest = [np.where(binVector)[0] for binVector in binVectorsTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2273a6-a5c4-4e5f-bf9f-f9fe5a6f432f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# v = binVectorsToSliceTest[2]\n",
    "# cov[v[:, None],  v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8dbd5-5255-4646-86b9-494611148717",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d65fd-a8b4-4649-aea5-e73d04723d81",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# pd.Series(np.ravel(mean)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2db3cb-f6d6-406d-be91-5bcccf5acb7e",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# pd.Series(yTest).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebeec7-8a14-46f7-8c85-c19fa6bde752",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# yPred = np.concatenate([np.arange(5000)] * 2, axis = 0)\n",
    "# yPredTrain = np.concatenate([np.arange(50000)] * 2, axis = 0)\n",
    "# binSize = 200\n",
    "\n",
    "# neighborsDictTrain, neighborsRemoved, neighborsAdded = generateNeighborhoodsUnique(binSize = binSize,\n",
    "#                                                                                yPred = yPredTrain)\n",
    "\n",
    "# neighborsDictTest = generateNeighborhoodsTestUnique(binSize = binSize,\n",
    "#                                                 yPred = yPred,\n",
    "#                                                 yPredTrain = yPredTrain,\n",
    "#                                                 neighborsDictTrain = neighborsDictTrain)\n",
    "\n",
    "# start = time.time()\n",
    "# kernelValuesList = getKernelValues(binSize = binSize,\n",
    "#                                    yPred = yPred,\n",
    "#                                    yPredTrain = yPredTrain,\n",
    "#                                    neighborsDictTest = neighborsDictTest,\n",
    "#                                    neighborsDictTrain = neighborsDictTrain,\n",
    "#                                    neighborsRemoved = neighborsRemoved,\n",
    "#                                    neighborsAdded = neighborsAdded)\n",
    "# print(time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
